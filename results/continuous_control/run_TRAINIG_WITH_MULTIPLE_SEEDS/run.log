2025-12-29 22:50:41,816 | INFO | Logging initialized. Log file: results\continuous_control\run_20251229_225041\run.log
2025-12-29 22:50:41,816 | INFO | Results will be saved to: results\continuous_control\run_20251229_225041
2025-12-29 22:50:41,816 | INFO | Seeds: (33, 41, 66, 39, 8, 77, 21, 20, 44, 22)
2025-12-29 22:50:41,816 | INFO | Unity exe: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 22:50:41,816 | INFO | No hyperparameter search requested; running a single configuration.
2025-12-29 22:50:41,816 | INFO | Using hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 22:50:41,826 | INFO | [default | seed 33] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 22:50:41,826 | INFO | [default | seed 33] === Starting run for seed 33 ===
2025-12-29 22:50:41,826 | INFO | [default | seed 33] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 22:50:41,830 | INFO | [default | seed 33] Launching UnityVectorEnv with worker_id=33, seed=33
2025-12-29 22:50:41,830 | INFO | [Main] Spawning worker 33 for Unity env (seed=33). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 22:50:41,851 | INFO | [Main] Worker 33 started (pid=79272).
2025-12-29 22:50:47,250 | INFO | [default | seed 33] Environment batched agents (train): 20
2025-12-29 22:51:20,273 | INFO | [default | seed 33] Environment batched agents (eval): 20
2025-12-29 22:51:36,838 | INFO | [default | seed 33] elapsed_time 00:00:55, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 05.240000, episode_sum_max_abs_reward_per_step 05.240000, mean_reward_over_100_episodes_from_training 00.33±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0000, mean_reward_over_100_episodes_from_eval 00.43±00.00
2025-12-29 22:52:23,878 | INFO | [default | seed 33] elapsed_time 00:01:42, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 21.970000, episode_sum_max_abs_reward_per_step 21.970000, mean_reward_over_100_episodes_from_training 00.97±00.64, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0006, mean_reward_over_100_episodes_from_eval 00.92±00.50
2025-12-29 22:53:12,340 | INFO | [default | seed 33] elapsed_time 00:02:30, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 21.000000, episode_sum_max_abs_reward_per_step 21.000000, mean_reward_over_100_episodes_from_training 01.13±00.56, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 01.08±00.46
2025-12-29 22:54:13,331 | INFO | [default | seed 33] elapsed_time 00:03:31, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 20.040000, episode_sum_max_abs_reward_per_step 20.040000, mean_reward_over_100_episodes_from_training 01.19±00.50, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0006, mean_reward_over_100_episodes_from_eval 01.24±00.49
2025-12-29 22:55:02,722 | INFO | [default | seed 33] elapsed_time 00:04:20, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 21.060000, episode_sum_max_abs_reward_per_step 21.060000, mean_reward_over_100_episodes_from_training 01.29±00.49, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0005, mean_reward_over_100_episodes_from_eval 01.35±00.48
2025-12-29 22:55:49,273 | INFO | [default | seed 33] elapsed_time 00:05:07, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 32.839999, episode_sum_max_abs_reward_per_step 32.839999, mean_reward_over_100_episodes_from_training 01.60±00.84, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0005, mean_reward_over_100_episodes_from_eval 01.74±00.98
2025-12-29 22:56:34,916 | INFO | [default | seed 33] elapsed_time 00:05:53, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 32.589999, episode_sum_max_abs_reward_per_step 32.589999, mean_reward_over_100_episodes_from_training 01.84±00.96, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0005, mean_reward_over_100_episodes_from_eval 02.31±01.67
2025-12-29 22:57:21,364 | INFO | [default | seed 33] elapsed_time 00:06:39, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 36.469999, episode_sum_max_abs_reward_per_step 36.469999, mean_reward_over_100_episodes_from_training 02.16±01.24, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0005, mean_reward_over_100_episodes_from_eval 02.40±01.58
2025-12-29 22:58:13,868 | INFO | [default | seed 33] elapsed_time 00:07:32, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 35.329999, episode_sum_max_abs_reward_per_step 35.329999, mean_reward_over_100_episodes_from_training 02.44±01.42, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0006, mean_reward_over_100_episodes_from_eval 02.67±01.67
2025-12-29 22:59:00,100 | INFO | [default | seed 33] elapsed_time 00:08:18, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 38.529999, episode_sum_max_abs_reward_per_step 38.529999, mean_reward_over_100_episodes_from_training 02.85±01.82, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0006, mean_reward_over_100_episodes_from_eval 03.03±01.93
2025-12-29 22:59:54,648 | INFO | [default | seed 33] elapsed_time 00:09:12, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 03.38±02.40, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0006, mean_reward_over_100_episodes_from_eval 03.46±02.28
2025-12-29 23:00:41,772 | INFO | [default | seed 33] elapsed_time 00:09:59, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.419999, episode_sum_max_abs_reward_per_step 39.419999, mean_reward_over_100_episodes_from_training 03.87±02.81, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0006, mean_reward_over_100_episodes_from_eval 04.09±03.01
2025-12-29 23:01:28,439 | INFO | [default | seed 33] elapsed_time 00:10:46, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 04.47±03.43, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0006, mean_reward_over_100_episodes_from_eval 04.84±03.90
2025-12-29 23:02:14,312 | INFO | [default | seed 33] elapsed_time 00:11:32, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 05.19±04.19, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0006, mean_reward_over_100_episodes_from_eval 05.42±04.30
2025-12-29 23:02:59,925 | INFO | [default | seed 33] elapsed_time 00:12:18, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 05.95±04.95, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0006, mean_reward_over_100_episodes_from_eval 06.11±04.88
2025-12-29 23:03:45,513 | INFO | [default | seed 33] elapsed_time 00:13:03, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 06.56±05.34, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0006, mean_reward_over_100_episodes_from_eval 06.71±05.27
2025-12-29 23:04:30,426 | INFO | [default | seed 33] elapsed_time 00:13:48, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 07.05±05.55, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0005, mean_reward_over_100_episodes_from_eval 07.24±05.53
2025-12-29 23:05:16,367 | INFO | [default | seed 33] elapsed_time 00:14:34, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 07.71±06.04, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0008, mean_reward_over_100_episodes_from_eval 07.90±06.03
2025-12-29 23:06:01,911 | INFO | [default | seed 33] elapsed_time 00:15:20, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 08.28±06.34, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0008, mean_reward_over_100_episodes_from_eval 08.55±06.49
2025-12-29 23:06:48,618 | INFO | [default | seed 33] elapsed_time 00:16:06, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 08.89±06.74, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0008, mean_reward_over_100_episodes_from_eval 09.22±06.97
2025-12-29 23:07:33,971 | INFO | [default | seed 33] elapsed_time 00:16:52, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 09.37±06.92, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 09.79±07.25
2025-12-29 23:08:19,991 | INFO | [default | seed 33] elapsed_time 00:17:38, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 09.96±07.28, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 10.39±07.60
2025-12-29 23:09:05,345 | INFO | [default | seed 33] elapsed_time 00:18:23, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 10.55±07.64, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 10.97±07.93
2025-12-29 23:09:52,271 | INFO | [default | seed 33] elapsed_time 00:19:10, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 11.15±08.01, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 11.58±08.28
2025-12-29 23:10:38,432 | INFO | [default | seed 33] elapsed_time 00:19:56, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 11.71±08.31, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 12.17±08.63
2025-12-29 23:11:24,394 | INFO | [default | seed 33] elapsed_time 00:20:42, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 12.18±08.49, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 12.70±08.85
2025-12-29 23:12:10,218 | INFO | [default | seed 33] elapsed_time 00:21:28, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 12.62±08.62, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 13.12±08.95
2025-12-29 23:12:55,726 | INFO | [default | seed 33] elapsed_time 00:22:13, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 13.05±08.75, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 13.45±08.96
2025-12-29 23:13:42,934 | INFO | [default | seed 33] elapsed_time 00:23:01, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 13.39±08.79, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 13.73±08.93
2025-12-29 23:14:28,218 | INFO | [default | seed 33] elapsed_time 00:23:46, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 13.76±08.87, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 13.89±08.82
2025-12-29 23:15:14,615 | INFO | [default | seed 33] elapsed_time 00:24:32, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 14.05±08.87, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 14.23±08.88
2025-12-29 23:16:01,574 | INFO | [default | seed 33] elapsed_time 00:25:19, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 14.44±09.00, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 14.61±08.98
2025-12-29 23:16:47,779 | INFO | [default | seed 33] elapsed_time 00:26:05, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 14.81±09.10, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 14.99±09.11
2025-12-29 23:17:33,554 | INFO | [default | seed 33] elapsed_time 00:26:51, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 15.21±09.26, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 15.41±09.29
2025-12-29 23:18:18,526 | INFO | [default | seed 33] elapsed_time 00:27:36, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 15.63±09.45, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 15.86±09.52
2025-12-29 23:19:03,659 | INFO | [default | seed 33] elapsed_time 00:28:21, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 16.05±09.63, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 16.24±09.66
2025-12-29 23:19:49,756 | INFO | [default | seed 33] elapsed_time 00:29:07, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 16.44±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 16.58±09.74
2025-12-29 23:20:34,536 | INFO | [default | seed 33] elapsed_time 00:29:52, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 16.78±09.87, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 16.87±09.78
2025-12-29 23:21:20,136 | INFO | [default | seed 33] elapsed_time 00:30:38, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 17.13±09.99, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 17.14±09.79
2025-12-29 23:22:06,423 | INFO | [default | seed 33] elapsed_time 00:31:24, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 17.54±10.20, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 17.51±09.94
2025-12-29 23:22:52,000 | INFO | [default | seed 33] elapsed_time 00:32:10, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 17.96±10.40, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 17.96±10.23
2025-12-29 23:23:39,428 | INFO | [default | seed 33] elapsed_time 00:32:57, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 18.28±10.48, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 18.34±10.38
2025-12-29 23:24:25,089 | INFO | [default | seed 33] elapsed_time 00:33:43, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 18.68±10.69, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0008, mean_reward_over_100_episodes_from_eval 18.76±10.62
2025-12-29 23:25:11,963 | INFO | [default | seed 33] elapsed_time 00:34:30, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 19.03±10.81, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 19.14±10.79
2025-12-29 23:25:57,801 | INFO | [default | seed 33] elapsed_time 00:35:15, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 19.32±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 19.39±10.80
2025-12-29 23:26:44,985 | INFO | [default | seed 33] elapsed_time 00:36:03, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 19.55±10.85, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 19.68±10.86
2025-12-29 23:27:30,825 | INFO | [default | seed 33] elapsed_time 00:36:48, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 19.81±10.88, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 20.00±10.95
2025-12-29 23:28:18,106 | INFO | [default | seed 33] elapsed_time 00:37:36, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.08±10.93, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 20.33±11.07
2025-12-29 23:29:04,905 | INFO | [default | seed 33] elapsed_time 00:38:23, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 20.38±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 20.63±11.16
2025-12-29 23:29:51,791 | INFO | [default | seed 33] elapsed_time 00:39:09, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 20.63±11.04, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 20.90±11.20
2025-12-29 23:30:38,367 | INFO | [default | seed 33] elapsed_time 00:39:56, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 20.90±11.09, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 21.10±11.19
2025-12-29 23:31:24,245 | INFO | [default | seed 33] elapsed_time 00:40:42, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.08±11.07, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 21.30±11.17
2025-12-29 23:32:10,521 | INFO | [default | seed 33] elapsed_time 00:41:28, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 21.27±11.04, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0008, mean_reward_over_100_episodes_from_eval 21.50±11.16
2025-12-29 23:32:56,451 | INFO | [default | seed 33] elapsed_time 00:42:14, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 21.47±11.04, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 21.66±11.11
2025-12-29 23:33:44,120 | INFO | [default | seed 33] elapsed_time 00:43:02, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 21.66±11.02, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 21.86±11.11
2025-12-29 23:34:30,238 | INFO | [default | seed 33] elapsed_time 00:43:48, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 21.86±11.02, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 22.15±11.21
2025-12-29 23:35:17,202 | INFO | [default | seed 33] elapsed_time 00:44:35, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 22.08±11.05, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 22.37±11.24
2025-12-29 23:36:04,772 | INFO | [default | seed 33] elapsed_time 00:45:22, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 22.25±11.03, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 22.41±11.15
2025-12-29 23:36:51,937 | INFO | [default | seed 33] elapsed_time 00:46:10, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 22.40±11.00, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 22.61±11.15
2025-12-29 23:37:38,730 | INFO | [default | seed 33] elapsed_time 00:46:56, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 22.51±10.94, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 22.80±11.16
2025-12-29 23:38:25,505 | INFO | [default | seed 33] elapsed_time 00:47:43, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 22.69±10.94, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 22.98±11.15
2025-12-29 23:39:13,015 | INFO | [default | seed 33] elapsed_time 00:48:31, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 22.87±10.94, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 23.19±11.18
2025-12-29 23:40:00,029 | INFO | [default | seed 33] elapsed_time 00:49:18, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 23.03±10.92, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 23.39±11.20
2025-12-29 23:40:46,631 | INFO | [default | seed 33] elapsed_time 00:50:04, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 23.20±10.92, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 23.55±11.19
2025-12-29 23:41:33,817 | INFO | [default | seed 33] elapsed_time 00:50:51, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 23.35±10.90, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 23.73±11.19
2025-12-29 23:42:20,738 | INFO | [default | seed 33] elapsed_time 00:51:38, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.52±10.91, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 23.85±11.15
2025-12-29 23:43:08,150 | INFO | [default | seed 33] elapsed_time 00:52:26, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 23.69±10.91, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0009, mean_reward_over_100_episodes_from_eval 23.98±11.11
2025-12-29 23:43:54,728 | INFO | [default | seed 33] elapsed_time 00:53:12, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.82±10.88, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0009, mean_reward_over_100_episodes_from_eval 24.07±11.06
2025-12-29 23:44:43,759 | INFO | [default | seed 33] elapsed_time 00:54:01, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 23.97±10.87, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0009, mean_reward_over_100_episodes_from_eval 24.24±11.07
2025-12-29 23:45:31,205 | INFO | [default | seed 33] elapsed_time 00:54:49, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.11±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0010, mean_reward_over_100_episodes_from_eval 24.43±11.10
2025-12-29 23:46:17,775 | INFO | [default | seed 33] elapsed_time 00:55:35, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 24.26±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0010, mean_reward_over_100_episodes_from_eval 24.62±11.13
2025-12-29 23:47:04,697 | INFO | [default | seed 33] elapsed_time 00:56:22, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.42±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0010, mean_reward_over_100_episodes_from_eval 24.73±11.09
2025-12-29 23:47:52,038 | INFO | [default | seed 33] elapsed_time 00:57:10, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.56±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0010, mean_reward_over_100_episodes_from_eval 24.90±11.11
2025-12-29 23:48:38,534 | INFO | [default | seed 33] elapsed_time 00:57:56, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 24.68±10.83, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0010, mean_reward_over_100_episodes_from_eval 24.98±11.06
2025-12-29 23:49:24,538 | INFO | [default | seed 33] elapsed_time 00:58:42, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.79±10.80, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0011, mean_reward_over_100_episodes_from_eval 25.11±11.03
2025-12-29 23:50:11,275 | INFO | [default | seed 33] elapsed_time 00:59:29, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 24.90±10.77, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0011, mean_reward_over_100_episodes_from_eval 25.19±10.99
2025-12-29 23:50:57,309 | INFO | [default | seed 33] elapsed_time 01:00:15, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.749999, episode_sum_max_abs_reward_per_step 39.749999, mean_reward_over_100_episodes_from_training 25.01±10.74, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0011, mean_reward_over_100_episodes_from_eval 25.24±10.92
2025-12-29 23:51:43,637 | INFO | [default | seed 33] elapsed_time 01:01:01, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 25.12±10.72, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0012, mean_reward_over_100_episodes_from_eval 25.38±10.92
2025-12-29 23:52:29,370 | INFO | [default | seed 33] elapsed_time 01:01:47, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.27±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0012, mean_reward_over_100_episodes_from_eval 25.53±10.93
2025-12-29 23:53:16,672 | INFO | [default | seed 33] elapsed_time 01:02:34, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 25.40±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0012, mean_reward_over_100_episodes_from_eval 25.67±10.94
2025-12-29 23:54:04,441 | INFO | [default | seed 33] elapsed_time 01:03:22, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.50±10.70, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 25.73±10.88
2025-12-29 23:54:53,613 | INFO | [default | seed 33] elapsed_time 01:04:11, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.58±10.66, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 25.86±10.88
2025-12-29 23:55:40,152 | INFO | [default | seed 33] elapsed_time 01:04:58, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 25.66±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 25.96±10.85
2025-12-29 23:56:26,155 | INFO | [default | seed 33] elapsed_time 01:05:44, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 25.73±10.57, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 26.10±10.86
2025-12-29 23:57:12,699 | INFO | [default | seed 33] elapsed_time 01:06:30, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 25.84±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 26.21±10.84
2025-12-29 23:57:58,453 | INFO | [default | seed 33] elapsed_time 01:07:16, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 25.96±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 26.31±10.82
2025-12-29 23:58:46,626 | INFO | [default | seed 33] elapsed_time 01:08:04, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.08±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 26.42±10.81
2025-12-29 23:59:33,929 | INFO | [default | seed 33] elapsed_time 01:08:52, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.19±10.55, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 26.52±10.79
2025-12-30 00:00:21,500 | INFO | [default | seed 33] elapsed_time 01:09:39, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.29±10.53, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 26.63±10.77
2025-12-30 00:01:09,907 | INFO | [default | seed 33] elapsed_time 01:10:28, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 26.39±10.51, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 26.70±10.73
2025-12-30 00:01:57,495 | INFO | [default | seed 33] elapsed_time 01:11:15, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 26.46±10.47, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 26.79±10.71
2025-12-30 00:02:44,250 | INFO | [default | seed 33] elapsed_time 01:12:02, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.55±10.46, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 26.89±10.70
2025-12-30 00:03:30,447 | INFO | [default | seed 33] elapsed_time 01:12:48, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 26.66±10.45, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 27.01±10.70
2025-12-30 00:04:18,202 | INFO | [default | seed 33] elapsed_time 01:13:36, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.74±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 27.09±10.66
2025-12-30 00:05:05,421 | INFO | [default | seed 33] elapsed_time 01:14:23, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.83±10.41, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 27.17±10.64
2025-12-30 00:05:53,075 | INFO | [default | seed 33] elapsed_time 01:15:11, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 26.91±10.38, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 27.24±10.61
2025-12-30 00:06:40,474 | INFO | [default | seed 33] elapsed_time 01:15:58, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 26.99±10.36, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 27.25±10.55
2025-12-30 00:07:27,178 | INFO | [default | seed 33] elapsed_time 01:16:45, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.06±10.33, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 27.30±10.51
2025-12-30 00:08:14,675 | INFO | [default | seed 33] elapsed_time 01:17:32, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.15±10.32, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 27.38±10.49
2025-12-30 00:09:00,963 | INFO | [default | seed 33] elapsed_time 01:18:19, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.22±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 27.43±10.45
2025-12-30 00:09:47,556 | INFO | [default | seed 33] elapsed_time 01:19:05, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.57±09.96, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0015, mean_reward_over_100_episodes_from_eval 27.76±10.11
2025-12-30 00:10:33,386 | INFO | [default | seed 33] elapsed_time 01:19:51, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.86±09.61, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0015, mean_reward_over_100_episodes_from_eval 28.10±09.79
2025-12-30 00:11:20,359 | INFO | [default | seed 33] elapsed_time 01:20:38, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.14±09.24, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0015, mean_reward_over_100_episodes_from_eval 28.38±09.41
2025-12-30 00:12:07,691 | INFO | [default | seed 33] elapsed_time 01:21:25, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.45±08.85, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0015, mean_reward_over_100_episodes_from_eval 28.70±09.04
2025-12-30 00:12:54,340 | INFO | [default | seed 33] elapsed_time 01:22:12, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.76±08.44, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0015, mean_reward_over_100_episodes_from_eval 29.03±08.64
2025-12-30 00:13:41,512 | INFO | [default | seed 33] elapsed_time 01:22:59, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.05±08.04, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0015, mean_reward_over_100_episodes_from_eval 29.30±08.26
2025-12-30 00:14:27,473 | INFO | [default | seed 33] elapsed_time 01:23:45, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.35±07.62, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0016, mean_reward_over_100_episodes_from_eval 29.59±07.93
2025-12-30 00:15:13,779 | INFO | [default | seed 33] elapsed_time 01:24:31, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 29.63±07.21, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0016, mean_reward_over_100_episodes_from_eval 29.92±07.49
2025-12-30 00:15:59,505 | INFO | [default | seed 33] Requirement met (evaluation metric): solved at episode 109 with mean_100_eval=30.24
2025-12-30 00:15:59,509 | INFO | [default | seed 33] elapsed_time 01:25:17, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.96±06.80, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0016, mean_reward_over_100_episodes_from_eval 30.24±07.09
2025-12-30 00:15:59,509 | INFO | [default | seed 33] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 00:41:01,612 | INFO | [default | seed 33] Training complete.
2025-12-30 00:41:01,612 | INFO | [default | seed 33] Solved (evaluation metric) at episode 109.
2025-12-30 00:41:01,612 | INFO | [default | seed 33] Final evaluation score 36.52±0.53 in 3509.00s training, 6619.79s wall.
2025-12-30 00:41:01,612 | INFO | [default | seed 33] Closing UnityVectorEnv (worker_id=33).
2025-12-30 00:41:01,612 | INFO | [Main] Requesting worker 33 to close Unity env.
2025-12-30 00:41:02,634 | INFO | [Main] Worker 33 joined. Unity env fully closed.
2025-12-30 00:41:02,636 | INFO | [default | seed 33] Final eval score: 36.52
2025-12-30 00:41:03,194 | INFO | [default | seed 33] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_33.png
2025-12-30 00:41:03,194 | INFO | [default | seed 33] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 00:41:03,381 | INFO | [default | seed 41] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 00:41:03,381 | INFO | [default | seed 41] === Starting run for seed 41 ===
2025-12-30 00:41:03,381 | INFO | [default | seed 41] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 00:41:03,412 | INFO | [default | seed 41] Launching UnityVectorEnv with worker_id=41, seed=41
2025-12-30 00:41:03,412 | INFO | [Main] Spawning worker 41 for Unity env (seed=41). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 00:41:03,430 | INFO | [Main] Worker 41 started (pid=80368).
2025-12-30 00:41:07,060 | INFO | [default | seed 41] Environment batched agents (train): 20
2025-12-30 00:41:34,595 | INFO | [default | seed 41] Environment batched agents (eval): 20
2025-12-30 00:41:50,032 | INFO | [default | seed 41] elapsed_time 00:00:46, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 11.290000, episode_sum_max_abs_reward_per_step 11.290000, mean_reward_over_100_episodes_from_training 00.65±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0000, mean_reward_over_100_episodes_from_eval 01.40±00.00
2025-12-30 00:42:35,012 | INFO | [default | seed 41] elapsed_time 00:01:31, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 19.280000, episode_sum_max_abs_reward_per_step 19.280000, mean_reward_over_100_episodes_from_training 01.02±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0002, mean_reward_over_100_episodes_from_eval 01.66±00.26
2025-12-30 00:43:21,713 | INFO | [default | seed 41] elapsed_time 00:02:18, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 26.689999, episode_sum_max_abs_reward_per_step 26.689999, mean_reward_over_100_episodes_from_training 01.39±00.61, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0002, mean_reward_over_100_episodes_from_eval 01.91±00.42
2025-12-30 00:44:08,776 | INFO | [default | seed 41] elapsed_time 00:03:05, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 31.909999, episode_sum_max_abs_reward_per_step 31.909999, mean_reward_over_100_episodes_from_training 01.75±00.81, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0002, mean_reward_over_100_episodes_from_eval 01.91±00.36
2025-12-30 00:44:55,727 | INFO | [default | seed 41] elapsed_time 00:03:52, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 30.379999, episode_sum_max_abs_reward_per_step 30.379999, mean_reward_over_100_episodes_from_training 01.94±00.82, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0002, mean_reward_over_100_episodes_from_eval 02.14±00.57
2025-12-30 00:45:43,158 | INFO | [default | seed 41] elapsed_time 00:04:39, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 33.629999, episode_sum_max_abs_reward_per_step 33.629999, mean_reward_over_100_episodes_from_training 02.22±00.98, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0004, mean_reward_over_100_episodes_from_eval 02.45±00.86
2025-12-30 00:46:30,156 | INFO | [default | seed 41] elapsed_time 00:05:26, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 35.659999, episode_sum_max_abs_reward_per_step 35.659999, mean_reward_over_100_episodes_from_training 02.52±01.17, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0004, mean_reward_over_100_episodes_from_eval 02.85±01.27
2025-12-30 00:47:17,622 | INFO | [default | seed 41] elapsed_time 00:06:14, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 36.519999, episode_sum_max_abs_reward_per_step 36.519999, mean_reward_over_100_episodes_from_training 02.84±01.38, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0004, mean_reward_over_100_episodes_from_eval 03.26±01.61
2025-12-30 00:48:04,859 | INFO | [default | seed 41] elapsed_time 00:07:01, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 38.519999, episode_sum_max_abs_reward_per_step 38.519999, mean_reward_over_100_episodes_from_training 03.44±02.14, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0005, mean_reward_over_100_episodes_from_eval 03.90±02.35
2025-12-30 00:48:52,191 | INFO | [default | seed 41] elapsed_time 00:07:48, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 03.96±02.56, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0005, mean_reward_over_100_episodes_from_eval 04.70±03.29
2025-12-30 00:49:40,252 | INFO | [default | seed 41] elapsed_time 00:08:36, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.429999, episode_sum_max_abs_reward_per_step 39.429999, mean_reward_over_100_episodes_from_training 04.76±03.51, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0005, mean_reward_over_100_episodes_from_eval 05.47±03.96
2025-12-30 00:50:26,015 | INFO | [default | seed 41] elapsed_time 00:09:22, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 05.70±04.60, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0005, mean_reward_over_100_episodes_from_eval 06.75±05.70
2025-12-30 00:51:13,343 | INFO | [default | seed 41] elapsed_time 00:10:09, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 06.78±05.79, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0006, mean_reward_over_100_episodes_from_eval 07.88±06.72
2025-12-30 00:51:59,092 | INFO | [default | seed 41] elapsed_time 00:10:55, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 08.09±07.31, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0008, mean_reward_over_100_episodes_from_eval 09.34±08.35
2025-12-30 00:52:46,726 | INFO | [default | seed 41] elapsed_time 00:11:43, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 09.53±08.88, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0011, mean_reward_over_100_episodes_from_eval 10.70±09.54
2025-12-30 00:53:33,987 | INFO | [default | seed 41] elapsed_time 00:12:30, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 11.18±10.70, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0013, mean_reward_over_100_episodes_from_eval 12.42±11.40
2025-12-30 00:54:22,248 | INFO | [default | seed 41] elapsed_time 00:13:18, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 12.64±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0013, mean_reward_over_100_episodes_from_eval 13.84±12.43
2025-12-30 00:55:09,614 | INFO | [default | seed 41] elapsed_time 00:14:06, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 14.01±12.89, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0013, mean_reward_over_100_episodes_from_eval 15.01±13.00
2025-12-30 00:55:55,514 | INFO | [default | seed 41] elapsed_time 00:14:52, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 15.20±13.53, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0015, mean_reward_over_100_episodes_from_eval 16.23±13.67
2025-12-30 00:56:42,940 | INFO | [default | seed 41] elapsed_time 00:15:39, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 16.29±14.01, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0016, mean_reward_over_100_episodes_from_eval 17.18±13.96
2025-12-30 00:57:29,507 | INFO | [default | seed 41] elapsed_time 00:16:26, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 17.17±14.23, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0016, mean_reward_over_100_episodes_from_eval 18.07±14.19
2025-12-30 00:58:18,018 | INFO | [default | seed 41] elapsed_time 00:17:14, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 18.03±14.45, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0016, mean_reward_over_100_episodes_from_eval 18.82±14.28
2025-12-30 00:59:05,902 | INFO | [default | seed 41] elapsed_time 00:18:02, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.78±14.56, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0016, mean_reward_over_100_episodes_from_eval 19.50±14.33
2025-12-30 00:59:53,431 | INFO | [default | seed 41] elapsed_time 00:18:50, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 19.46±14.62, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0016, mean_reward_over_100_episodes_from_eval 20.21±14.44
2025-12-30 01:00:41,484 | INFO | [default | seed 41] elapsed_time 00:19:38, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 20.09±14.65, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0016, mean_reward_over_100_episodes_from_eval 20.82±14.46
2025-12-30 01:01:29,778 | INFO | [default | seed 41] elapsed_time 00:20:26, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 20.61±14.60, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0016, mean_reward_over_100_episodes_from_eval 21.31±14.38
2025-12-30 01:02:17,175 | INFO | [default | seed 41] elapsed_time 00:21:13, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 21.12±14.56, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0016, mean_reward_over_100_episodes_from_eval 21.70±14.25
2025-12-30 01:03:04,457 | INFO | [default | seed 41] elapsed_time 00:22:01, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 21.63±14.55, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 22.13±14.18
2025-12-30 01:03:52,823 | INFO | [default | seed 41] elapsed_time 00:22:49, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.12±14.53, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 22.56±14.12
2025-12-30 01:04:40,859 | INFO | [default | seed 41] elapsed_time 00:23:37, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 22.48±14.41, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 22.96±14.05
2025-12-30 01:05:26,851 | INFO | [default | seed 41] elapsed_time 00:24:23, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 22.89±14.36, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 23.38±14.00
2025-12-30 01:06:14,023 | INFO | [default | seed 41] elapsed_time 00:25:10, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.29±14.31, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 23.70±13.90
2025-12-30 01:07:00,898 | INFO | [default | seed 41] elapsed_time 00:25:57, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 23.61±14.21, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 23.95±13.76
2025-12-30 01:07:47,376 | INFO | [default | seed 41] elapsed_time 00:26:43, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 23.97±14.15, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 24.34±13.74
2025-12-30 01:08:33,800 | INFO | [default | seed 41] elapsed_time 00:27:30, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 24.31±14.08, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0014, mean_reward_over_100_episodes_from_eval 24.52±13.59
2025-12-30 01:09:21,175 | INFO | [default | seed 41] elapsed_time 00:28:17, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 24.60±13.99, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0014, mean_reward_over_100_episodes_from_eval 24.75±13.46
2025-12-30 01:10:09,902 | INFO | [default | seed 41] elapsed_time 00:29:06, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 24.90±13.91, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0014, mean_reward_over_100_episodes_from_eval 24.99±13.36
2025-12-30 01:10:56,568 | INFO | [default | seed 41] elapsed_time 00:29:53, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.17±13.83, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0014, mean_reward_over_100_episodes_from_eval 25.31±13.32
2025-12-30 01:11:45,181 | INFO | [default | seed 41] elapsed_time 00:30:41, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.40±13.72, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0014, mean_reward_over_100_episodes_from_eval 25.57±13.25
2025-12-30 01:12:32,621 | INFO | [default | seed 41] elapsed_time 00:31:29, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.64±13.63, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0014, mean_reward_over_100_episodes_from_eval 25.77±13.14
2025-12-30 01:13:19,994 | INFO | [default | seed 41] elapsed_time 00:32:16, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 25.88±13.55, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0015, mean_reward_over_100_episodes_from_eval 26.04±13.09
2025-12-30 01:14:08,986 | INFO | [default | seed 41] elapsed_time 00:33:05, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 26.04±13.43, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0015, mean_reward_over_100_episodes_from_eval 26.22±12.99
2025-12-30 01:14:56,720 | INFO | [default | seed 41] elapsed_time 00:33:53, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 26.23±13.33, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0015, mean_reward_over_100_episodes_from_eval 26.46±12.92
2025-12-30 01:15:44,567 | INFO | [default | seed 41] elapsed_time 00:34:41, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.40±13.22, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0016, mean_reward_over_100_episodes_from_eval 26.57±12.80
2025-12-30 01:16:32,226 | INFO | [default | seed 41] elapsed_time 00:35:28, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.59±13.14, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0016, mean_reward_over_100_episodes_from_eval 26.68±12.68
2025-12-30 01:17:20,444 | INFO | [default | seed 41] elapsed_time 00:36:17, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 26.76±13.04, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0016, mean_reward_over_100_episodes_from_eval 26.89±12.61
2025-12-30 01:18:07,436 | INFO | [default | seed 41] elapsed_time 00:37:04, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.97±12.99, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0016, mean_reward_over_100_episodes_from_eval 27.09±12.56
2025-12-30 01:18:55,639 | INFO | [default | seed 41] elapsed_time 00:37:52, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.11±12.88, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0016, mean_reward_over_100_episodes_from_eval 27.23±12.46
2025-12-30 01:19:43,751 | INFO | [default | seed 41] elapsed_time 00:38:40, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.23±12.78, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0016, mean_reward_over_100_episodes_from_eval 27.43±12.41
2025-12-30 01:20:31,054 | INFO | [default | seed 41] elapsed_time 00:39:27, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.38±12.69, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0016, mean_reward_over_100_episodes_from_eval 27.60±12.34
2025-12-30 01:21:19,433 | INFO | [default | seed 41] elapsed_time 00:40:16, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.57±12.64, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0017, mean_reward_over_100_episodes_from_eval 27.81±12.31
2025-12-30 01:22:11,748 | INFO | [default | seed 41] elapsed_time 00:41:08, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.74±12.58, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0017, mean_reward_over_100_episodes_from_eval 27.99±12.26
2025-12-30 01:22:58,664 | INFO | [default | seed 41] elapsed_time 00:41:55, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.85±12.48, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0017, mean_reward_over_100_episodes_from_eval 28.08±12.16
2025-12-30 01:23:46,584 | INFO | [default | seed 41] elapsed_time 00:42:43, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 27.94±12.38, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0017, mean_reward_over_100_episodes_from_eval 28.14±12.06
2025-12-30 01:24:32,702 | INFO | [default | seed 41] elapsed_time 00:43:29, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.06±12.30, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0017, mean_reward_over_100_episodes_from_eval 28.26±11.98
2025-12-30 01:25:19,891 | INFO | [default | seed 41] elapsed_time 00:44:16, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.24±12.26, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0017, mean_reward_over_100_episodes_from_eval 28.45±11.95
2025-12-30 01:26:08,166 | INFO | [default | seed 41] elapsed_time 00:45:04, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 28.37±12.20, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0017, mean_reward_over_100_episodes_from_eval 28.62±11.91
2025-12-30 01:26:56,872 | INFO | [default | seed 41] elapsed_time 00:45:53, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.52±12.14, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0017, mean_reward_over_100_episodes_from_eval 28.74±11.85
2025-12-30 01:27:43,326 | INFO | [default | seed 41] elapsed_time 00:46:39, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.66±12.08, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0018, mean_reward_over_100_episodes_from_eval 28.90±11.81
2025-12-30 01:28:29,906 | INFO | [default | seed 41] elapsed_time 00:47:26, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.73±12.00, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0018, mean_reward_over_100_episodes_from_eval 28.99±11.73
2025-12-30 01:29:17,021 | INFO | [default | seed 41] elapsed_time 00:48:13, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.81±11.91, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0018, mean_reward_over_100_episodes_from_eval 29.06±11.65
2025-12-30 01:30:05,330 | INFO | [default | seed 41] elapsed_time 00:49:01, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 28.85±11.82, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0018, mean_reward_over_100_episodes_from_eval 29.15±11.57
2025-12-30 01:30:53,084 | INFO | [default | seed 41] elapsed_time 00:49:49, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.98±11.77, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0018, mean_reward_over_100_episodes_from_eval 29.27±11.52
2025-12-30 01:31:41,319 | INFO | [default | seed 41] elapsed_time 00:50:37, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.01±11.68, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0018, mean_reward_over_100_episodes_from_eval 29.33±11.44
2025-12-30 01:32:27,991 | INFO | [default | seed 41] elapsed_time 00:51:24, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.08±11.60, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0018, mean_reward_over_100_episodes_from_eval 29.37±11.36
2025-12-30 01:33:14,554 | INFO | [default | seed 41] elapsed_time 00:52:11, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.13±11.52, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0018, mean_reward_over_100_episodes_from_eval 29.45±11.29
2025-12-30 01:34:02,548 | INFO | [default | seed 41] elapsed_time 00:52:59, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.20±11.45, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0018, mean_reward_over_100_episodes_from_eval 29.50±11.21
2025-12-30 01:34:50,828 | INFO | [default | seed 41] elapsed_time 00:53:47, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.25±11.37, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0018, mean_reward_over_100_episodes_from_eval 29.58±11.15
2025-12-30 01:35:38,772 | INFO | [default | seed 41] elapsed_time 00:54:35, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.35±11.32, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0018, mean_reward_over_100_episodes_from_eval 29.68±11.10
2025-12-30 01:36:25,312 | INFO | [default | seed 41] elapsed_time 00:55:21, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.44±11.26, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0019, mean_reward_over_100_episodes_from_eval 29.78±11.05
2025-12-30 01:37:12,104 | INFO | [default | seed 41] elapsed_time 00:56:08, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.50±11.19, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0019, mean_reward_over_100_episodes_from_eval 29.87±11.00
2025-12-30 01:37:59,492 | INFO | [default | seed 41] elapsed_time 00:56:56, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.59±11.14, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0019, mean_reward_over_100_episodes_from_eval 29.96±10.95
2025-12-30 01:38:47,881 | INFO | [default | seed 41] elapsed_time 00:57:44, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.68±11.09, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0019, mean_reward_over_100_episodes_from_eval 30.04±10.89
2025-12-30 01:39:35,644 | INFO | [default | seed 41] elapsed_time 00:58:32, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.75±11.03, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0019, mean_reward_over_100_episodes_from_eval 30.09±10.83
2025-12-30 01:40:24,285 | INFO | [default | seed 41] elapsed_time 00:59:20, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.80±10.96, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.11±10.76
2025-12-30 01:41:12,880 | INFO | [default | seed 41] elapsed_time 01:00:09, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.86±10.91, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.15±10.69
2025-12-30 01:41:59,915 | INFO | [default | seed 41] elapsed_time 01:00:56, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.91±10.84, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.22±10.64
2025-12-30 01:42:46,538 | INFO | [default | seed 41] elapsed_time 01:01:43, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.95±10.78, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.28±10.58
2025-12-30 01:43:35,165 | INFO | [default | seed 41] elapsed_time 01:02:31, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.01±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.36±10.54
2025-12-30 01:44:24,516 | INFO | [default | seed 41] elapsed_time 01:03:21, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.08±10.68, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.39±10.48
2025-12-30 01:45:14,823 | INFO | [default | seed 41] elapsed_time 01:04:11, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.06±10.61, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 30.39±10.41
2025-12-30 01:46:03,311 | INFO | [default | seed 41] elapsed_time 01:04:59, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.759999, episode_sum_max_abs_reward_per_step 39.759999, mean_reward_over_100_episodes_from_training 30.07±10.55, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0020, mean_reward_over_100_episodes_from_eval 30.47±10.37
2025-12-30 01:46:51,670 | INFO | [default | seed 41] elapsed_time 01:05:48, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.16±10.52, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0020, mean_reward_over_100_episodes_from_eval 30.55±10.34
2025-12-30 01:47:38,417 | INFO | [default | seed 41] elapsed_time 01:06:35, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.23±10.48, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0020, mean_reward_over_100_episodes_from_eval 30.63±10.30
2025-12-30 01:48:25,990 | INFO | [default | seed 41] elapsed_time 01:07:22, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.32±10.44, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0020, mean_reward_over_100_episodes_from_eval 30.69±10.25
2025-12-30 01:49:13,307 | INFO | [default | seed 41] elapsed_time 01:08:09, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.38±10.40, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0020, mean_reward_over_100_episodes_from_eval 30.74±10.21
2025-12-30 01:50:01,362 | INFO | [default | seed 41] elapsed_time 01:08:57, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 30.43±10.35, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0020, mean_reward_over_100_episodes_from_eval 30.77±10.15
2025-12-30 01:50:47,941 | INFO | [default | seed 41] elapsed_time 01:09:44, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.45±10.29, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0020, mean_reward_over_100_episodes_from_eval 30.81±10.10
2025-12-30 01:51:34,877 | INFO | [default | seed 41] elapsed_time 01:10:31, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.48±10.24, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0020, mean_reward_over_100_episodes_from_eval 30.83±10.04
2025-12-30 01:52:21,693 | INFO | [default | seed 41] elapsed_time 01:11:18, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.54±10.19, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0020, mean_reward_over_100_episodes_from_eval 30.91±10.01
2025-12-30 01:53:10,614 | INFO | [default | seed 41] elapsed_time 01:12:07, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 30.58±10.15, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0020, mean_reward_over_100_episodes_from_eval 30.98±09.98
2025-12-30 01:53:58,615 | INFO | [default | seed 41] elapsed_time 01:12:55, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.63±10.10, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0020, mean_reward_over_100_episodes_from_eval 30.94±09.93
2025-12-30 01:54:45,746 | INFO | [default | seed 41] elapsed_time 01:13:42, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.66±10.05, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0020, mean_reward_over_100_episodes_from_eval 30.97±09.88
2025-12-30 01:55:31,936 | INFO | [default | seed 41] elapsed_time 01:14:28, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.70±10.01, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0020, mean_reward_over_100_episodes_from_eval 31.00±09.83
2025-12-30 01:56:19,944 | INFO | [default | seed 41] elapsed_time 01:15:16, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.72±09.96, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0020, mean_reward_over_100_episodes_from_eval 31.05±09.79
2025-12-30 01:57:08,138 | INFO | [default | seed 41] elapsed_time 01:16:04, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.79±09.93, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0020, mean_reward_over_100_episodes_from_eval 31.13±09.77
2025-12-30 01:57:55,511 | INFO | [default | seed 41] elapsed_time 01:16:52, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.86±09.90, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0020, mean_reward_over_100_episodes_from_eval 31.15±09.72
2025-12-30 01:58:43,385 | INFO | [default | seed 41] elapsed_time 01:17:40, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.90±09.86, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0020, mean_reward_over_100_episodes_from_eval 31.19±09.68
2025-12-30 01:59:29,745 | INFO | [default | seed 41] elapsed_time 01:18:26, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.97±09.83, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0020, mean_reward_over_100_episodes_from_eval 31.25±09.65
2025-12-30 02:00:16,575 | INFO | [default | seed 41] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=31.25
2025-12-30 02:00:16,575 | INFO | [default | seed 41] elapsed_time 01:19:13, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 31.00±09.78, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0020, mean_reward_over_100_episodes_from_eval 31.25±09.60
2025-12-30 02:00:16,576 | INFO | [default | seed 41] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 02:25:26,685 | INFO | [default | seed 41] Training complete.
2025-12-30 02:25:26,685 | INFO | [default | seed 41] Solved (evaluation metric) at episode 100.
2025-12-30 02:25:26,685 | INFO | [default | seed 41] Final evaluation score 30.05±0.90 in 3260.06s training, 6263.30s wall.
2025-12-30 02:25:26,685 | INFO | [default | seed 41] Closing UnityVectorEnv (worker_id=41).
2025-12-30 02:25:26,687 | INFO | [Main] Requesting worker 41 to close Unity env.
2025-12-30 02:25:27,368 | INFO | [Main] Worker 41 joined. Unity env fully closed.
2025-12-30 02:25:27,369 | INFO | [default | seed 41] Final eval score: 30.05
2025-12-30 02:25:27,657 | INFO | [default | seed 41] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_41.png
2025-12-30 02:25:27,658 | INFO | [default | seed 41] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 02:25:27,823 | INFO | [default | seed 66] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 02:25:27,823 | INFO | [default | seed 66] === Starting run for seed 66 ===
2025-12-30 02:25:27,823 | INFO | [default | seed 66] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 02:25:27,823 | INFO | [default | seed 66] Launching UnityVectorEnv with worker_id=66, seed=66
2025-12-30 02:25:27,823 | INFO | [Main] Spawning worker 66 for Unity env (seed=66). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 02:25:27,841 | INFO | [Main] Worker 66 started (pid=82620).
2025-12-30 02:25:31,591 | INFO | [default | seed 66] Environment batched agents (train): 20
2025-12-30 02:25:59,295 | INFO | [default | seed 66] Environment batched agents (eval): 20
2025-12-30 02:26:15,136 | INFO | [default | seed 66] elapsed_time 00:00:47, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 11.380000, episode_sum_max_abs_reward_per_step 11.380000, mean_reward_over_100_episodes_from_training 00.72±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0000, mean_reward_over_100_episodes_from_eval 01.22±00.00
2025-12-30 02:27:00,574 | INFO | [default | seed 66] elapsed_time 00:01:32, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 14.060000, episode_sum_max_abs_reward_per_step 14.060000, mean_reward_over_100_episodes_from_training 00.83±00.11, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0007, mean_reward_over_100_episodes_from_eval 01.14±00.09
2025-12-30 02:27:45,137 | INFO | [default | seed 66] elapsed_time 00:02:17, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 16.710000, episode_sum_max_abs_reward_per_step 16.710000, mean_reward_over_100_episodes_from_training 00.97±00.22, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0007, mean_reward_over_100_episodes_from_eval 01.32±00.26
2025-12-30 02:28:33,144 | INFO | [default | seed 66] elapsed_time 00:03:05, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 26.959999, episode_sum_max_abs_reward_per_step 26.959999, mean_reward_over_100_episodes_from_training 01.27±00.56, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0008, mean_reward_over_100_episodes_from_eval 01.60±00.54
2025-12-30 02:29:20,533 | INFO | [default | seed 66] elapsed_time 00:03:52, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 29.439999, episode_sum_max_abs_reward_per_step 29.439999, mean_reward_over_100_episodes_from_training 01.53±00.72, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0007, mean_reward_over_100_episodes_from_eval 01.71±00.53
2025-12-30 02:30:08,469 | INFO | [default | seed 66] elapsed_time 00:04:40, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 33.069999, episode_sum_max_abs_reward_per_step 33.069999, mean_reward_over_100_episodes_from_training 01.87±01.00, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0007, mean_reward_over_100_episodes_from_eval 02.16±01.13
2025-12-30 02:30:55,981 | INFO | [default | seed 66] elapsed_time 00:05:28, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 38.209999, episode_sum_max_abs_reward_per_step 38.209999, mean_reward_over_100_episodes_from_training 02.37±01.54, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0006, mean_reward_over_100_episodes_from_eval 02.75±01.77
2025-12-30 02:31:43,923 | INFO | [default | seed 66] elapsed_time 00:06:16, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 38.619999, episode_sum_max_abs_reward_per_step 38.619999, mean_reward_over_100_episodes_from_training 02.95±02.10, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0006, mean_reward_over_100_episodes_from_eval 03.52±02.63
2025-12-30 02:32:30,807 | INFO | [default | seed 66] elapsed_time 00:07:02, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 03.94±03.43, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0006, mean_reward_over_100_episodes_from_eval 04.81±04.40
2025-12-30 02:33:19,327 | INFO | [default | seed 66] elapsed_time 00:07:51, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 05.43±05.52, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0007, mean_reward_over_100_episodes_from_eval 06.75±07.18
2025-12-30 02:34:07,519 | INFO | [default | seed 66] elapsed_time 00:08:39, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 07.71±08.94, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0008, mean_reward_over_100_episodes_from_eval 09.02±09.91
2025-12-30 02:34:55,889 | INFO | [default | seed 66] elapsed_time 00:09:28, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 10.17±11.81, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0012, mean_reward_over_100_episodes_from_eval 11.49±12.54
2025-12-30 02:35:44,238 | INFO | [default | seed 66] elapsed_time 00:10:16, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 12.33±13.59, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0015, mean_reward_over_100_episodes_from_eval 13.52±13.95
2025-12-30 02:36:31,956 | INFO | [default | seed 66] elapsed_time 00:11:04, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 14.20±14.74, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0016, mean_reward_over_100_episodes_from_eval 15.36±14.99
2025-12-30 02:37:20,248 | INFO | [default | seed 66] elapsed_time 00:11:52, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 15.77±15.39, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0017, mean_reward_over_100_episodes_from_eval 16.90±15.58
2025-12-30 02:38:07,470 | INFO | [default | seed 66] elapsed_time 00:12:39, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 17.14±15.82, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0017, mean_reward_over_100_episodes_from_eval 18.27±16.00
2025-12-30 02:38:54,854 | INFO | [default | seed 66] elapsed_time 00:13:27, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 18.29±16.03, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0017, mean_reward_over_100_episodes_from_eval 19.44±16.21
2025-12-30 02:39:42,107 | INFO | [default | seed 66] elapsed_time 00:14:14, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 19.33±16.15, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0017, mean_reward_over_100_episodes_from_eval 20.31±16.15
2025-12-30 02:40:29,372 | INFO | [default | seed 66] elapsed_time 00:15:01, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 20.11±16.07, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0016, mean_reward_over_100_episodes_from_eval 21.07±16.05
2025-12-30 02:41:18,407 | INFO | [default | seed 66] elapsed_time 00:15:50, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 20.85±15.99, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0016, mean_reward_over_100_episodes_from_eval 21.87±16.03
2025-12-30 02:42:04,282 | INFO | [default | seed 66] elapsed_time 00:16:36, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 21.60±15.96, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0016, mean_reward_over_100_episodes_from_eval 22.47±15.87
2025-12-30 02:42:50,983 | INFO | [default | seed 66] elapsed_time 00:17:23, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 22.24±15.87, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0016, mean_reward_over_100_episodes_from_eval 23.06±15.74
2025-12-30 02:43:38,630 | INFO | [default | seed 66] elapsed_time 00:18:10, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 22.85±15.78, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0016, mean_reward_over_100_episodes_from_eval 23.67±15.66
2025-12-30 02:44:28,074 | INFO | [default | seed 66] elapsed_time 00:19:00, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.41±15.68, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0016, mean_reward_over_100_episodes_from_eval 24.18±15.52
2025-12-30 02:45:17,683 | INFO | [default | seed 66] elapsed_time 00:19:49, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.89±15.54, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0016, mean_reward_over_100_episodes_from_eval 24.70±15.42
2025-12-30 02:46:07,343 | INFO | [default | seed 66] elapsed_time 00:20:39, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 24.28±15.37, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 25.11±15.26
2025-12-30 02:46:54,797 | INFO | [default | seed 66] elapsed_time 00:21:26, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 24.66±15.20, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 25.50±15.11
2025-12-30 02:47:42,123 | INFO | [default | seed 66] elapsed_time 00:22:14, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.05±15.06, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 25.93±15.00
2025-12-30 02:48:29,018 | INFO | [default | seed 66] elapsed_time 00:23:01, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 25.43±14.94, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 26.17±14.80
2025-12-30 02:49:15,152 | INFO | [default | seed 66] elapsed_time 00:23:47, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 25.76±14.79, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0014, mean_reward_over_100_episodes_from_eval 26.52±14.67
2025-12-30 02:50:01,638 | INFO | [default | seed 66] elapsed_time 00:24:33, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.07±14.65, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0014, mean_reward_over_100_episodes_from_eval 26.85±14.54
2025-12-30 02:50:48,533 | INFO | [default | seed 66] elapsed_time 00:25:20, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 26.31±14.48, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0014, mean_reward_over_100_episodes_from_eval 27.13±14.40
2025-12-30 02:51:36,433 | INFO | [default | seed 66] elapsed_time 00:26:08, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 26.54±14.32, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0015, mean_reward_over_100_episodes_from_eval 27.37±14.24
2025-12-30 02:52:24,398 | INFO | [default | seed 66] elapsed_time 00:26:56, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.80±14.19, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0015, mean_reward_over_100_episodes_from_eval 27.55±14.07
2025-12-30 02:53:12,509 | INFO | [default | seed 66] elapsed_time 00:27:44, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.93±14.00, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 27.63±13.87
2025-12-30 02:54:00,842 | INFO | [default | seed 66] elapsed_time 00:28:33, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.06±13.83, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0015, mean_reward_over_100_episodes_from_eval 27.84±13.73
2025-12-30 02:54:49,016 | INFO | [default | seed 66] elapsed_time 00:29:21, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.29±13.71, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0015, mean_reward_over_100_episodes_from_eval 28.11±13.65
2025-12-30 02:55:36,367 | INFO | [default | seed 66] elapsed_time 00:30:08, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.55±13.62, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0015, mean_reward_over_100_episodes_from_eval 28.38±13.56
2025-12-30 02:56:25,816 | INFO | [default | seed 66] elapsed_time 00:30:57, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.77±13.51, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0015, mean_reward_over_100_episodes_from_eval 28.61±13.47
2025-12-30 02:57:12,816 | INFO | [default | seed 66] elapsed_time 00:31:44, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.94±13.39, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0016, mean_reward_over_100_episodes_from_eval 28.75±13.32
2025-12-30 02:57:58,937 | INFO | [default | seed 66] elapsed_time 00:32:31, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.09±13.25, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0016, mean_reward_over_100_episodes_from_eval 28.85±13.18
2025-12-30 02:58:46,118 | INFO | [default | seed 66] elapsed_time 00:33:18, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.23±13.13, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0016, mean_reward_over_100_episodes_from_eval 28.97±13.04
2025-12-30 02:59:34,015 | INFO | [default | seed 66] elapsed_time 00:34:06, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.41±13.03, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0017, mean_reward_over_100_episodes_from_eval 29.17±12.95
2025-12-30 03:00:22,342 | INFO | [default | seed 66] elapsed_time 00:34:54, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.63±12.96, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0017, mean_reward_over_100_episodes_from_eval 29.36±12.87
2025-12-30 03:01:10,657 | INFO | [default | seed 66] elapsed_time 00:35:42, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.81±12.87, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0018, mean_reward_over_100_episodes_from_eval 29.47±12.74
2025-12-30 03:01:58,379 | INFO | [default | seed 66] elapsed_time 00:36:30, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.92±12.75, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0018, mean_reward_over_100_episodes_from_eval 29.54±12.61
2025-12-30 03:02:45,323 | INFO | [default | seed 66] elapsed_time 00:37:17, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.02±12.63, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0019, mean_reward_over_100_episodes_from_eval 29.67±12.51
2025-12-30 03:03:31,751 | INFO | [default | seed 66] elapsed_time 00:38:03, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.09±12.51, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0019, mean_reward_over_100_episodes_from_eval 29.68±12.38
2025-12-30 03:04:21,093 | INFO | [default | seed 66] elapsed_time 00:38:53, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.23±12.42, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0019, mean_reward_over_100_episodes_from_eval 29.81±12.28
2025-12-30 03:05:08,365 | INFO | [default | seed 66] elapsed_time 00:39:40, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.35±12.32, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0020, mean_reward_over_100_episodes_from_eval 29.92±12.18
2025-12-30 03:05:56,085 | INFO | [default | seed 66] elapsed_time 00:40:28, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.47±12.23, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0020, mean_reward_over_100_episodes_from_eval 30.04±12.09
2025-12-30 03:06:44,014 | INFO | [default | seed 66] elapsed_time 00:41:16, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.60±12.15, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0020, mean_reward_over_100_episodes_from_eval 30.19±12.02
2025-12-30 03:07:29,850 | INFO | [default | seed 66] elapsed_time 00:42:02, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.68±12.05, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0020, mean_reward_over_100_episodes_from_eval 30.27±11.92
2025-12-30 03:08:16,495 | INFO | [default | seed 66] elapsed_time 00:42:48, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.78±11.96, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0021, mean_reward_over_100_episodes_from_eval 30.37±11.84
2025-12-30 03:09:02,108 | INFO | [default | seed 66] elapsed_time 00:43:34, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.88±11.87, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0021, mean_reward_over_100_episodes_from_eval 30.43±11.74
2025-12-30 03:09:50,426 | INFO | [default | seed 66] elapsed_time 00:44:22, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.98±11.79, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0021, mean_reward_over_100_episodes_from_eval 30.56±11.67
2025-12-30 03:10:36,513 | INFO | [default | seed 66] elapsed_time 00:45:08, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.05±11.69, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0021, mean_reward_over_100_episodes_from_eval 30.59±11.57
2025-12-30 03:11:23,527 | INFO | [default | seed 66] elapsed_time 00:45:55, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.16±11.62, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0021, mean_reward_over_100_episodes_from_eval 30.64±11.48
2025-12-30 03:12:09,979 | INFO | [default | seed 66] elapsed_time 00:46:42, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.25±11.55, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0021, mean_reward_over_100_episodes_from_eval 30.74±11.41
2025-12-30 03:12:58,976 | INFO | [default | seed 66] elapsed_time 00:47:31, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 30.28±11.45, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0021, mean_reward_over_100_episodes_from_eval 30.77±11.32
2025-12-30 03:13:48,159 | INFO | [default | seed 66] elapsed_time 00:48:20, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 30.35±11.37, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 30.85±11.24
2025-12-30 03:14:39,410 | INFO | [default | seed 66] elapsed_time 00:49:11, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 30.42±11.29, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 30.95±11.18
2025-12-30 03:15:27,410 | INFO | [default | seed 66] elapsed_time 00:49:59, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.52±11.23, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 31.04±11.11
2025-12-30 03:16:16,398 | INFO | [default | seed 66] elapsed_time 00:50:48, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.56±11.15, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0021, mean_reward_over_100_episodes_from_eval 31.10±11.03
2025-12-30 03:17:04,716 | INFO | [default | seed 66] elapsed_time 00:51:36, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.66±11.09, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0021, mean_reward_over_100_episodes_from_eval 31.18±10.96
2025-12-30 03:17:52,061 | INFO | [default | seed 66] elapsed_time 00:52:24, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.74±11.02, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0021, mean_reward_over_100_episodes_from_eval 31.27±10.91
2025-12-30 03:18:40,204 | INFO | [default | seed 66] elapsed_time 00:53:12, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.79±10.95, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0022, mean_reward_over_100_episodes_from_eval 31.30±10.83
2025-12-30 03:19:27,474 | INFO | [default | seed 66] elapsed_time 00:53:59, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.82±10.87, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0022, mean_reward_over_100_episodes_from_eval 31.33±10.75
2025-12-30 03:20:14,421 | INFO | [default | seed 66] elapsed_time 00:54:46, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.84±10.79, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0022, mean_reward_over_100_episodes_from_eval 31.35±10.67
2025-12-30 03:21:00,856 | INFO | [default | seed 66] elapsed_time 00:55:33, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.91±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0022, mean_reward_over_100_episodes_from_eval 31.42±10.61
2025-12-30 03:21:47,728 | INFO | [default | seed 66] elapsed_time 00:56:19, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 30.98±10.67, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0022, mean_reward_over_100_episodes_from_eval 31.46±10.54
2025-12-30 03:22:34,097 | INFO | [default | seed 66] elapsed_time 00:57:06, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 31.04±10.61, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0022, mean_reward_over_100_episodes_from_eval 31.48±10.47
2025-12-30 03:23:22,043 | INFO | [default | seed 66] elapsed_time 00:57:54, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 31.09±10.54, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0022, mean_reward_over_100_episodes_from_eval 31.58±10.43
2025-12-30 03:24:10,274 | INFO | [default | seed 66] elapsed_time 00:58:42, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 31.13±10.48, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0022, mean_reward_over_100_episodes_from_eval 31.60±10.36
2025-12-30 03:24:57,038 | INFO | [default | seed 66] elapsed_time 00:59:29, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 31.22±10.44, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 31.69±10.32
2025-12-30 03:25:45,011 | INFO | [default | seed 66] elapsed_time 01:00:17, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 31.30±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 31.73±10.26
2025-12-30 03:26:33,752 | INFO | [default | seed 66] elapsed_time 01:01:05, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 31.35±10.33, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 31.82±10.22
2025-12-30 03:27:21,311 | INFO | [default | seed 66] elapsed_time 01:01:53, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 31.41±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 31.88±10.17
2025-12-30 03:28:09,159 | INFO | [default | seed 66] elapsed_time 01:02:41, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 31.46±10.22, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 31.94±10.12
2025-12-30 03:28:58,783 | INFO | [default | seed 66] elapsed_time 01:03:30, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 31.50±10.17, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 32.01±10.08
2025-12-30 03:29:48,639 | INFO | [default | seed 66] elapsed_time 01:04:20, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 31.56±10.12, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 32.05±10.02
2025-12-30 03:30:36,142 | INFO | [default | seed 66] elapsed_time 01:05:08, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 31.62±10.07, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 32.12±09.98
2025-12-30 03:31:24,178 | INFO | [default | seed 66] elapsed_time 01:05:56, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 31.68±10.02, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 32.18±09.93
2025-12-30 03:32:12,485 | INFO | [default | seed 66] elapsed_time 01:06:44, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 31.76±09.99, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 32.19±09.88
2025-12-30 03:33:00,225 | INFO | [default | seed 66] elapsed_time 01:07:32, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 31.76±09.93, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 32.24±09.83
2025-12-30 03:33:49,343 | INFO | [default | seed 66] elapsed_time 01:08:21, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 31.78±09.88, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 32.26±09.77
2025-12-30 03:34:36,845 | INFO | [default | seed 66] elapsed_time 01:09:09, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 31.82±09.83, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 32.28±09.72
2025-12-30 03:35:25,366 | INFO | [default | seed 66] elapsed_time 01:09:57, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 31.88±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 32.35±09.69
2025-12-30 03:36:13,012 | INFO | [default | seed 66] elapsed_time 01:10:45, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 31.95±09.75, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 32.38±09.64
2025-12-30 03:37:01,054 | INFO | [default | seed 66] elapsed_time 01:11:33, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 32.02±09.72, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 32.44±09.60
2025-12-30 03:37:48,654 | INFO | [default | seed 66] elapsed_time 01:12:20, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 32.06±09.67, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 32.49±09.56
2025-12-30 03:38:35,618 | INFO | [default | seed 66] elapsed_time 01:13:07, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 32.06±09.62, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 32.45±09.51
2025-12-30 03:39:23,904 | INFO | [default | seed 66] elapsed_time 01:13:56, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 32.09±09.58, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 32.53±09.49
2025-12-30 03:40:12,626 | INFO | [default | seed 66] elapsed_time 01:14:44, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 32.16±09.54, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 32.53±09.44
2025-12-30 03:41:00,625 | INFO | [default | seed 66] elapsed_time 01:15:32, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 32.17±09.49, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 32.56±09.39
2025-12-30 03:41:48,590 | INFO | [default | seed 66] elapsed_time 01:16:20, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 32.18±09.45, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 32.58±09.35
2025-12-30 03:42:35,506 | INFO | [default | seed 66] elapsed_time 01:17:07, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 32.22±09.40, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 32.58±09.30
2025-12-30 03:43:24,491 | INFO | [default | seed 66] elapsed_time 01:17:56, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 32.23±09.36, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0022, mean_reward_over_100_episodes_from_eval 32.63±09.27
2025-12-30 03:44:12,331 | INFO | [default | seed 66] elapsed_time 01:18:44, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 32.26±09.31, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0022, mean_reward_over_100_episodes_from_eval 32.62±09.22
2025-12-30 03:44:58,607 | INFO | [default | seed 66] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=32.64
2025-12-30 03:44:58,608 | INFO | [default | seed 66] elapsed_time 01:19:30, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 32.27±09.27, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0022, mean_reward_over_100_episodes_from_eval 32.64±09.17
2025-12-30 03:44:58,608 | INFO | [default | seed 66] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 04:10:14,158 | INFO | [default | seed 66] Training complete.
2025-12-30 04:10:14,159 | INFO | [default | seed 66] Solved (evaluation metric) at episode 100.
2025-12-30 04:10:14,159 | INFO | [default | seed 66] Final evaluation score 34.96±0.83 in 3274.10s training, 6286.33s wall.
2025-12-30 04:10:14,159 | INFO | [default | seed 66] Closing UnityVectorEnv (worker_id=66).
2025-12-30 04:10:14,159 | INFO | [Main] Requesting worker 66 to close Unity env.
2025-12-30 04:10:14,603 | INFO | [Main] Worker 66 joined. Unity env fully closed.
2025-12-30 04:10:14,603 | INFO | [default | seed 66] Final eval score: 34.96
2025-12-30 04:10:14,815 | INFO | [default | seed 66] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_66.png
2025-12-30 04:10:14,816 | INFO | [default | seed 66] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 04:10:14,944 | INFO | [default | seed 39] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 04:10:14,945 | INFO | [default | seed 39] === Starting run for seed 39 ===
2025-12-30 04:10:14,945 | INFO | [default | seed 39] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 04:10:14,945 | INFO | [default | seed 39] Launching UnityVectorEnv with worker_id=39, seed=39
2025-12-30 04:10:14,945 | INFO | [Main] Spawning worker 39 for Unity env (seed=39). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 04:10:14,961 | INFO | [Main] Worker 39 started (pid=87116).
2025-12-30 04:10:18,569 | INFO | [default | seed 39] Environment batched agents (train): 20
2025-12-30 04:10:46,372 | INFO | [default | seed 39] Environment batched agents (eval): 20
2025-12-30 04:11:01,128 | INFO | [default | seed 39] elapsed_time 00:00:46, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 08.080000, episode_sum_max_abs_reward_per_step 08.080000, mean_reward_over_100_episodes_from_training 00.50±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0000, mean_reward_over_100_episodes_from_eval 00.10±00.00
2025-12-30 04:11:47,930 | INFO | [default | seed 39] elapsed_time 00:01:32, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 04.940000, episode_sum_max_abs_reward_per_step 04.940000, mean_reward_over_100_episodes_from_training 00.39±00.11, mean_exploration_ratio_over_100_episodes_from_training 0.0123±0.0007, mean_reward_over_100_episodes_from_eval 00.47±00.38
2025-12-30 04:12:32,601 | INFO | [default | seed 39] elapsed_time 00:02:17, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 15.460000, episode_sum_max_abs_reward_per_step 15.460000, mean_reward_over_100_episodes_from_training 00.58±00.28, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0009, mean_reward_over_100_episodes_from_eval 00.55±00.33
2025-12-30 04:13:18,235 | INFO | [default | seed 39] elapsed_time 00:03:03, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 14.120000, episode_sum_max_abs_reward_per_step 14.120000, mean_reward_over_100_episodes_from_training 00.65±00.27, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0008, mean_reward_over_100_episodes_from_eval 00.58±00.29
2025-12-30 04:14:05,018 | INFO | [default | seed 39] elapsed_time 00:03:50, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 11.170000, episode_sum_max_abs_reward_per_step 11.170000, mean_reward_over_100_episodes_from_training 00.65±00.24, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 00.56±00.26
2025-12-30 04:14:52,461 | INFO | [default | seed 39] elapsed_time 00:04:37, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 11.570000, episode_sum_max_abs_reward_per_step 11.570000, mean_reward_over_100_episodes_from_training 00.67±00.22, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0009, mean_reward_over_100_episodes_from_eval 00.63±00.30
2025-12-30 04:15:38,757 | INFO | [default | seed 39] elapsed_time 00:05:23, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 22.100000, episode_sum_max_abs_reward_per_step 22.100000, mean_reward_over_100_episodes_from_training 00.85±00.48, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0009, mean_reward_over_100_episodes_from_eval 01.01±00.96
2025-12-30 04:16:26,666 | INFO | [default | seed 39] elapsed_time 00:06:11, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 32.219999, episode_sum_max_abs_reward_per_step 32.219999, mean_reward_over_100_episodes_from_training 01.21±01.05, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0010, mean_reward_over_100_episodes_from_eval 01.26±01.12
2025-12-30 04:17:13,231 | INFO | [default | seed 39] elapsed_time 00:06:58, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 33.759999, episode_sum_max_abs_reward_per_step 33.759999, mean_reward_over_100_episodes_from_training 01.44±01.19, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0010, mean_reward_over_100_episodes_from_eval 01.73±01.69
2025-12-30 04:17:59,572 | INFO | [default | seed 39] elapsed_time 00:07:44, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 37.309999, episode_sum_max_abs_reward_per_step 37.309999, mean_reward_over_100_episodes_from_training 01.87±01.72, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0009, mean_reward_over_100_episodes_from_eval 02.42±02.64
2025-12-30 04:18:46,298 | INFO | [default | seed 39] elapsed_time 00:08:31, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 02.53±02.65, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0009, mean_reward_over_100_episodes_from_eval 03.31±03.76
2025-12-30 04:19:32,345 | INFO | [default | seed 39] elapsed_time 00:09:17, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 03.68±04.57, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 04.58±05.54
2025-12-30 04:20:18,982 | INFO | [default | seed 39] elapsed_time 00:10:04, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 05.38±07.36, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 06.23±07.81
2025-12-30 04:21:05,993 | INFO | [default | seed 39] elapsed_time 00:10:51, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 07.27±09.84, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0017, mean_reward_over_100_episodes_from_eval 08.17±10.27
2025-12-30 04:21:55,620 | INFO | [default | seed 39] elapsed_time 00:11:40, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 09.16±11.85, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0020, mean_reward_over_100_episodes_from_eval 10.15±12.40
2025-12-30 04:22:44,177 | INFO | [default | seed 39] elapsed_time 00:12:29, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 10.86±13.23, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0022, mean_reward_over_100_episodes_from_eval 11.73±13.48
2025-12-30 04:23:31,792 | INFO | [default | seed 39] elapsed_time 00:13:16, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 12.41±14.25, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0022, mean_reward_over_100_episodes_from_eval 13.32±14.53
2025-12-30 04:24:19,178 | INFO | [default | seed 39] elapsed_time 00:14:04, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 13.74±14.90, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0023, mean_reward_over_100_episodes_from_eval 14.67±15.17
2025-12-30 04:25:05,634 | INFO | [default | seed 39] elapsed_time 00:14:50, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 15.01±15.47, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0023, mean_reward_over_100_episodes_from_eval 15.78±15.50
2025-12-30 04:25:52,779 | INFO | [default | seed 39] elapsed_time 00:15:37, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 16.11±15.82, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0023, mean_reward_over_100_episodes_from_eval 16.87±15.84
2025-12-30 04:26:41,695 | INFO | [default | seed 39] elapsed_time 00:16:26, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 17.00±15.94, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0023, mean_reward_over_100_episodes_from_eval 17.79±16.00
2025-12-30 04:27:29,555 | INFO | [default | seed 39] elapsed_time 00:17:14, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 17.86±16.07, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0023, mean_reward_over_100_episodes_from_eval 18.54±16.00
2025-12-30 04:28:17,437 | INFO | [default | seed 39] elapsed_time 00:18:02, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 18.60±16.09, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0023, mean_reward_over_100_episodes_from_eval 19.30±16.05
2025-12-30 04:29:04,541 | INFO | [default | seed 39] elapsed_time 00:18:49, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 19.29±16.10, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0023, mean_reward_over_100_episodes_from_eval 19.93±16.00
2025-12-30 04:29:52,092 | INFO | [default | seed 39] elapsed_time 00:19:37, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 19.98±16.13, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0023, mean_reward_over_100_episodes_from_eval 20.55±15.97
2025-12-30 04:30:40,551 | INFO | [default | seed 39] elapsed_time 00:20:25, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 20.51±16.04, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0023, mean_reward_over_100_episodes_from_eval 21.10±15.90
2025-12-30 04:31:29,261 | INFO | [default | seed 39] elapsed_time 00:21:14, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 21.03±15.96, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0022, mean_reward_over_100_episodes_from_eval 21.55±15.77
2025-12-30 04:32:17,084 | INFO | [default | seed 39] elapsed_time 00:22:02, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.47±15.84, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0022, mean_reward_over_100_episodes_from_eval 21.93±15.61
2025-12-30 04:33:03,894 | INFO | [default | seed 39] elapsed_time 00:22:48, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 21.80±15.66, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0021, mean_reward_over_100_episodes_from_eval 22.31±15.47
2025-12-30 04:33:53,077 | INFO | [default | seed 39] elapsed_time 00:23:38, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 22.17±15.53, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0021, mean_reward_over_100_episodes_from_eval 22.80±15.44
2025-12-30 04:34:39,943 | INFO | [default | seed 39] elapsed_time 00:24:24, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.65±15.50, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0021, mean_reward_over_100_episodes_from_eval 23.17±15.32
2025-12-30 04:35:27,714 | INFO | [default | seed 39] elapsed_time 00:25:12, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.01±15.38, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0020, mean_reward_over_100_episodes_from_eval 23.42±15.15
2025-12-30 04:36:17,474 | INFO | [default | seed 39] elapsed_time 00:26:02, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 23.39±15.30, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0020, mean_reward_over_100_episodes_from_eval 23.81±15.07
2025-12-30 04:37:04,857 | INFO | [default | seed 39] elapsed_time 00:26:49, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 23.70±15.18, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0020, mean_reward_over_100_episodes_from_eval 24.06±14.92
2025-12-30 04:37:53,015 | INFO | [default | seed 39] elapsed_time 00:27:38, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 23.95±15.03, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0020, mean_reward_over_100_episodes_from_eval 24.38±14.82
2025-12-30 04:38:40,637 | INFO | [default | seed 39] elapsed_time 00:28:25, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.12±14.86, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0020, mean_reward_over_100_episodes_from_eval 24.50±14.63
2025-12-30 04:39:28,292 | INFO | [default | seed 39] elapsed_time 00:29:13, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 24.32±14.70, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0020, mean_reward_over_100_episodes_from_eval 24.83±14.57
2025-12-30 04:40:16,362 | INFO | [default | seed 39] elapsed_time 00:30:01, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 24.53±14.57, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0020, mean_reward_over_100_episodes_from_eval 25.08±14.46
2025-12-30 04:41:03,403 | INFO | [default | seed 39] elapsed_time 00:30:48, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 24.75±14.44, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0020, mean_reward_over_100_episodes_from_eval 25.30±14.33
2025-12-30 04:41:50,510 | INFO | [default | seed 39] elapsed_time 00:31:35, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 24.92±14.30, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0020, mean_reward_over_100_episodes_from_eval 25.52±14.22
2025-12-30 04:42:38,751 | INFO | [default | seed 39] elapsed_time 00:32:23, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 25.14±14.19, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0020, mean_reward_over_100_episodes_from_eval 25.75±14.12
2025-12-30 04:43:25,585 | INFO | [default | seed 39] elapsed_time 00:33:10, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.39±14.11, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0020, mean_reward_over_100_episodes_from_eval 25.95±14.01
2025-12-30 04:44:15,514 | INFO | [default | seed 39] elapsed_time 00:34:00, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.54±13.98, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0020, mean_reward_over_100_episodes_from_eval 26.17±13.92
2025-12-30 04:45:09,283 | INFO | [default | seed 39] elapsed_time 00:34:54, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 25.70±13.86, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0020, mean_reward_over_100_episodes_from_eval 26.40±13.84
2025-12-30 04:46:01,211 | INFO | [default | seed 39] elapsed_time 00:35:46, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.91±13.78, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0020, mean_reward_over_100_episodes_from_eval 26.59±13.74
2025-12-30 04:47:14,763 | INFO | [default | seed 39] elapsed_time 00:36:59, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.09±13.68, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0021, mean_reward_over_100_episodes_from_eval 26.73±13.63
2025-12-30 04:48:21,347 | INFO | [default | seed 39] elapsed_time 00:38:06, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.23±13.57, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0020, mean_reward_over_100_episodes_from_eval 26.83±13.50
2025-12-30 04:49:21,031 | INFO | [default | seed 39] elapsed_time 00:39:06, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.36±13.45, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0021, mean_reward_over_100_episodes_from_eval 27.06±13.45
2025-12-30 04:50:21,486 | INFO | [default | seed 39] elapsed_time 00:40:06, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.52±13.36, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 27.20±13.35
2025-12-30 04:51:30,558 | INFO | [default | seed 39] elapsed_time 00:41:15, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 26.69±13.28, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 27.40±13.29
2025-12-30 04:52:51,730 | INFO | [default | seed 39] elapsed_time 00:42:36, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.83±13.19, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0021, mean_reward_over_100_episodes_from_eval 27.47±13.16
2025-12-30 04:54:16,086 | INFO | [default | seed 39] elapsed_time 00:44:01, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.95±13.09, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0021, mean_reward_over_100_episodes_from_eval 27.63±13.09
2025-12-30 04:55:18,047 | INFO | [default | seed 39] elapsed_time 00:45:03, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 27.14±13.04, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0022, mean_reward_over_100_episodes_from_eval 27.82±13.04
2025-12-30 04:56:18,879 | INFO | [default | seed 39] elapsed_time 00:46:03, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.33±12.99, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0022, mean_reward_over_100_episodes_from_eval 28.03±13.00
2025-12-30 04:57:22,009 | INFO | [default | seed 39] elapsed_time 00:47:07, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.48±12.92, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0022, mean_reward_over_100_episodes_from_eval 28.16±12.92
2025-12-30 04:58:27,883 | INFO | [default | seed 39] elapsed_time 00:48:12, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.54±12.81, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0022, mean_reward_over_100_episodes_from_eval 28.28±12.83
2025-12-30 04:59:27,398 | INFO | [default | seed 39] elapsed_time 00:49:12, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.64±12.72, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0022, mean_reward_over_100_episodes_from_eval 28.42±12.77
2025-12-30 05:00:27,344 | INFO | [default | seed 39] elapsed_time 00:50:12, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.80±12.67, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0022, mean_reward_over_100_episodes_from_eval 28.56±12.70
2025-12-30 05:01:29,411 | INFO | [default | seed 39] elapsed_time 00:51:14, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.93±12.60, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0022, mean_reward_over_100_episodes_from_eval 28.68±12.63
2025-12-30 05:02:30,873 | INFO | [default | seed 39] elapsed_time 00:52:15, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.06±12.54, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0022, mean_reward_over_100_episodes_from_eval 28.81±12.56
2025-12-30 05:03:30,518 | INFO | [default | seed 39] elapsed_time 00:53:15, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.16±12.45, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0023, mean_reward_over_100_episodes_from_eval 28.90±12.47
2025-12-30 05:04:51,101 | INFO | [default | seed 39] elapsed_time 00:54:36, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.26±12.38, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0023, mean_reward_over_100_episodes_from_eval 28.98±12.39
2025-12-30 05:05:50,013 | INFO | [default | seed 39] elapsed_time 00:55:35, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 28.38±12.32, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0023, mean_reward_over_100_episodes_from_eval 29.09±12.32
2025-12-30 05:06:48,606 | INFO | [default | seed 39] elapsed_time 00:56:33, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.46±12.24, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0023, mean_reward_over_100_episodes_from_eval 29.15±12.23
2025-12-30 05:07:46,596 | INFO | [default | seed 39] elapsed_time 00:57:31, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.53±12.15, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0023, mean_reward_over_100_episodes_from_eval 29.29±12.19
2025-12-30 05:08:45,921 | INFO | [default | seed 39] elapsed_time 00:58:30, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.65±12.10, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0023, mean_reward_over_100_episodes_from_eval 29.41±12.14
2025-12-30 05:09:46,208 | INFO | [default | seed 39] elapsed_time 00:59:31, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.77±12.05, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0023, mean_reward_over_100_episodes_from_eval 29.53±12.09
2025-12-30 05:10:49,043 | INFO | [default | seed 39] elapsed_time 01:00:34, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.88±12.00, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0023, mean_reward_over_100_episodes_from_eval 29.65±12.04
2025-12-30 05:11:55,903 | INFO | [default | seed 39] elapsed_time 01:01:40, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.99±11.94, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0023, mean_reward_over_100_episodes_from_eval 29.74±11.97
2025-12-30 05:12:54,776 | INFO | [default | seed 39] elapsed_time 01:02:39, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 29.10±11.89, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0023, mean_reward_over_100_episodes_from_eval 29.84±11.91
2025-12-30 05:14:02,470 | INFO | [default | seed 39] elapsed_time 01:03:47, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.21±11.84, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0024, mean_reward_over_100_episodes_from_eval 29.79±11.84
2025-12-30 05:15:06,858 | INFO | [default | seed 39] elapsed_time 01:04:51, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.25±11.77, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0024, mean_reward_over_100_episodes_from_eval 29.90±11.80
2025-12-30 05:16:07,667 | INFO | [default | seed 39] elapsed_time 01:05:52, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 29.36±11.73, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0024, mean_reward_over_100_episodes_from_eval 30.02±11.76
2025-12-30 05:17:06,766 | INFO | [default | seed 39] elapsed_time 01:06:51, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.48±11.69, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0024, mean_reward_over_100_episodes_from_eval 30.12±11.71
2025-12-30 05:18:15,330 | INFO | [default | seed 39] elapsed_time 01:08:00, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.58±11.64, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0024, mean_reward_over_100_episodes_from_eval 30.22±11.67
2025-12-30 05:19:15,311 | INFO | [default | seed 39] elapsed_time 01:09:00, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.67±11.59, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0024, mean_reward_over_100_episodes_from_eval 30.31±11.61
2025-12-30 05:20:14,720 | INFO | [default | seed 39] elapsed_time 01:09:59, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.78±11.55, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0024, mean_reward_over_100_episodes_from_eval 30.41±11.57
2025-12-30 05:21:14,579 | INFO | [default | seed 39] elapsed_time 01:10:59, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 29.88±11.51, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0024, mean_reward_over_100_episodes_from_eval 30.49±11.52
2025-12-30 05:22:13,526 | INFO | [default | seed 39] elapsed_time 01:11:58, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.95±11.46, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0024, mean_reward_over_100_episodes_from_eval 30.54±11.45
2025-12-30 05:23:11,315 | INFO | [default | seed 39] elapsed_time 01:12:56, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.02±11.40, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0024, mean_reward_over_100_episodes_from_eval 30.63±11.41
2025-12-30 05:24:10,144 | INFO | [default | seed 39] elapsed_time 01:13:55, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.11±11.36, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0024, mean_reward_over_100_episodes_from_eval 30.65±11.34
2025-12-30 05:25:08,999 | INFO | [default | seed 39] elapsed_time 01:14:54, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 30.18±11.31, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0024, mean_reward_over_100_episodes_from_eval 30.68±11.27
2025-12-30 05:26:06,923 | INFO | [default | seed 39] elapsed_time 01:15:51, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.20±11.24, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0024, mean_reward_over_100_episodes_from_eval 30.71±11.21
2025-12-30 05:27:04,823 | INFO | [default | seed 39] elapsed_time 01:16:49, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.23±11.18, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0024, mean_reward_over_100_episodes_from_eval 30.69±11.14
2025-12-30 05:28:02,380 | INFO | [default | seed 39] elapsed_time 01:17:47, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.28±11.12, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0024, mean_reward_over_100_episodes_from_eval 30.75±11.09
2025-12-30 05:29:00,473 | INFO | [default | seed 39] elapsed_time 01:18:45, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.32±11.06, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0024, mean_reward_over_100_episodes_from_eval 30.79±11.03
2025-12-30 05:29:58,988 | INFO | [default | seed 39] elapsed_time 01:19:44, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.35±11.00, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0024, mean_reward_over_100_episodes_from_eval 30.85±10.98
2025-12-30 05:30:56,938 | INFO | [default | seed 39] elapsed_time 01:20:41, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.41±10.95, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0024, mean_reward_over_100_episodes_from_eval 30.93±10.94
2025-12-30 05:31:54,406 | INFO | [default | seed 39] elapsed_time 01:21:39, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.44±10.90, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0024, mean_reward_over_100_episodes_from_eval 30.98±10.89
2025-12-30 05:32:50,710 | INFO | [default | seed 39] elapsed_time 01:22:35, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.52±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0024, mean_reward_over_100_episodes_from_eval 31.05±10.85
2025-12-30 05:33:50,319 | INFO | [default | seed 39] elapsed_time 01:23:35, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.59±10.82, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0024, mean_reward_over_100_episodes_from_eval 31.13±10.82
2025-12-30 05:34:48,797 | INFO | [default | seed 39] elapsed_time 01:24:33, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.66±10.78, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0024, mean_reward_over_100_episodes_from_eval 31.16±10.76
2025-12-30 05:35:46,818 | INFO | [default | seed 39] elapsed_time 01:25:31, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.69±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0024, mean_reward_over_100_episodes_from_eval 31.21±10.72
2025-12-30 05:36:45,801 | INFO | [default | seed 39] elapsed_time 01:26:30, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 30.74±10.68, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0024, mean_reward_over_100_episodes_from_eval 31.24±10.66
2025-12-30 05:37:42,855 | INFO | [default | seed 39] elapsed_time 01:27:27, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.79±10.63, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0024, mean_reward_over_100_episodes_from_eval 31.26±10.61
2025-12-30 05:38:41,539 | INFO | [default | seed 39] elapsed_time 01:28:26, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 30.86±10.60, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0024, mean_reward_over_100_episodes_from_eval 31.32±10.57
2025-12-30 05:39:39,793 | INFO | [default | seed 39] elapsed_time 01:29:24, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 30.92±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0024, mean_reward_over_100_episodes_from_eval 31.39±10.53
2025-12-30 05:40:36,904 | INFO | [default | seed 39] elapsed_time 01:30:21, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.98±10.53, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0024, mean_reward_over_100_episodes_from_eval 31.46±10.51
2025-12-30 05:41:35,333 | INFO | [default | seed 39] elapsed_time 01:31:20, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 31.03±10.49, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0024, mean_reward_over_100_episodes_from_eval 31.42±10.46
2025-12-30 05:42:33,033 | INFO | [default | seed 39] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=31.44
2025-12-30 05:42:33,035 | INFO | [default | seed 39] elapsed_time 01:32:18, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 31.06±10.44, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0024, mean_reward_over_100_episodes_from_eval 31.44±10.41
2025-12-30 05:42:33,035 | INFO | [default | seed 39] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 06:11:41,632 | INFO | [default | seed 39] Training complete.
2025-12-30 06:11:41,632 | INFO | [default | seed 39] Solved (evaluation metric) at episode 100.
2025-12-30 06:11:41,632 | INFO | [default | seed 39] Final evaluation score 33.11±1.38 in 3762.31s training, 7286.69s wall.
2025-12-30 06:11:41,632 | INFO | [default | seed 39] Closing UnityVectorEnv (worker_id=39).
2025-12-30 06:11:41,633 | INFO | [Main] Requesting worker 39 to close Unity env.
2025-12-30 06:11:42,767 | INFO | [Main] Worker 39 joined. Unity env fully closed.
2025-12-30 06:11:42,767 | INFO | [default | seed 39] Final eval score: 33.11
2025-12-30 06:11:43,101 | INFO | [default | seed 39] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_39.png
2025-12-30 06:11:43,102 | INFO | [default | seed 39] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 06:11:43,283 | INFO | [default | seed 8] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 06:11:43,283 | INFO | [default | seed 8] === Starting run for seed 8 ===
2025-12-30 06:11:43,283 | INFO | [default | seed 8] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 06:11:43,283 | INFO | [default | seed 8] Launching UnityVectorEnv with worker_id=8, seed=8
2025-12-30 06:11:43,283 | INFO | [Main] Spawning worker 8 for Unity env (seed=8). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 06:11:43,310 | INFO | [Main] Worker 8 started (pid=72380).
2025-12-30 06:11:47,625 | INFO | [default | seed 8] Environment batched agents (train): 20
2025-12-30 06:12:19,764 | INFO | [default | seed 8] Environment batched agents (eval): 20
2025-12-30 06:12:36,388 | INFO | [default | seed 8] elapsed_time 00:00:53, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 11.810000, episode_sum_max_abs_reward_per_step 11.810000, mean_reward_over_100_episodes_from_training 00.74±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0000, mean_reward_over_100_episodes_from_eval 01.27±00.00
2025-12-30 06:13:29,376 | INFO | [default | seed 8] elapsed_time 00:01:46, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 16.740000, episode_sum_max_abs_reward_per_step 16.740000, mean_reward_over_100_episodes_from_training 00.97±00.22, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0002, mean_reward_over_100_episodes_from_eval 01.13±00.14
2025-12-30 06:14:24,150 | INFO | [default | seed 8] elapsed_time 00:02:40, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 20.380000, episode_sum_max_abs_reward_per_step 20.380000, mean_reward_over_100_episodes_from_training 01.11±00.27, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0008, mean_reward_over_100_episodes_from_eval 01.16±00.13
2025-12-30 06:15:19,256 | INFO | [default | seed 8] elapsed_time 00:03:35, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 16.920000, episode_sum_max_abs_reward_per_step 16.920000, mean_reward_over_100_episodes_from_training 01.12±00.24, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0011, mean_reward_over_100_episodes_from_eval 01.24±00.18
2025-12-30 06:16:15,436 | INFO | [default | seed 8] elapsed_time 00:04:32, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 25.729999, episode_sum_max_abs_reward_per_step 25.729999, mean_reward_over_100_episodes_from_training 01.35±00.50, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0011, mean_reward_over_100_episodes_from_eval 01.54±00.62
2025-12-30 06:17:11,956 | INFO | [default | seed 8] elapsed_time 00:05:28, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 34.499999, episode_sum_max_abs_reward_per_step 34.499999, mean_reward_over_100_episodes_from_training 01.85±01.21, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 01.86±00.91
2025-12-30 06:18:09,052 | INFO | [default | seed 8] elapsed_time 00:06:25, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 34.729999, episode_sum_max_abs_reward_per_step 34.729999, mean_reward_over_100_episodes_from_training 02.23±01.46, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 02.36±01.48
2025-12-30 06:19:05,698 | INFO | [default | seed 8] elapsed_time 00:07:22, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 03.16±02.82, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 03.61±03.58
2025-12-30 06:20:03,572 | INFO | [default | seed 8] elapsed_time 00:08:20, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 04.59±04.83, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 04.84±04.86
2025-12-30 06:21:02,360 | INFO | [default | seed 8] elapsed_time 00:09:19, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 05.61±05.51, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 06.14±06.03
2025-12-30 06:21:59,140 | INFO | [default | seed 8] elapsed_time 00:10:15, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 06.87±06.59, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 07.83±07.85
2025-12-30 06:22:55,796 | INFO | [default | seed 8] elapsed_time 00:11:12, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 08.37±08.03, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 09.52±09.38
2025-12-30 06:23:52,838 | INFO | [default | seed 8] elapsed_time 00:12:09, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 10.09±09.76, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0011, mean_reward_over_100_episodes_from_eval 11.16±10.65
2025-12-30 06:24:50,787 | INFO | [default | seed 8] elapsed_time 00:13:07, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 11.50±10.68, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0013, mean_reward_over_100_episodes_from_eval 12.33±11.10
2025-12-30 06:25:47,869 | INFO | [default | seed 8] elapsed_time 00:14:04, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 12.68±11.23, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 13.69±11.87
2025-12-30 06:26:46,413 | INFO | [default | seed 8] elapsed_time 00:15:03, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 13.93±11.91, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0014, mean_reward_over_100_episodes_from_eval 14.74±12.18
2025-12-30 06:27:44,513 | INFO | [default | seed 8] elapsed_time 00:16:01, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 14.91±12.19, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 15.63±12.35
2025-12-30 06:28:41,629 | INFO | [default | seed 8] elapsed_time 00:16:58, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 15.91±12.54, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 16.49±12.52
2025-12-30 06:29:38,148 | INFO | [default | seed 8] elapsed_time 00:17:54, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 16.90±12.91, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0015, mean_reward_over_100_episodes_from_eval 17.30±12.66
2025-12-30 06:30:34,027 | INFO | [default | seed 8] elapsed_time 00:18:50, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 17.79±13.18, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0016, mean_reward_over_100_episodes_from_eval 18.16±12.89
2025-12-30 06:31:31,640 | INFO | [default | seed 8] elapsed_time 00:19:48, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 18.51±13.25, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 18.96±13.09
2025-12-30 06:32:28,774 | INFO | [default | seed 8] elapsed_time 00:20:45, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 19.23±13.36, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 19.70±13.23
2025-12-30 06:33:26,232 | INFO | [default | seed 8] elapsed_time 00:21:42, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 19.94±13.48, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 20.29±13.22
2025-12-30 06:34:23,859 | INFO | [default | seed 8] elapsed_time 00:22:40, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 20.55±13.52, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0015, mean_reward_over_100_episodes_from_eval 20.95±13.33
2025-12-30 06:35:21,374 | INFO | [default | seed 8] elapsed_time 00:23:38, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 21.11±13.53, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0014, mean_reward_over_100_episodes_from_eval 21.49±13.32
2025-12-30 06:36:19,154 | INFO | [default | seed 8] elapsed_time 00:24:35, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 21.63±13.52, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0014, mean_reward_over_100_episodes_from_eval 22.00±13.31
2025-12-30 06:37:15,989 | INFO | [default | seed 8] elapsed_time 00:25:32, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 22.15±13.53, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0014, mean_reward_over_100_episodes_from_eval 22.55±13.36
2025-12-30 06:38:12,922 | INFO | [default | seed 8] elapsed_time 00:26:29, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.59±13.48, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0014, mean_reward_over_100_episodes_from_eval 22.98±13.31
2025-12-30 06:39:09,166 | INFO | [default | seed 8] elapsed_time 00:27:25, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 22.99±13.41, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 23.41±13.27
2025-12-30 06:40:08,151 | INFO | [default | seed 8] elapsed_time 00:28:24, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.34±13.32, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0014, mean_reward_over_100_episodes_from_eval 23.85±13.26
2025-12-30 06:41:07,405 | INFO | [default | seed 8] elapsed_time 00:29:24, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.67±13.23, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0013, mean_reward_over_100_episodes_from_eval 23.95±13.06
2025-12-30 06:42:05,149 | INFO | [default | seed 8] elapsed_time 00:30:21, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.87±13.07, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0013, mean_reward_over_100_episodes_from_eval 24.19±12.92
2025-12-30 06:43:01,592 | INFO | [default | seed 8] elapsed_time 00:31:18, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.18±12.99, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0013, mean_reward_over_100_episodes_from_eval 24.49±12.83
2025-12-30 06:43:58,772 | INFO | [default | seed 8] elapsed_time 00:32:15, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 24.43±12.88, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0013, mean_reward_over_100_episodes_from_eval 24.63±12.67
2025-12-30 06:44:56,232 | INFO | [default | seed 8] elapsed_time 00:33:12, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 24.62±12.74, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0013, mean_reward_over_100_episodes_from_eval 24.81±12.53
2025-12-30 06:45:52,941 | INFO | [default | seed 8] elapsed_time 00:34:09, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 24.80±12.60, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0013, mean_reward_over_100_episodes_from_eval 24.99±12.40
2025-12-30 06:46:50,450 | INFO | [default | seed 8] elapsed_time 00:35:07, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.96±12.47, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0013, mean_reward_over_100_episodes_from_eval 25.15±12.27
2025-12-30 06:47:47,659 | INFO | [default | seed 8] elapsed_time 00:36:04, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.16±12.36, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0013, mean_reward_over_100_episodes_from_eval 25.26±12.13
2025-12-30 06:48:44,142 | INFO | [default | seed 8] elapsed_time 00:37:00, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 25.32±12.25, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0013, mean_reward_over_100_episodes_from_eval 25.45±12.03
2025-12-30 06:49:40,144 | INFO | [default | seed 8] elapsed_time 00:37:56, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 25.50±12.14, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0013, mean_reward_over_100_episodes_from_eval 25.68±11.96
2025-12-30 06:50:36,819 | INFO | [default | seed 8] elapsed_time 00:38:53, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.72±12.08, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0013, mean_reward_over_100_episodes_from_eval 25.85±11.87
2025-12-30 06:51:34,698 | INFO | [default | seed 8] elapsed_time 00:39:51, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 25.83±11.95, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0013, mean_reward_over_100_episodes_from_eval 26.04±11.78
2025-12-30 06:52:31,172 | INFO | [default | seed 8] elapsed_time 00:40:47, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.03±11.88, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0013, mean_reward_over_100_episodes_from_eval 26.16±11.67
2025-12-30 06:53:28,858 | INFO | [default | seed 8] elapsed_time 00:41:45, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.20±11.80, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0014, mean_reward_over_100_episodes_from_eval 26.31±11.58
2025-12-30 06:54:26,430 | INFO | [default | seed 8] elapsed_time 00:42:43, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 26.35±11.71, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0014, mean_reward_over_100_episodes_from_eval 26.53±11.55
2025-12-30 06:55:24,395 | INFO | [default | seed 8] elapsed_time 00:43:41, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 26.52±11.64, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0014, mean_reward_over_100_episodes_from_eval 26.75±11.51
2025-12-30 06:56:21,663 | INFO | [default | seed 8] elapsed_time 00:44:38, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.68±11.57, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0014, mean_reward_over_100_episodes_from_eval 26.93±11.46
2025-12-30 06:57:19,910 | INFO | [default | seed 8] elapsed_time 00:45:36, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 26.82±11.48, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0014, mean_reward_over_100_episodes_from_eval 27.10±11.40
2025-12-30 06:58:18,016 | INFO | [default | seed 8] elapsed_time 00:46:34, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.96±11.41, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0014, mean_reward_over_100_episodes_from_eval 27.21±11.30
2025-12-30 06:59:15,481 | INFO | [default | seed 8] elapsed_time 00:47:32, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.04±11.31, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0015, mean_reward_over_100_episodes_from_eval 27.38±11.25
2025-12-30 07:00:12,890 | INFO | [default | seed 8] elapsed_time 00:48:29, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.19±11.24, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0015, mean_reward_over_100_episodes_from_eval 27.54±11.20
2025-12-30 07:01:18,747 | INFO | [default | seed 8] elapsed_time 00:49:35, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.32±11.18, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0015, mean_reward_over_100_episodes_from_eval 27.70±11.15
2025-12-30 07:02:15,534 | INFO | [default | seed 8] elapsed_time 00:50:32, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.47±11.12, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0015, mean_reward_over_100_episodes_from_eval 27.80±11.07
2025-12-30 07:03:11,482 | INFO | [default | seed 8] elapsed_time 00:51:28, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 27.60±11.06, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0015, mean_reward_over_100_episodes_from_eval 27.91±11.00
2025-12-30 07:04:09,454 | INFO | [default | seed 8] elapsed_time 00:52:26, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 27.72±10.99, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0015, mean_reward_over_100_episodes_from_eval 28.04±10.94
2025-12-30 07:05:07,352 | INFO | [default | seed 8] elapsed_time 00:53:24, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.86±10.95, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0016, mean_reward_over_100_episodes_from_eval 28.19±10.90
2025-12-30 07:06:06,015 | INFO | [default | seed 8] elapsed_time 00:54:22, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 28.01±10.90, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0016, mean_reward_over_100_episodes_from_eval 28.33±10.85
2025-12-30 07:07:05,116 | INFO | [default | seed 8] elapsed_time 00:55:21, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.14±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0016, mean_reward_over_100_episodes_from_eval 28.37±10.76
2025-12-30 07:08:02,475 | INFO | [default | seed 8] elapsed_time 00:56:19, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 28.26±10.80, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0016, mean_reward_over_100_episodes_from_eval 28.52±10.73
2025-12-30 07:09:00,736 | INFO | [default | seed 8] elapsed_time 00:57:17, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.35±10.74, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0016, mean_reward_over_100_episodes_from_eval 28.61±10.66
2025-12-30 07:09:58,503 | INFO | [default | seed 8] elapsed_time 00:58:15, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.45±10.67, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0016, mean_reward_over_100_episodes_from_eval 28.76±10.64
2025-12-30 07:10:56,246 | INFO | [default | seed 8] elapsed_time 00:59:12, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.55±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0016, mean_reward_over_100_episodes_from_eval 28.91±10.62
2025-12-30 07:11:55,066 | INFO | [default | seed 8] elapsed_time 01:00:11, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.67±10.57, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0016, mean_reward_over_100_episodes_from_eval 29.00±10.56
2025-12-30 07:12:52,075 | INFO | [default | seed 8] elapsed_time 01:01:08, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 28.73±10.50, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0016, mean_reward_over_100_episodes_from_eval 29.10±10.51
2025-12-30 07:13:50,140 | INFO | [default | seed 8] elapsed_time 01:02:06, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.81±10.44, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0017, mean_reward_over_100_episodes_from_eval 29.22±10.47
2025-12-30 07:14:54,032 | INFO | [default | seed 8] elapsed_time 01:03:10, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.91±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0017, mean_reward_over_100_episodes_from_eval 29.32±10.42
2025-12-30 07:15:47,694 | INFO | [default | seed 8] elapsed_time 01:04:04, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.99±10.33, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0017, mean_reward_over_100_episodes_from_eval 29.39±10.36
2025-12-30 07:16:43,939 | INFO | [default | seed 8] elapsed_time 01:05:00, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.10±10.30, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0017, mean_reward_over_100_episodes_from_eval 29.44±10.29
2025-12-30 07:17:36,528 | INFO | [default | seed 8] elapsed_time 01:05:53, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.20±10.25, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0017, mean_reward_over_100_episodes_from_eval 29.53±10.24
2025-12-30 07:18:31,163 | INFO | [default | seed 8] elapsed_time 01:06:47, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 29.25±10.19, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0017, mean_reward_over_100_episodes_from_eval 29.60±10.19
2025-12-30 07:19:25,719 | INFO | [default | seed 8] elapsed_time 01:07:42, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.37±10.16, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0017, mean_reward_over_100_episodes_from_eval 29.66±10.13
2025-12-30 07:20:21,111 | INFO | [default | seed 8] elapsed_time 01:08:37, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.43±10.11, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0017, mean_reward_over_100_episodes_from_eval 29.72±10.07
2025-12-30 07:21:16,962 | INFO | [default | seed 8] elapsed_time 01:09:33, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.49±10.05, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0017, mean_reward_over_100_episodes_from_eval 29.67±10.01
2025-12-30 07:22:10,968 | INFO | [default | seed 8] elapsed_time 01:10:27, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 29.49±09.98, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0018, mean_reward_over_100_episodes_from_eval 29.74±09.95
2025-12-30 07:23:05,139 | INFO | [default | seed 8] elapsed_time 01:11:21, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.58±09.94, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0018, mean_reward_over_100_episodes_from_eval 29.83±09.92
2025-12-30 07:24:00,135 | INFO | [default | seed 8] elapsed_time 01:12:16, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.64±09.89, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0018, mean_reward_over_100_episodes_from_eval 29.92±09.89
2025-12-30 07:24:54,300 | INFO | [default | seed 8] elapsed_time 01:13:11, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.69±09.83, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0018, mean_reward_over_100_episodes_from_eval 29.96±09.83
2025-12-30 07:25:50,540 | INFO | [default | seed 8] elapsed_time 01:14:07, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.76±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0018, mean_reward_over_100_episodes_from_eval 30.01±09.77
2025-12-30 07:26:45,248 | INFO | [default | seed 8] elapsed_time 01:15:01, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.81±09.74, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0018, mean_reward_over_100_episodes_from_eval 30.07±09.73
2025-12-30 07:27:38,507 | INFO | [default | seed 8] elapsed_time 01:15:55, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.86±09.69, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0018, mean_reward_over_100_episodes_from_eval 30.11±09.67
2025-12-30 07:28:33,121 | INFO | [default | seed 8] elapsed_time 01:16:49, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.91±09.64, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0018, mean_reward_over_100_episodes_from_eval 30.11±09.61
2025-12-30 07:29:27,556 | INFO | [default | seed 8] elapsed_time 01:17:44, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.93±09.58, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0018, mean_reward_over_100_episodes_from_eval 30.16±09.56
2025-12-30 07:30:23,006 | INFO | [default | seed 8] elapsed_time 01:18:39, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.98±09.53, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0018, mean_reward_over_100_episodes_from_eval 30.19±09.51
2025-12-30 07:31:19,050 | INFO | [default | seed 8] elapsed_time 01:19:35, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.05±09.50, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0018, mean_reward_over_100_episodes_from_eval 30.26±09.47
2025-12-30 07:32:12,140 | INFO | [default | seed 8] elapsed_time 01:20:28, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.10±09.45, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0019, mean_reward_over_100_episodes_from_eval 30.32±09.43
2025-12-30 07:33:04,471 | INFO | [default | seed 8] elapsed_time 01:21:21, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.15±09.41, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0019, mean_reward_over_100_episodes_from_eval 30.35±09.38
2025-12-30 07:34:02,850 | INFO | [default | seed 8] elapsed_time 01:22:19, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 30.17±09.36, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0019, mean_reward_over_100_episodes_from_eval 30.41±09.35
2025-12-30 07:34:58,178 | INFO | [default | seed 8] elapsed_time 01:23:14, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.24±09.32, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0019, mean_reward_over_100_episodes_from_eval 30.45±09.30
2025-12-30 07:35:52,826 | INFO | [default | seed 8] elapsed_time 01:24:09, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.31±09.29, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.51±09.27
2025-12-30 07:36:47,417 | INFO | [default | seed 8] elapsed_time 01:25:04, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.38±09.27, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.56±09.23
2025-12-30 07:37:40,381 | INFO | [default | seed 8] elapsed_time 01:25:57, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.45±09.24, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.60±09.18
2025-12-30 07:38:34,318 | INFO | [default | seed 8] elapsed_time 01:26:51, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.45±09.19, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0019, mean_reward_over_100_episodes_from_eval 30.60±09.13
2025-12-30 07:39:28,342 | INFO | [default | seed 8] elapsed_time 01:27:45, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.48±09.14, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.61±09.08
2025-12-30 07:40:23,373 | INFO | [default | seed 8] elapsed_time 01:28:40, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 30.51±09.10, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.68±09.06
2025-12-30 07:41:18,793 | INFO | [default | seed 8] elapsed_time 01:29:35, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 30.58±09.07, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.76±09.05
2025-12-30 07:42:13,280 | INFO | [default | seed 8] elapsed_time 01:30:29, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 30.65±09.05, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 30.79±09.00
2025-12-30 07:43:06,615 | INFO | [default | seed 8] elapsed_time 01:31:23, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 30.66±09.01, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 30.82±08.96
2025-12-30 07:44:01,654 | INFO | [default | seed 8] elapsed_time 01:32:18, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.70±08.97, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 30.82±08.92
2025-12-30 07:45:00,533 | INFO | [default | seed 8] elapsed_time 01:33:17, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.75±08.94, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 30.89±08.90
2025-12-30 07:46:00,346 | INFO | [default | seed 8] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=30.94
2025-12-30 07:46:00,347 | INFO | [default | seed 8] elapsed_time 01:34:17, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 30.81±08.91, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 30.94±08.87
2025-12-30 07:46:00,347 | INFO | [default | seed 8] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 08:14:30,984 | INFO | [default | seed 8] Training complete.
2025-12-30 08:14:30,985 | INFO | [default | seed 8] Solved (evaluation metric) at episode 100.
2025-12-30 08:14:30,985 | INFO | [default | seed 8] Final evaluation score 35.04±1.26 in 3857.37s training, 7367.70s wall.
2025-12-30 08:14:30,985 | INFO | [default | seed 8] Closing UnityVectorEnv (worker_id=8).
2025-12-30 08:14:30,986 | INFO | [Main] Requesting worker 8 to close Unity env.
2025-12-30 08:14:32,040 | INFO | [Main] Worker 8 joined. Unity env fully closed.
2025-12-30 08:14:32,040 | INFO | [default | seed 8] Final eval score: 35.04
2025-12-30 08:14:32,416 | INFO | [default | seed 8] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_8.png
2025-12-30 08:14:32,419 | INFO | [default | seed 8] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 08:14:32,650 | INFO | [default | seed 77] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 08:14:32,652 | INFO | [default | seed 77] === Starting run for seed 77 ===
2025-12-30 08:14:32,652 | INFO | [default | seed 77] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 08:14:32,653 | INFO | [default | seed 77] Launching UnityVectorEnv with worker_id=77, seed=77
2025-12-30 08:14:32,653 | INFO | [Main] Spawning worker 77 for Unity env (seed=77). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 08:14:32,676 | INFO | [Main] Worker 77 started (pid=91520).
2025-12-30 08:14:36,208 | INFO | [default | seed 77] Environment batched agents (train): 20
2025-12-30 08:15:07,956 | INFO | [default | seed 77] Environment batched agents (eval): 20
2025-12-30 08:15:25,219 | INFO | [default | seed 77] elapsed_time 00:00:52, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 04.800000, episode_sum_max_abs_reward_per_step 04.800000, mean_reward_over_100_episodes_from_training 00.26±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0116±0.0000, mean_reward_over_100_episodes_from_eval 00.08±00.00
2025-12-30 08:16:16,162 | INFO | [default | seed 77] elapsed_time 00:01:43, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 11.650000, episode_sum_max_abs_reward_per_step 11.650000, mean_reward_over_100_episodes_from_training 00.48±00.22, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0015, mean_reward_over_100_episodes_from_eval 00.87±00.79
2025-12-30 08:17:02,597 | INFO | [default | seed 77] elapsed_time 00:02:29, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 17.860000, episode_sum_max_abs_reward_per_step 17.860000, mean_reward_over_100_episodes_from_training 00.72±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0018, mean_reward_over_100_episodes_from_eval 01.00±00.67
2025-12-30 08:17:49,733 | INFO | [default | seed 77] elapsed_time 00:03:17, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 16.240000, episode_sum_max_abs_reward_per_step 16.240000, mean_reward_over_100_episodes_from_training 00.80±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0017, mean_reward_over_100_episodes_from_eval 01.24±00.72
2025-12-30 08:18:36,661 | INFO | [default | seed 77] elapsed_time 00:04:04, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 21.250000, episode_sum_max_abs_reward_per_step 21.250000, mean_reward_over_100_episodes_from_training 00.96±00.46, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0016, mean_reward_over_100_episodes_from_eval 01.33±00.66
2025-12-30 08:19:25,427 | INFO | [default | seed 77] elapsed_time 00:04:52, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 27.559999, episode_sum_max_abs_reward_per_step 27.559999, mean_reward_over_100_episodes_from_training 01.19±00.66, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0016, mean_reward_over_100_episodes_from_eval 01.55±00.78
2025-12-30 08:20:14,643 | INFO | [default | seed 77] elapsed_time 00:05:41, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 31.459999, episode_sum_max_abs_reward_per_step 31.459999, mean_reward_over_100_episodes_from_training 01.47±00.91, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0015, mean_reward_over_100_episodes_from_eval 01.79±00.94
2025-12-30 08:21:02,911 | INFO | [default | seed 77] elapsed_time 00:06:30, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 35.179999, episode_sum_max_abs_reward_per_step 35.179999, mean_reward_over_100_episodes_from_training 01.82±01.27, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0014, mean_reward_over_100_episodes_from_eval 02.17±01.33
2025-12-30 08:21:50,525 | INFO | [default | seed 77] elapsed_time 00:07:17, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 38.559999, episode_sum_max_abs_reward_per_step 38.559999, mean_reward_over_100_episodes_from_training 02.49±02.23, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0013, mean_reward_over_100_episodes_from_eval 03.09±02.90
2025-12-30 08:22:39,397 | INFO | [default | seed 77] elapsed_time 00:08:06, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 03.52±03.76, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0013, mean_reward_over_100_episodes_from_eval 04.46±04.94
2025-12-30 08:23:27,086 | INFO | [default | seed 77] elapsed_time 00:08:54, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 05.13±06.22, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 05.79±06.31
2025-12-30 08:24:15,927 | INFO | [default | seed 77] elapsed_time 00:09:43, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 06.64±07.78, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0012, mean_reward_over_100_episodes_from_eval 07.67±08.70
2025-12-30 08:25:15,057 | INFO | [default | seed 77] elapsed_time 00:10:42, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 08.30±09.43, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0013, mean_reward_over_100_episodes_from_eval 09.62±10.74
2025-12-30 08:27:42,902 | INFO | [default | seed 77] elapsed_time 00:13:10, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 10.11±11.18, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0015, mean_reward_over_100_episodes_from_eval 11.51±12.38
2025-12-30 08:28:49,307 | INFO | [default | seed 77] elapsed_time 00:14:16, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 11.86±12.64, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0016, mean_reward_over_100_episodes_from_eval 13.24±13.61
2025-12-30 08:29:44,237 | INFO | [default | seed 77] elapsed_time 00:15:11, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 13.42±13.64, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0016, mean_reward_over_100_episodes_from_eval 14.69±14.32
2025-12-30 08:30:38,908 | INFO | [default | seed 77] elapsed_time 00:16:06, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 14.70±14.20, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0016, mean_reward_over_100_episodes_from_eval 15.89±14.71
2025-12-30 08:31:58,706 | INFO | [default | seed 77] elapsed_time 00:17:26, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 15.76±14.48, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0017, mean_reward_over_100_episodes_from_eval 17.12±15.16
2025-12-30 08:33:00,319 | INFO | [default | seed 77] elapsed_time 00:18:27, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 16.78±14.73, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0017, mean_reward_over_100_episodes_from_eval 17.98±15.19
2025-12-30 08:34:02,382 | INFO | [default | seed 77] elapsed_time 00:19:29, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 17.70±14.91, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0017, mean_reward_over_100_episodes_from_eval 18.84±15.28
2025-12-30 08:34:58,908 | INFO | [default | seed 77] elapsed_time 00:20:26, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 18.52±15.01, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0017, mean_reward_over_100_episodes_from_eval 19.72±15.42
2025-12-30 08:36:00,421 | INFO | [default | seed 77] elapsed_time 00:21:27, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 19.20±14.99, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0016, mean_reward_over_100_episodes_from_eval 20.22±15.24
2025-12-30 08:36:59,088 | INFO | [default | seed 77] elapsed_time 00:22:26, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 19.77±14.90, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0016, mean_reward_over_100_episodes_from_eval 20.77±15.13
2025-12-30 08:37:57,677 | INFO | [default | seed 77] elapsed_time 00:23:25, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 20.27±14.79, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0016, mean_reward_over_100_episodes_from_eval 21.20±14.95
2025-12-30 08:38:56,425 | INFO | [default | seed 77] elapsed_time 00:24:23, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 20.66±14.61, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0016, mean_reward_over_100_episodes_from_eval 21.36±14.67
2025-12-30 08:39:55,094 | INFO | [default | seed 77] elapsed_time 00:25:22, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 21.21±14.59, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0016, mean_reward_over_100_episodes_from_eval 21.85±14.59
2025-12-30 08:40:50,777 | INFO | [default | seed 77] elapsed_time 00:26:18, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.66±14.49, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0015, mean_reward_over_100_episodes_from_eval 22.35±14.55
2025-12-30 08:41:46,342 | INFO | [default | seed 77] elapsed_time 00:27:13, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 22.16±14.47, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0015, mean_reward_over_100_episodes_from_eval 22.88±14.55
2025-12-30 08:42:42,558 | INFO | [default | seed 77] elapsed_time 00:28:09, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 22.61±14.41, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0015, mean_reward_over_100_episodes_from_eval 23.33±14.49
2025-12-30 08:43:37,638 | INFO | [default | seed 77] elapsed_time 00:29:04, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.06±14.38, mean_exploration_ratio_over_100_episodes_from_training 0.0164±0.0015, mean_reward_over_100_episodes_from_eval 23.72±14.40
2025-12-30 08:44:31,355 | INFO | [default | seed 77] elapsed_time 00:29:58, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.39±14.26, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0016, mean_reward_over_100_episodes_from_eval 24.05±14.28
2025-12-30 08:45:26,824 | INFO | [default | seed 77] elapsed_time 00:30:54, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.55±14.07, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 24.35±14.15
2025-12-30 08:46:21,822 | INFO | [default | seed 77] elapsed_time 00:31:49, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 23.75±13.90, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 24.59±14.01
2025-12-30 08:47:16,674 | INFO | [default | seed 77] elapsed_time 00:32:44, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 24.03±13.79, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0015, mean_reward_over_100_episodes_from_eval 24.77±13.84
2025-12-30 08:48:11,604 | INFO | [default | seed 77] elapsed_time 00:33:38, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 24.29±13.67, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0015, mean_reward_over_100_episodes_from_eval 25.10±13.78
2025-12-30 08:49:07,228 | INFO | [default | seed 77] elapsed_time 00:34:34, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 24.55±13.57, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 25.32±13.65
2025-12-30 08:50:03,763 | INFO | [default | seed 77] elapsed_time 00:35:31, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 24.82±13.48, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 25.57±13.54
2025-12-30 08:50:59,853 | INFO | [default | seed 77] elapsed_time 00:36:27, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.05±13.38, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 25.68±13.38
2025-12-30 08:51:54,821 | INFO | [default | seed 77] elapsed_time 00:37:22, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 25.18±13.23, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 25.69±13.20
2025-12-30 08:52:50,775 | INFO | [default | seed 77] elapsed_time 00:38:18, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 25.37±13.11, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0014, mean_reward_over_100_episodes_from_eval 25.85±13.07
2025-12-30 08:53:47,058 | INFO | [default | seed 77] elapsed_time 00:39:14, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.58±13.02, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0014, mean_reward_over_100_episodes_from_eval 26.01±12.95
2025-12-30 08:54:42,781 | INFO | [default | seed 77] elapsed_time 00:40:10, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 25.77±12.92, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0015, mean_reward_over_100_episodes_from_eval 26.27±12.91
2025-12-30 08:55:37,718 | INFO | [default | seed 77] elapsed_time 00:41:05, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.02±12.88, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0015, mean_reward_over_100_episodes_from_eval 26.54±12.88
2025-12-30 08:56:31,539 | INFO | [default | seed 77] elapsed_time 00:41:58, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 26.26±12.83, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0015, mean_reward_over_100_episodes_from_eval 26.73±12.79
2025-12-30 08:57:26,777 | INFO | [default | seed 77] elapsed_time 00:42:54, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 26.47±12.76, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0015, mean_reward_over_100_episodes_from_eval 26.89±12.69
2025-12-30 08:58:23,866 | INFO | [default | seed 77] elapsed_time 00:43:51, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.61±12.65, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0015, mean_reward_over_100_episodes_from_eval 27.08±12.61
2025-12-30 08:59:20,382 | INFO | [default | seed 77] elapsed_time 00:44:47, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 26.78±12.57, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0015, mean_reward_over_100_episodes_from_eval 27.24±12.53
2025-12-30 09:00:16,394 | INFO | [default | seed 77] elapsed_time 00:45:43, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.92±12.48, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0016, mean_reward_over_100_episodes_from_eval 27.38±12.43
2025-12-30 09:01:11,866 | INFO | [default | seed 77] elapsed_time 00:46:39, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.04±12.38, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0017, mean_reward_over_100_episodes_from_eval 27.54±12.36
2025-12-30 09:02:07,437 | INFO | [default | seed 77] elapsed_time 00:47:34, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 27.15±12.28, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0017, mean_reward_over_100_episodes_from_eval 27.63±12.25
2025-12-30 09:03:01,920 | INFO | [default | seed 77] elapsed_time 00:48:29, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 27.21±12.17, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0017, mean_reward_over_100_episodes_from_eval 27.78±12.18
2025-12-30 09:03:58,216 | INFO | [default | seed 77] elapsed_time 00:49:25, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.35±12.09, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0018, mean_reward_over_100_episodes_from_eval 27.85±12.07
2025-12-30 09:04:54,056 | INFO | [default | seed 77] elapsed_time 00:50:21, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 27.44±11.99, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0018, mean_reward_over_100_episodes_from_eval 27.94±11.97
2025-12-30 09:05:52,185 | INFO | [default | seed 77] elapsed_time 00:51:19, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 27.56±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0018, mean_reward_over_100_episodes_from_eval 28.05±11.89
2025-12-30 09:06:48,106 | INFO | [default | seed 77] elapsed_time 00:52:15, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 27.69±11.84, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0018, mean_reward_over_100_episodes_from_eval 28.24±11.86
2025-12-30 09:07:43,277 | INFO | [default | seed 77] elapsed_time 00:53:10, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.82±11.78, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0019, mean_reward_over_100_episodes_from_eval 28.29±11.76
2025-12-30 09:08:38,636 | INFO | [default | seed 77] elapsed_time 00:54:05, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 27.92±11.69, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0019, mean_reward_over_100_episodes_from_eval 28.40±11.68
2025-12-30 09:09:33,545 | INFO | [default | seed 77] elapsed_time 00:55:00, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 28.05±11.64, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0019, mean_reward_over_100_episodes_from_eval 28.54±11.63
2025-12-30 09:10:30,896 | INFO | [default | seed 77] elapsed_time 00:55:58, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.20±11.60, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0019, mean_reward_over_100_episodes_from_eval 28.62±11.55
2025-12-30 09:11:26,276 | INFO | [default | seed 77] elapsed_time 00:56:53, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.31±11.53, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0019, mean_reward_over_100_episodes_from_eval 28.68±11.46
2025-12-30 09:12:22,387 | INFO | [default | seed 77] elapsed_time 00:57:49, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 28.42±11.47, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0020, mean_reward_over_100_episodes_from_eval 28.77±11.39
2025-12-30 09:13:17,766 | INFO | [default | seed 77] elapsed_time 00:58:45, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.48±11.38, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0020, mean_reward_over_100_episodes_from_eval 28.83±11.31
2025-12-30 09:14:13,531 | INFO | [default | seed 77] elapsed_time 00:59:40, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.54±11.30, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0020, mean_reward_over_100_episodes_from_eval 28.88±11.22
2025-12-30 09:15:10,255 | INFO | [default | seed 77] elapsed_time 01:00:37, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.59±11.22, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0020, mean_reward_over_100_episodes_from_eval 28.95±11.15
2025-12-30 09:16:05,918 | INFO | [default | seed 77] elapsed_time 01:01:33, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 28.63±11.14, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0020, mean_reward_over_100_episodes_from_eval 29.04±11.09
2025-12-30 09:17:01,028 | INFO | [default | seed 77] elapsed_time 01:02:28, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.68±11.06, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0020, mean_reward_over_100_episodes_from_eval 29.06±11.01
2025-12-30 09:17:56,798 | INFO | [default | seed 77] elapsed_time 01:03:24, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 28.73±10.99, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0021, mean_reward_over_100_episodes_from_eval 29.09±10.93
2025-12-30 09:18:52,791 | INFO | [default | seed 77] elapsed_time 01:04:20, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 28.81±10.92, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0021, mean_reward_over_100_episodes_from_eval 29.18±10.87
2025-12-30 09:19:49,024 | INFO | [default | seed 77] elapsed_time 01:05:16, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.90±10.87, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0021, mean_reward_over_100_episodes_from_eval 29.29±10.83
2025-12-30 09:20:44,432 | INFO | [default | seed 77] elapsed_time 01:06:11, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.00±10.83, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0021, mean_reward_over_100_episodes_from_eval 29.41±10.80
2025-12-30 09:21:42,416 | INFO | [default | seed 77] elapsed_time 01:07:09, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.09±10.78, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0021, mean_reward_over_100_episodes_from_eval 29.50±10.75
2025-12-30 09:22:37,581 | INFO | [default | seed 77] elapsed_time 01:08:04, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 29.19±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0021, mean_reward_over_100_episodes_from_eval 29.58±10.70
2025-12-30 09:23:31,775 | INFO | [default | seed 77] elapsed_time 01:08:59, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.25±10.67, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0021, mean_reward_over_100_episodes_from_eval 29.63±10.63
2025-12-30 09:24:27,461 | INFO | [default | seed 77] elapsed_time 01:09:54, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.31±10.61, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0021, mean_reward_over_100_episodes_from_eval 29.69±10.57
2025-12-30 09:25:23,903 | INFO | [default | seed 77] elapsed_time 01:10:51, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.39±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0021, mean_reward_over_100_episodes_from_eval 29.75±10.51
2025-12-30 09:26:23,532 | INFO | [default | seed 77] elapsed_time 01:11:50, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.46±10.51, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0021, mean_reward_over_100_episodes_from_eval 29.83±10.47
2025-12-30 09:27:18,812 | INFO | [default | seed 77] elapsed_time 01:12:46, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.54±10.47, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0021, mean_reward_over_100_episodes_from_eval 29.95±10.45
2025-12-30 09:28:14,908 | INFO | [default | seed 77] elapsed_time 01:13:42, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.61±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 30.02±10.40
2025-12-30 09:29:12,975 | INFO | [default | seed 77] elapsed_time 01:14:40, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.66±10.36, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 30.05±10.34
2025-12-30 09:30:09,263 | INFO | [default | seed 77] elapsed_time 01:15:36, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.71±10.31, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 30.07±10.27
2025-12-30 09:31:04,187 | INFO | [default | seed 77] elapsed_time 01:16:31, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 29.74±10.25, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 30.12±10.22
2025-12-30 09:31:59,655 | INFO | [default | seed 77] elapsed_time 01:17:27, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.76±10.19, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0021, mean_reward_over_100_episodes_from_eval 30.18±10.17
2025-12-30 09:32:56,929 | INFO | [default | seed 77] elapsed_time 01:18:24, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.85±10.16, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0021, mean_reward_over_100_episodes_from_eval 30.26±10.14
2025-12-30 09:33:53,025 | INFO | [default | seed 77] elapsed_time 01:19:20, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.93±10.12, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0021, mean_reward_over_100_episodes_from_eval 30.30±10.08
2025-12-30 09:34:49,909 | INFO | [default | seed 77] elapsed_time 01:20:17, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.98±10.07, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0021, mean_reward_over_100_episodes_from_eval 30.35±10.04
2025-12-30 09:35:45,910 | INFO | [default | seed 77] elapsed_time 01:21:13, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.05±10.04, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0021, mean_reward_over_100_episodes_from_eval 30.40±09.99
2025-12-30 09:36:42,889 | INFO | [default | seed 77] elapsed_time 01:22:10, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.11±09.99, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0021, mean_reward_over_100_episodes_from_eval 30.47±09.95
2025-12-30 09:37:37,737 | INFO | [default | seed 77] elapsed_time 01:23:05, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 30.15±09.94, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0021, mean_reward_over_100_episodes_from_eval 30.54±09.92
2025-12-30 09:38:34,034 | INFO | [default | seed 77] elapsed_time 01:24:01, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.21±09.90, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0021, mean_reward_over_100_episodes_from_eval 30.61±09.88
2025-12-30 09:39:31,453 | INFO | [default | seed 77] elapsed_time 01:24:58, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 30.27±09.86, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0021, mean_reward_over_100_episodes_from_eval 30.65±09.83
2025-12-30 09:40:27,076 | INFO | [default | seed 77] elapsed_time 01:25:54, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.29±09.81, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.70±09.79
2025-12-30 09:41:25,985 | INFO | [default | seed 77] elapsed_time 01:26:53, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.33±09.76, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.75±09.75
2025-12-30 09:42:21,478 | INFO | [default | seed 77] elapsed_time 01:27:48, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.39±09.72, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.81±09.71
2025-12-30 09:43:17,432 | INFO | [default | seed 77] elapsed_time 01:28:44, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.45±09.69, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.85±09.67
2025-12-30 09:44:13,931 | INFO | [default | seed 77] elapsed_time 01:29:41, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 30.50±09.65, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.90±09.63
2025-12-30 09:45:11,365 | INFO | [default | seed 77] elapsed_time 01:30:38, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 30.53±09.61, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.94±09.59
2025-12-30 09:46:09,093 | INFO | [default | seed 77] elapsed_time 01:31:36, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.58±09.57, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0021, mean_reward_over_100_episodes_from_eval 30.98±09.55
2025-12-30 09:47:04,269 | INFO | [default | seed 77] elapsed_time 01:32:31, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.64±09.54, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0021, mean_reward_over_100_episodes_from_eval 31.04±09.51
2025-12-30 09:47:59,199 | INFO | [default | seed 77] elapsed_time 01:33:26, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.68±09.50, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0021, mean_reward_over_100_episodes_from_eval 31.05±09.47
2025-12-30 09:48:53,482 | INFO | [default | seed 77] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=31.08
2025-12-30 09:48:53,486 | INFO | [default | seed 77] elapsed_time 01:34:20, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.65±09.46, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0021, mean_reward_over_100_episodes_from_eval 31.08±09.42
2025-12-30 09:48:53,487 | INFO | [default | seed 77] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 10:19:34,992 | INFO | [default | seed 77] Training complete.
2025-12-30 10:19:34,993 | INFO | [default | seed 77] Solved (evaluation metric) at episode 100.
2025-12-30 10:19:34,993 | INFO | [default | seed 77] Final evaluation score 32.53±1.17 in 3805.68s training, 7502.34s wall.
2025-12-30 10:19:34,993 | INFO | [default | seed 77] Closing UnityVectorEnv (worker_id=77).
2025-12-30 10:19:34,994 | INFO | [Main] Requesting worker 77 to close Unity env.
2025-12-30 10:19:36,429 | INFO | [Main] Worker 77 joined. Unity env fully closed.
2025-12-30 10:19:36,431 | INFO | [default | seed 77] Final eval score: 32.53
2025-12-30 10:19:36,870 | INFO | [default | seed 77] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_77.png
2025-12-30 10:19:36,870 | INFO | [default | seed 77] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 10:19:37,062 | INFO | [default | seed 21] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 10:19:37,062 | INFO | [default | seed 21] === Starting run for seed 21 ===
2025-12-30 10:19:37,062 | INFO | [default | seed 21] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 10:19:37,066 | INFO | [default | seed 21] Launching UnityVectorEnv with worker_id=21, seed=21
2025-12-30 10:19:37,066 | INFO | [Main] Spawning worker 21 for Unity env (seed=21). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 10:19:37,082 | INFO | [Main] Worker 21 started (pid=96104).
2025-12-30 10:19:44,303 | INFO | [default | seed 21] Environment batched agents (train): 20
2025-12-30 10:20:17,208 | INFO | [default | seed 21] Environment batched agents (eval): 20
2025-12-30 10:20:37,824 | INFO | [default | seed 21] elapsed_time 00:01:00, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 08.470000, episode_sum_max_abs_reward_per_step 08.470000, mean_reward_over_100_episodes_from_training 00.53±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0000, mean_reward_over_100_episodes_from_eval 00.66±00.00
2025-12-30 10:21:40,145 | INFO | [default | seed 21] elapsed_time 00:02:03, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 17.550000, episode_sum_max_abs_reward_per_step 17.550000, mean_reward_over_100_episodes_from_training 00.83±00.30, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0001, mean_reward_over_100_episodes_from_eval 00.90±00.24
2025-12-30 10:22:36,996 | INFO | [default | seed 21] elapsed_time 00:02:59, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 20.360000, episode_sum_max_abs_reward_per_step 20.360000, mean_reward_over_100_episodes_from_training 01.04±00.39, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0002, mean_reward_over_100_episodes_from_eval 01.15±00.40
2025-12-30 10:23:31,528 | INFO | [default | seed 21] elapsed_time 00:03:54, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 20.100000, episode_sum_max_abs_reward_per_step 20.100000, mean_reward_over_100_episodes_from_training 01.14±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0005, mean_reward_over_100_episodes_from_eval 01.26±00.39
2025-12-30 10:24:26,948 | INFO | [default | seed 21] elapsed_time 00:04:49, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 24.819999, episode_sum_max_abs_reward_per_step 24.819999, mean_reward_over_100_episodes_from_training 01.29±00.46, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0009, mean_reward_over_100_episodes_from_eval 01.46±00.55
2025-12-30 10:25:25,483 | INFO | [default | seed 21] elapsed_time 00:05:48, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 28.439999, episode_sum_max_abs_reward_per_step 28.439999, mean_reward_over_100_episodes_from_training 01.50±00.62, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0009, mean_reward_over_100_episodes_from_eval 01.94±01.17
2025-12-30 10:26:22,856 | INFO | [default | seed 21] elapsed_time 00:06:45, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 32.629999, episode_sum_max_abs_reward_per_step 32.629999, mean_reward_over_100_episodes_from_training 01.83±00.99, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0009, mean_reward_over_100_episodes_from_eval 02.30±01.41
2025-12-30 10:27:19,537 | INFO | [default | seed 21] elapsed_time 00:07:42, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 35.849999, episode_sum_max_abs_reward_per_step 35.849999, mean_reward_over_100_episodes_from_training 02.17±01.29, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0008, mean_reward_over_100_episodes_from_eval 02.94±02.14
2025-12-30 10:28:18,687 | INFO | [default | seed 21] elapsed_time 00:08:41, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 38.289999, episode_sum_max_abs_reward_per_step 38.289999, mean_reward_over_100_episodes_from_training 02.63±01.79, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0008, mean_reward_over_100_episodes_from_eval 03.51±02.57
2025-12-30 10:29:17,913 | INFO | [default | seed 21] elapsed_time 00:09:40, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.249999, episode_sum_max_abs_reward_per_step 39.249999, mean_reward_over_100_episodes_from_training 03.34±02.72, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0008, mean_reward_over_100_episodes_from_eval 04.35±03.52
2025-12-30 10:30:17,906 | INFO | [default | seed 21] elapsed_time 00:10:40, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.439999, episode_sum_max_abs_reward_per_step 39.439999, mean_reward_over_100_episodes_from_training 04.22±03.79, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0008, mean_reward_over_100_episodes_from_eval 05.41±04.73
2025-12-30 10:31:16,646 | INFO | [default | seed 21] elapsed_time 00:11:39, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 05.15±04.77, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0007, mean_reward_over_100_episodes_from_eval 06.60±06.03
2025-12-30 10:32:14,702 | INFO | [default | seed 21] elapsed_time 00:12:37, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 06.26±05.99, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0008, mean_reward_over_100_episodes_from_eval 07.70±06.91
2025-12-30 10:33:38,438 | INFO | [default | seed 21] elapsed_time 00:14:01, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 07.34±06.97, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0008, mean_reward_over_100_episodes_from_eval 08.71±07.61
2025-12-30 10:34:35,763 | INFO | [default | seed 21] elapsed_time 00:14:58, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 08.34±07.69, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0009, mean_reward_over_100_episodes_from_eval 09.57±08.02
2025-12-30 10:35:39,596 | INFO | [default | seed 21] elapsed_time 00:16:02, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 09.39±08.49, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0009, mean_reward_over_100_episodes_from_eval 10.61±08.74
2025-12-30 10:36:35,565 | INFO | [default | seed 21] elapsed_time 00:16:58, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 10.40±09.17, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0009, mean_reward_over_100_episodes_from_eval 11.51±09.21
2025-12-30 10:37:55,699 | INFO | [default | seed 21] elapsed_time 00:18:18, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 11.13±09.41, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0009, mean_reward_over_100_episodes_from_eval 12.36±09.61
2025-12-30 10:38:51,924 | INFO | [default | seed 21] elapsed_time 00:19:14, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 11.91±09.74, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0009, mean_reward_over_100_episodes_from_eval 12.97±09.71
2025-12-30 10:39:49,408 | INFO | [default | seed 21] elapsed_time 00:20:12, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 12.64±10.00, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 13.71±09.99
2025-12-30 10:40:43,538 | INFO | [default | seed 21] elapsed_time 00:21:06, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 13.43±10.38, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 14.28±10.08
2025-12-30 10:41:39,491 | INFO | [default | seed 21] elapsed_time 00:22:02, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 14.11±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 14.93±10.29
2025-12-30 10:42:33,638 | INFO | [default | seed 21] elapsed_time 00:22:56, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 14.71±10.76, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 15.58±10.52
2025-12-30 10:43:29,114 | INFO | [default | seed 21] elapsed_time 00:23:52, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 15.25±10.85, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 16.14±10.64
2025-12-30 10:44:25,491 | INFO | [default | seed 21] elapsed_time 00:24:48, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 15.82±10.98, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 16.49±10.57
2025-12-30 10:45:21,521 | INFO | [default | seed 21] elapsed_time 00:25:44, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 16.27±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 16.88±10.54
2025-12-30 10:46:18,561 | INFO | [default | seed 21] elapsed_time 00:26:41, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 16.65±10.97, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 17.27±10.54
2025-12-30 10:47:14,054 | INFO | [default | seed 21] elapsed_time 00:27:36, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 17.03±10.96, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 17.62±10.50
2025-12-30 10:48:19,083 | INFO | [default | seed 21] elapsed_time 00:28:42, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 17.27±10.84, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 17.90±10.43
2025-12-30 10:49:15,320 | INFO | [default | seed 21] elapsed_time 00:29:38, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 17.54±10.76, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 18.16±10.34
2025-12-30 10:50:12,350 | INFO | [default | seed 21] elapsed_time 00:30:35, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 17.79±10.67, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 18.43±10.29
2025-12-30 10:51:08,000 | INFO | [default | seed 21] elapsed_time 00:31:30, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 18.09±10.63, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 18.65±10.20
2025-12-30 10:52:04,769 | INFO | [default | seed 21] elapsed_time 00:32:27, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 18.39±10.61, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 18.84±10.10
2025-12-30 10:53:01,404 | INFO | [default | seed 21] elapsed_time 00:33:24, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 18.69±10.59, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0010, mean_reward_over_100_episodes_from_eval 19.12±10.08
2025-12-30 10:53:57,830 | INFO | [default | seed 21] elapsed_time 00:34:20, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 18.97±10.57, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0010, mean_reward_over_100_episodes_from_eval 19.46±10.13
2025-12-30 10:54:55,449 | INFO | [default | seed 21] elapsed_time 00:35:18, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 19.28±10.58, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0010, mean_reward_over_100_episodes_from_eval 19.75±10.14
2025-12-30 10:55:50,998 | INFO | [default | seed 21] elapsed_time 00:36:13, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 19.49±10.51, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0010, mean_reward_over_100_episodes_from_eval 20.03±10.14
2025-12-30 10:56:47,479 | INFO | [default | seed 21] elapsed_time 00:37:10, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 19.75±10.49, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0010, mean_reward_over_100_episodes_from_eval 20.17±10.04
2025-12-30 10:57:42,276 | INFO | [default | seed 21] elapsed_time 00:38:05, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 19.94±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0010, mean_reward_over_100_episodes_from_eval 20.48±10.09
2025-12-30 10:58:38,475 | INFO | [default | seed 21] elapsed_time 00:39:01, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 20.21±10.43, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0010, mean_reward_over_100_episodes_from_eval 20.80±10.16
2025-12-30 10:59:32,911 | INFO | [default | seed 21] elapsed_time 00:39:55, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 20.46±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0010, mean_reward_over_100_episodes_from_eval 20.96±10.09
2025-12-30 11:00:30,475 | INFO | [default | seed 21] elapsed_time 00:40:53, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.409999, episode_sum_max_abs_reward_per_step 39.409999, mean_reward_over_100_episodes_from_training 20.61±10.34, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0011, mean_reward_over_100_episodes_from_eval 21.16±10.05
2025-12-30 11:01:26,835 | INFO | [default | seed 21] elapsed_time 00:41:49, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 20.81±10.30, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0011, mean_reward_over_100_episodes_from_eval 21.32±09.99
2025-12-30 11:02:21,784 | INFO | [default | seed 21] elapsed_time 00:42:44, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.03±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0011, mean_reward_over_100_episodes_from_eval 21.57±10.01
2025-12-30 11:03:18,020 | INFO | [default | seed 21] elapsed_time 00:43:40, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.27±10.30, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0011, mean_reward_over_100_episodes_from_eval 21.78±09.99
2025-12-30 11:04:13,749 | INFO | [default | seed 21] elapsed_time 00:44:36, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 21.52±10.32, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0011, mean_reward_over_100_episodes_from_eval 22.03±10.02
2025-12-30 11:05:09,678 | INFO | [default | seed 21] elapsed_time 00:45:32, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 21.74±10.32, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0012, mean_reward_over_100_episodes_from_eval 22.25±10.03
2025-12-30 11:06:05,179 | INFO | [default | seed 21] elapsed_time 00:46:28, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 21.91±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 22.49±10.06
2025-12-30 11:07:01,567 | INFO | [default | seed 21] elapsed_time 00:47:24, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 22.12±10.27, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 22.72±10.09
2025-12-30 11:07:56,938 | INFO | [default | seed 21] elapsed_time 00:48:19, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 22.37±10.32, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 22.96±10.13
2025-12-30 11:08:52,615 | INFO | [default | seed 21] elapsed_time 00:49:15, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 22.61±10.36, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0013, mean_reward_over_100_episodes_from_eval 23.13±10.10
2025-12-30 11:09:50,129 | INFO | [default | seed 21] elapsed_time 00:50:13, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 22.80±10.35, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 23.37±10.14
2025-12-30 11:10:46,611 | INFO | [default | seed 21] elapsed_time 00:51:09, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.02±10.37, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 23.60±10.19
2025-12-30 11:11:47,900 | INFO | [default | seed 21] elapsed_time 00:52:10, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 23.25±10.41, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 23.80±10.19
2025-12-30 11:12:43,890 | INFO | [default | seed 21] elapsed_time 00:53:06, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.49±10.46, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0013, mean_reward_over_100_episodes_from_eval 23.99±10.20
2025-12-30 11:13:39,754 | INFO | [default | seed 21] elapsed_time 00:54:02, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 23.68±10.46, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 24.21±10.23
2025-12-30 11:14:34,835 | INFO | [default | seed 21] elapsed_time 00:54:57, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 23.86±10.46, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 24.32±10.17
2025-12-30 11:15:31,413 | INFO | [default | seed 21] elapsed_time 00:55:54, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.99±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 24.45±10.14
2025-12-30 11:16:27,674 | INFO | [default | seed 21] elapsed_time 00:56:50, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 24.15±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 24.62±10.14
2025-12-30 11:17:24,118 | INFO | [default | seed 21] elapsed_time 00:57:47, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 24.32±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0014, mean_reward_over_100_episodes_from_eval 24.73±10.08
2025-12-30 11:18:18,928 | INFO | [default | seed 21] elapsed_time 00:58:41, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 24.49±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0014, mean_reward_over_100_episodes_from_eval 24.94±10.13
2025-12-30 11:19:14,297 | INFO | [default | seed 21] elapsed_time 00:59:37, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 24.69±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0014, mean_reward_over_100_episodes_from_eval 25.12±10.15
2025-12-30 11:20:10,288 | INFO | [default | seed 21] elapsed_time 01:00:33, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 24.89±10.46, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0014, mean_reward_over_100_episodes_from_eval 25.27±10.14
2025-12-30 11:21:05,278 | INFO | [default | seed 21] elapsed_time 01:01:28, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 25.08±10.48, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0014, mean_reward_over_100_episodes_from_eval 25.48±10.19
2025-12-30 11:22:00,274 | INFO | [default | seed 21] elapsed_time 01:02:23, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.28±10.52, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0014, mean_reward_over_100_episodes_from_eval 25.62±10.18
2025-12-30 11:22:54,576 | INFO | [default | seed 21] elapsed_time 01:03:17, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.42±10.51, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0014, mean_reward_over_100_episodes_from_eval 25.62±10.10
2025-12-30 11:23:50,301 | INFO | [default | seed 21] elapsed_time 01:04:13, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.52±10.46, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0015, mean_reward_over_100_episodes_from_eval 25.77±10.09
2025-12-30 11:24:46,087 | INFO | [default | seed 21] elapsed_time 01:05:09, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.62±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0015, mean_reward_over_100_episodes_from_eval 25.86±10.05
2025-12-30 11:25:42,540 | INFO | [default | seed 21] elapsed_time 01:06:05, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.74±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0015, mean_reward_over_100_episodes_from_eval 26.03±10.07
2025-12-30 11:26:38,334 | INFO | [default | seed 21] elapsed_time 01:07:01, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 25.90±10.40, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0015, mean_reward_over_100_episodes_from_eval 26.11±10.02
2025-12-30 11:27:33,180 | INFO | [default | seed 21] elapsed_time 01:07:56, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.99±10.35, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0015, mean_reward_over_100_episodes_from_eval 26.24±10.01
2025-12-30 11:28:30,195 | INFO | [default | seed 21] elapsed_time 01:08:53, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 26.11±10.33, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0015, mean_reward_over_100_episodes_from_eval 26.35±09.98
2025-12-30 11:29:29,668 | INFO | [default | seed 21] elapsed_time 01:09:52, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 26.26±10.33, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0015, mean_reward_over_100_episodes_from_eval 26.51±10.00
2025-12-30 11:30:26,689 | INFO | [default | seed 21] elapsed_time 01:10:49, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.41±10.35, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0015, mean_reward_over_100_episodes_from_eval 26.62±09.98
2025-12-30 11:31:23,301 | INFO | [default | seed 21] elapsed_time 01:11:46, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.55±10.35, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0015, mean_reward_over_100_episodes_from_eval 26.76±09.99
2025-12-30 11:32:18,707 | INFO | [default | seed 21] elapsed_time 01:12:41, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 26.65±10.32, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0015, mean_reward_over_100_episodes_from_eval 26.82±09.94
2025-12-30 11:33:14,982 | INFO | [default | seed 21] elapsed_time 01:13:37, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.77±10.30, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0015, mean_reward_over_100_episodes_from_eval 26.92±09.90
2025-12-30 11:34:11,970 | INFO | [default | seed 21] elapsed_time 01:14:34, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 26.88±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0015, mean_reward_over_100_episodes_from_eval 27.00±09.87
2025-12-30 11:35:07,656 | INFO | [default | seed 21] elapsed_time 01:15:30, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.95±10.23, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0015, mean_reward_over_100_episodes_from_eval 27.09±09.84
2025-12-30 11:36:03,632 | INFO | [default | seed 21] elapsed_time 01:16:26, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.02±10.19, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0016, mean_reward_over_100_episodes_from_eval 27.14±09.79
2025-12-30 11:37:00,936 | INFO | [default | seed 21] elapsed_time 01:17:23, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.10±10.15, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0016, mean_reward_over_100_episodes_from_eval 27.27±09.80
2025-12-30 11:37:56,781 | INFO | [default | seed 21] elapsed_time 01:18:19, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.19±10.12, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0016, mean_reward_over_100_episodes_from_eval 27.35±09.76
2025-12-30 11:38:52,866 | INFO | [default | seed 21] elapsed_time 01:19:15, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.25±10.08, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0016, mean_reward_over_100_episodes_from_eval 27.46±09.76
2025-12-30 11:39:49,904 | INFO | [default | seed 21] elapsed_time 01:20:12, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.36±10.06, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0016, mean_reward_over_100_episodes_from_eval 27.54±09.72
2025-12-30 11:40:46,659 | INFO | [default | seed 21] elapsed_time 01:21:09, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 27.41±10.01, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0016, mean_reward_over_100_episodes_from_eval 27.64±09.71
2025-12-30 11:41:44,589 | INFO | [default | seed 21] elapsed_time 01:22:07, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.50±09.99, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0016, mean_reward_over_100_episodes_from_eval 27.70±09.67
2025-12-30 11:42:40,816 | INFO | [default | seed 21] elapsed_time 01:23:03, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.57±09.95, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0016, mean_reward_over_100_episodes_from_eval 27.77±09.63
2025-12-30 11:43:36,060 | INFO | [default | seed 21] elapsed_time 01:23:58, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.66±09.93, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0016, mean_reward_over_100_episodes_from_eval 27.86±09.62
2025-12-30 11:44:32,632 | INFO | [default | seed 21] elapsed_time 01:24:55, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.72±09.89, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0016, mean_reward_over_100_episodes_from_eval 27.87±09.56
2025-12-30 11:45:28,477 | INFO | [default | seed 21] elapsed_time 01:25:51, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.79±09.86, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0016, mean_reward_over_100_episodes_from_eval 27.96±09.55
2025-12-30 11:46:25,791 | INFO | [default | seed 21] elapsed_time 01:26:48, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.87±09.83, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0016, mean_reward_over_100_episodes_from_eval 28.05±09.54
2025-12-30 11:47:22,067 | INFO | [default | seed 21] elapsed_time 01:27:45, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.91±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0016, mean_reward_over_100_episodes_from_eval 28.12±09.51
2025-12-30 11:48:18,548 | INFO | [default | seed 21] elapsed_time 01:28:41, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.99±09.76, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0016, mean_reward_over_100_episodes_from_eval 28.19±09.48
2025-12-30 11:49:14,176 | INFO | [default | seed 21] elapsed_time 01:29:37, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.07±09.74, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0016, mean_reward_over_100_episodes_from_eval 28.26±09.45
2025-12-30 11:50:10,529 | INFO | [default | seed 21] elapsed_time 01:30:33, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.13±09.71, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0016, mean_reward_over_100_episodes_from_eval 28.25±09.40
2025-12-30 11:51:06,345 | INFO | [default | seed 21] elapsed_time 01:31:29, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.17±09.67, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0016, mean_reward_over_100_episodes_from_eval 28.29±09.36
2025-12-30 11:52:02,940 | INFO | [default | seed 21] elapsed_time 01:32:25, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 28.21±09.62, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0016, mean_reward_over_100_episodes_from_eval 28.33±09.32
2025-12-30 11:52:59,755 | INFO | [default | seed 21] elapsed_time 01:33:22, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.24±09.58, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0016, mean_reward_over_100_episodes_from_eval 28.36±09.28
2025-12-30 11:53:56,451 | INFO | [default | seed 21] elapsed_time 01:34:19, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.33±09.57, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0016, mean_reward_over_100_episodes_from_eval 28.45±09.28
2025-12-30 11:54:54,584 | INFO | [default | seed 21] elapsed_time 01:35:17, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.41±09.56, mean_exploration_ratio_over_100_episodes_from_training 0.0124±0.0016, mean_reward_over_100_episodes_from_eval 28.53±09.26
2025-12-30 11:55:50,772 | INFO | [default | seed 21] elapsed_time 01:36:13, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.76±09.16, mean_exploration_ratio_over_100_episodes_from_training 0.0124±0.0016, mean_reward_over_100_episodes_from_eval 28.84±08.84
2025-12-30 11:56:47,654 | INFO | [default | seed 21] elapsed_time 01:37:10, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 29.05±08.73, mean_exploration_ratio_over_100_episodes_from_training 0.0124±0.0016, mean_reward_over_100_episodes_from_eval 29.18±08.41
2025-12-30 11:57:43,484 | INFO | [default | seed 21] elapsed_time 01:38:06, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.38±08.30, mean_exploration_ratio_over_100_episodes_from_training 0.0124±0.0016, mean_reward_over_100_episodes_from_eval 29.51±07.95
2025-12-30 11:58:38,856 | INFO | [default | seed 21] elapsed_time 01:39:01, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.67±07.81, mean_exploration_ratio_over_100_episodes_from_training 0.0124±0.0016, mean_reward_over_100_episodes_from_eval 29.75±07.45
2025-12-30 11:59:34,163 | INFO | [default | seed 21] Requirement met (evaluation metric): solved at episode 105 with mean_100_eval=30.03
2025-12-30 11:59:34,166 | INFO | [default | seed 21] elapsed_time 01:39:57, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 29.95±07.29, mean_exploration_ratio_over_100_episodes_from_training 0.0123±0.0016, mean_reward_over_100_episodes_from_eval 30.03±06.92
2025-12-30 11:59:34,166 | INFO | [default | seed 21] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 12:28:19,270 | INFO | [default | seed 21] Training complete.
2025-12-30 12:28:19,271 | INFO | [default | seed 21] Solved (evaluation metric) at episode 105.
2025-12-30 12:28:19,271 | INFO | [default | seed 21] Final evaluation score 30.73±0.83 in 4068.65s training, 7722.21s wall.
2025-12-30 12:28:19,271 | INFO | [default | seed 21] Closing UnityVectorEnv (worker_id=21).
2025-12-30 12:28:19,271 | INFO | [Main] Requesting worker 21 to close Unity env.
2025-12-30 12:28:19,883 | INFO | [Main] Worker 21 joined. Unity env fully closed.
2025-12-30 12:28:19,883 | INFO | [default | seed 21] Final eval score: 30.73
2025-12-30 12:28:20,240 | INFO | [default | seed 21] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_21.png
2025-12-30 12:28:20,242 | INFO | [default | seed 21] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 12:28:20,409 | INFO | [default | seed 20] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 12:28:20,409 | INFO | [default | seed 20] === Starting run for seed 20 ===
2025-12-30 12:28:20,409 | INFO | [default | seed 20] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 12:28:20,409 | INFO | [default | seed 20] Launching UnityVectorEnv with worker_id=20, seed=20
2025-12-30 12:28:20,409 | INFO | [Main] Spawning worker 20 for Unity env (seed=20). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 12:28:20,441 | INFO | [Main] Worker 20 started (pid=85612).
2025-12-30 12:28:24,541 | INFO | [default | seed 20] Environment batched agents (train): 20
2025-12-30 12:28:57,818 | INFO | [default | seed 20] Environment batched agents (eval): 20
2025-12-30 12:29:15,833 | INFO | [default | seed 20] elapsed_time 00:00:55, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 14.500000, episode_sum_max_abs_reward_per_step 14.500000, mean_reward_over_100_episodes_from_training 00.86±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0000, mean_reward_over_100_episodes_from_eval 01.03±00.00
2025-12-30 12:30:08,354 | INFO | [default | seed 20] elapsed_time 00:01:47, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 15.910000, episode_sum_max_abs_reward_per_step 15.910000, mean_reward_over_100_episodes_from_training 00.97±00.11, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0002, mean_reward_over_100_episodes_from_eval 00.91±00.12
2025-12-30 12:31:00,082 | INFO | [default | seed 20] elapsed_time 00:02:39, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 09.940000, episode_sum_max_abs_reward_per_step 09.940000, mean_reward_over_100_episodes_from_training 00.83±00.21, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0005, mean_reward_over_100_episodes_from_eval 00.90±00.10
2025-12-30 12:31:53,978 | INFO | [default | seed 20] elapsed_time 00:03:33, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 21.910000, episode_sum_max_abs_reward_per_step 21.910000, mean_reward_over_100_episodes_from_training 01.02±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0005, mean_reward_over_100_episodes_from_eval 01.06±00.29
2025-12-30 12:32:49,599 | INFO | [default | seed 20] elapsed_time 00:04:29, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 25.129999, episode_sum_max_abs_reward_per_step 25.129999, mean_reward_over_100_episodes_from_training 01.23±00.54, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0005, mean_reward_over_100_episodes_from_eval 01.19±00.37
2025-12-30 12:33:45,833 | INFO | [default | seed 20] elapsed_time 00:05:25, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 27.309999, episode_sum_max_abs_reward_per_step 27.309999, mean_reward_over_100_episodes_from_training 01.40±00.62, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0005, mean_reward_over_100_episodes_from_eval 01.27±00.38
2025-12-30 12:34:42,859 | INFO | [default | seed 20] elapsed_time 00:06:22, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 30.649999, episode_sum_max_abs_reward_per_step 30.649999, mean_reward_over_100_episodes_from_training 01.61±00.77, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0006, mean_reward_over_100_episodes_from_eval 01.67±01.05
2025-12-30 12:35:38,418 | INFO | [default | seed 20] elapsed_time 00:07:18, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 33.939999, episode_sum_max_abs_reward_per_step 33.939999, mean_reward_over_100_episodes_from_training 01.89±01.04, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0006, mean_reward_over_100_episodes_from_eval 02.05±01.39
2025-12-30 12:37:02,150 | INFO | [default | seed 20] elapsed_time 00:08:41, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 38.899999, episode_sum_max_abs_reward_per_step 38.899999, mean_reward_over_100_episodes_from_training 02.40±01.75, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0005, mean_reward_over_100_episodes_from_eval 02.72±02.32
2025-12-30 12:38:00,753 | INFO | [default | seed 20] elapsed_time 00:09:40, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 03.00±02.45, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0005, mean_reward_over_100_episodes_from_eval 03.52±03.26
2025-12-30 12:39:01,827 | INFO | [default | seed 20] elapsed_time 00:10:41, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 38.969999, episode_sum_max_abs_reward_per_step 38.969999, mean_reward_over_100_episodes_from_training 03.64±03.08, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0005, mean_reward_over_100_episodes_from_eval 04.23±03.83
2025-12-30 12:40:18,808 | INFO | [default | seed 20] elapsed_time 00:11:58, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 04.43±03.96, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0005, mean_reward_over_100_episodes_from_eval 05.10±04.65
2025-12-30 12:41:19,994 | INFO | [default | seed 20] elapsed_time 00:12:59, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 05.42±05.12, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0007, mean_reward_over_100_episodes_from_eval 06.45±06.47
2025-12-30 12:42:16,255 | INFO | [default | seed 20] elapsed_time 00:13:55, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 06.77±06.92, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0008, mean_reward_over_100_episodes_from_eval 07.96±08.27
2025-12-30 12:43:14,224 | INFO | [default | seed 20] elapsed_time 00:14:53, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 08.42±09.11, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0009, mean_reward_over_100_episodes_from_eval 09.75±10.44
2025-12-30 12:44:12,675 | INFO | [default | seed 20] elapsed_time 00:15:52, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 10.17±11.12, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0014, mean_reward_over_100_episodes_from_eval 11.40±11.96
2025-12-30 12:45:27,700 | INFO | [default | seed 20] elapsed_time 00:17:07, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 11.75±12.50, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0016, mean_reward_over_100_episodes_from_eval 12.94±13.13
2025-12-30 12:46:23,565 | INFO | [default | seed 20] elapsed_time 00:18:03, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 13.17±13.49, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0018, mean_reward_over_100_episodes_from_eval 14.30±13.94
2025-12-30 12:47:20,891 | INFO | [default | seed 20] elapsed_time 00:19:00, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 14.42±14.15, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0018, mean_reward_over_100_episodes_from_eval 15.44±14.40
2025-12-30 12:48:14,668 | INFO | [default | seed 20] elapsed_time 00:19:54, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 15.49±14.56, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0018, mean_reward_over_100_episodes_from_eval 16.52±14.82
2025-12-30 12:49:09,077 | INFO | [default | seed 20] elapsed_time 00:20:48, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 16.33±14.70, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0018, mean_reward_over_100_episodes_from_eval 17.37±14.94
2025-12-30 12:50:03,298 | INFO | [default | seed 20] elapsed_time 00:21:42, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 17.09±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0017, mean_reward_over_100_episodes_from_eval 18.09±14.97
2025-12-30 12:50:58,848 | INFO | [default | seed 20] elapsed_time 00:22:38, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 17.93±14.99, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0018, mean_reward_over_100_episodes_from_eval 18.88±15.10
2025-12-30 12:51:56,011 | INFO | [default | seed 20] elapsed_time 00:23:35, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 18.66±15.08, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0018, mean_reward_over_100_episodes_from_eval 19.65±15.23
2025-12-30 12:52:53,420 | INFO | [default | seed 20] elapsed_time 00:24:33, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 19.37±15.18, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0018, mean_reward_over_100_episodes_from_eval 20.21±15.18
2025-12-30 12:53:49,972 | INFO | [default | seed 20] elapsed_time 00:25:29, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 20.04±15.26, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0018, mean_reward_over_100_episodes_from_eval 20.85±15.23
2025-12-30 12:55:04,643 | INFO | [default | seed 20] elapsed_time 00:26:44, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 20.59±15.23, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0018, mean_reward_over_100_episodes_from_eval 21.42±15.22
2025-12-30 12:55:58,672 | INFO | [default | seed 20] elapsed_time 00:27:38, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.04±15.14, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0018, mean_reward_over_100_episodes_from_eval 21.82±15.09
2025-12-30 12:56:52,129 | INFO | [default | seed 20] elapsed_time 00:28:31, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 21.53±15.10, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0017, mean_reward_over_100_episodes_from_eval 22.25±15.00
2025-12-30 12:57:46,255 | INFO | [default | seed 20] elapsed_time 00:29:25, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 22.00±15.06, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0017, mean_reward_over_100_episodes_from_eval 22.76±15.01
2025-12-30 12:58:40,366 | INFO | [default | seed 20] elapsed_time 00:30:19, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 22.37±14.95, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0017, mean_reward_over_100_episodes_from_eval 23.20±14.96
2025-12-30 12:59:34,923 | INFO | [default | seed 20] elapsed_time 00:31:14, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 22.79±14.90, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0017, mean_reward_over_100_episodes_from_eval 23.62±14.90
2025-12-30 13:00:30,658 | INFO | [default | seed 20] elapsed_time 00:32:10, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 23.11±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0017, mean_reward_over_100_episodes_from_eval 23.99±14.82
2025-12-30 13:01:27,134 | INFO | [default | seed 20] elapsed_time 00:33:06, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 23.37±14.64, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0016, mean_reward_over_100_episodes_from_eval 24.32±14.73
2025-12-30 13:02:27,984 | INFO | [default | seed 20] elapsed_time 00:34:07, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.53±14.46, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0017, mean_reward_over_100_episodes_from_eval 24.42±14.53
2025-12-30 13:03:41,526 | INFO | [default | seed 20] elapsed_time 00:35:21, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 23.77±14.33, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0017, mean_reward_over_100_episodes_from_eval 24.77±14.47
2025-12-30 13:04:43,901 | INFO | [default | seed 20] elapsed_time 00:36:23, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 24.03±14.22, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0017, mean_reward_over_100_episodes_from_eval 25.00±14.34
2025-12-30 13:05:36,955 | INFO | [default | seed 20] elapsed_time 00:37:16, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.31±14.14, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0017, mean_reward_over_100_episodes_from_eval 25.33±14.30
2025-12-30 13:06:30,326 | INFO | [default | seed 20] elapsed_time 00:38:09, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 24.59±14.06, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0017, mean_reward_over_100_episodes_from_eval 25.63±14.23
2025-12-30 13:07:26,525 | INFO | [default | seed 20] elapsed_time 00:39:06, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 24.80±13.95, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0017, mean_reward_over_100_episodes_from_eval 25.86±14.13
2025-12-30 13:08:22,071 | INFO | [default | seed 20] elapsed_time 00:40:01, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 25.07±13.88, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0018, mean_reward_over_100_episodes_from_eval 26.11±14.04
2025-12-30 13:09:17,979 | INFO | [default | seed 20] elapsed_time 00:40:57, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 25.31±13.80, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0018, mean_reward_over_100_episodes_from_eval 26.40±14.00
2025-12-30 13:10:13,969 | INFO | [default | seed 20] elapsed_time 00:41:53, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 25.56±13.73, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0018, mean_reward_over_100_episodes_from_eval 26.65±13.93
2025-12-30 13:11:09,480 | INFO | [default | seed 20] elapsed_time 00:42:49, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.75±13.63, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0018, mean_reward_over_100_episodes_from_eval 26.77±13.79
2025-12-30 13:12:04,218 | INFO | [default | seed 20] elapsed_time 00:43:43, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.95±13.54, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0018, mean_reward_over_100_episodes_from_eval 26.93±13.68
2025-12-30 13:12:59,814 | INFO | [default | seed 20] elapsed_time 00:44:39, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.15±13.47, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0018, mean_reward_over_100_episodes_from_eval 27.05±13.55
2025-12-30 13:13:56,269 | INFO | [default | seed 20] elapsed_time 00:45:35, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.30±13.36, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0019, mean_reward_over_100_episodes_from_eval 27.19±13.44
2025-12-30 13:14:52,986 | INFO | [default | seed 20] elapsed_time 00:46:32, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.41±13.24, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0019, mean_reward_over_100_episodes_from_eval 27.22±13.30
2025-12-30 13:15:49,091 | INFO | [default | seed 20] elapsed_time 00:47:28, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.53±13.13, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0019, mean_reward_over_100_episodes_from_eval 27.37±13.20
2025-12-30 13:16:45,217 | INFO | [default | seed 20] elapsed_time 00:48:24, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.72±13.07, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0019, mean_reward_over_100_episodes_from_eval 27.56±13.14
2025-12-30 13:17:41,143 | INFO | [default | seed 20] elapsed_time 00:49:20, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.90±13.00, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0019, mean_reward_over_100_episodes_from_eval 27.69±13.04
2025-12-30 13:18:35,851 | INFO | [default | seed 20] elapsed_time 00:50:15, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.09±12.95, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0019, mean_reward_over_100_episodes_from_eval 27.88±12.99
2025-12-30 13:19:31,263 | INFO | [default | seed 20] elapsed_time 00:51:10, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.26±12.89, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0020, mean_reward_over_100_episodes_from_eval 28.03±12.92
2025-12-30 13:20:26,544 | INFO | [default | seed 20] elapsed_time 00:52:06, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.39±12.80, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0020, mean_reward_over_100_episodes_from_eval 28.16±12.83
2025-12-30 13:21:23,077 | INFO | [default | seed 20] elapsed_time 00:53:02, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.53±12.73, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0020, mean_reward_over_100_episodes_from_eval 28.26±12.73
2025-12-30 13:22:21,569 | INFO | [default | seed 20] elapsed_time 00:54:01, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 27.68±12.66, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0020, mean_reward_over_100_episodes_from_eval 28.44±12.69
2025-12-30 13:23:19,142 | INFO | [default | seed 20] elapsed_time 00:54:58, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 27.82±12.59, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0020, mean_reward_over_100_episodes_from_eval 28.59±12.63
2025-12-30 13:24:16,528 | INFO | [default | seed 20] elapsed_time 00:55:56, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.93±12.51, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0020, mean_reward_over_100_episodes_from_eval 28.73±12.56
2025-12-30 13:25:13,151 | INFO | [default | seed 20] elapsed_time 00:56:52, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.749999, episode_sum_max_abs_reward_per_step 39.749999, mean_reward_over_100_episodes_from_training 27.99±12.41, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0020, mean_reward_over_100_episodes_from_eval 28.73±12.45
2025-12-30 13:26:10,819 | INFO | [default | seed 20] elapsed_time 00:57:50, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.08±12.32, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0020, mean_reward_over_100_episodes_from_eval 28.80±12.36
2025-12-30 13:27:08,075 | INFO | [default | seed 20] elapsed_time 00:58:47, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 28.14±12.23, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0021, mean_reward_over_100_episodes_from_eval 28.91±12.29
2025-12-30 13:28:05,058 | INFO | [default | seed 20] elapsed_time 00:59:44, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.23±12.15, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 28.90±12.19
2025-12-30 13:29:01,549 | INFO | [default | seed 20] elapsed_time 01:00:41, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.32±12.08, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 28.97±12.11
2025-12-30 13:30:01,617 | INFO | [default | seed 20] elapsed_time 01:01:41, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.37±11.99, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 29.02±12.02
2025-12-30 13:30:58,093 | INFO | [default | seed 20] elapsed_time 01:02:37, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.46±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0021, mean_reward_over_100_episodes_from_eval 29.10±11.94
2025-12-30 13:31:54,627 | INFO | [default | seed 20] elapsed_time 01:03:34, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.54±11.85, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0021, mean_reward_over_100_episodes_from_eval 29.17±11.86
2025-12-30 13:32:51,032 | INFO | [default | seed 20] elapsed_time 01:04:30, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.64±11.79, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0021, mean_reward_over_100_episodes_from_eval 29.27±11.80
2025-12-30 13:33:47,120 | INFO | [default | seed 20] elapsed_time 01:05:26, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.77±11.74, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0021, mean_reward_over_100_episodes_from_eval 29.39±11.76
2025-12-30 13:34:46,166 | INFO | [default | seed 20] elapsed_time 01:06:25, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.89±11.70, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0021, mean_reward_over_100_episodes_from_eval 29.50±11.71
2025-12-30 13:35:42,945 | INFO | [default | seed 20] elapsed_time 01:07:22, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.749999, episode_sum_max_abs_reward_per_step 39.749999, mean_reward_over_100_episodes_from_training 29.00±11.65, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0021, mean_reward_over_100_episodes_from_eval 29.58±11.64
2025-12-30 13:36:39,024 | INFO | [default | seed 20] elapsed_time 01:08:18, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.07±11.59, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0021, mean_reward_over_100_episodes_from_eval 29.67±11.58
2025-12-30 13:37:36,801 | INFO | [default | seed 20] elapsed_time 01:09:16, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.09±11.51, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0021, mean_reward_over_100_episodes_from_eval 29.73±11.51
2025-12-30 13:38:32,807 | INFO | [default | seed 20] elapsed_time 01:10:12, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.17±11.45, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0021, mean_reward_over_100_episodes_from_eval 29.83±11.46
2025-12-30 13:39:29,543 | INFO | [default | seed 20] elapsed_time 01:11:09, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.23±11.38, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0021, mean_reward_over_100_episodes_from_eval 29.90±11.40
2025-12-30 13:40:25,596 | INFO | [default | seed 20] elapsed_time 01:12:05, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.28±11.31, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0022, mean_reward_over_100_episodes_from_eval 29.99±11.36
2025-12-30 13:41:23,601 | INFO | [default | seed 20] elapsed_time 01:13:03, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.35±11.25, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 30.10±11.32
2025-12-30 13:42:19,415 | INFO | [default | seed 20] elapsed_time 01:13:59, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 29.39±11.18, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 30.16±11.26
2025-12-30 13:43:15,446 | INFO | [default | seed 20] elapsed_time 01:14:55, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.44±11.12, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 30.18±11.19
2025-12-30 13:44:12,907 | INFO | [default | seed 20] elapsed_time 01:15:52, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.50±11.06, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0022, mean_reward_over_100_episodes_from_eval 30.21±11.12
2025-12-30 13:45:08,908 | INFO | [default | seed 20] elapsed_time 01:16:48, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.54±11.00, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 30.26±11.06
2025-12-30 13:46:04,522 | INFO | [default | seed 20] elapsed_time 01:17:44, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.58±10.94, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 30.30±11.00
2025-12-30 13:47:00,129 | INFO | [default | seed 20] elapsed_time 01:18:39, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 29.66±10.89, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0022, mean_reward_over_100_episodes_from_eval 30.37±10.95
2025-12-30 13:47:56,507 | INFO | [default | seed 20] elapsed_time 01:19:36, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.74±10.85, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 30.45±10.90
2025-12-30 13:48:54,249 | INFO | [default | seed 20] elapsed_time 01:20:33, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 29.80±10.81, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 30.48±10.84
2025-12-30 13:49:50,627 | INFO | [default | seed 20] elapsed_time 01:21:30, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.87±10.76, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 30.55±10.80
2025-12-30 13:50:47,952 | INFO | [default | seed 20] elapsed_time 01:22:27, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.94±10.71, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0022, mean_reward_over_100_episodes_from_eval 30.59±10.74
2025-12-30 13:51:44,103 | INFO | [default | seed 20] elapsed_time 01:23:23, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.00±10.67, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 30.67±10.70
2025-12-30 13:52:41,385 | INFO | [default | seed 20] elapsed_time 01:24:20, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.07±10.63, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 30.72±10.65
2025-12-30 13:53:38,175 | INFO | [default | seed 20] elapsed_time 01:25:17, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 30.13±10.58, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 30.77±10.60
2025-12-30 13:54:33,209 | INFO | [default | seed 20] elapsed_time 01:26:12, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 30.13±10.52, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0022, mean_reward_over_100_episodes_from_eval 30.70±10.57
2025-12-30 13:55:28,374 | INFO | [default | seed 20] elapsed_time 01:27:07, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 30.11±10.47, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 30.72±10.51
2025-12-30 13:56:24,982 | INFO | [default | seed 20] elapsed_time 01:28:04, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.15±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 30.76±10.47
2025-12-30 13:57:21,769 | INFO | [default | seed 20] elapsed_time 01:29:01, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.19±10.36, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 30.80±10.42
2025-12-30 13:58:17,936 | INFO | [default | seed 20] elapsed_time 01:29:57, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.24±10.32, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0022, mean_reward_over_100_episodes_from_eval 30.87±10.38
2025-12-30 13:59:13,665 | INFO | [default | seed 20] elapsed_time 01:30:53, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 30.32±10.30, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 30.89±10.33
2025-12-30 14:00:09,790 | INFO | [default | seed 20] elapsed_time 01:31:49, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.38±10.26, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 30.93±10.28
2025-12-30 14:01:05,396 | INFO | [default | seed 20] elapsed_time 01:32:44, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.42±10.22, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 30.95±10.23
2025-12-30 14:02:02,439 | INFO | [default | seed 20] elapsed_time 01:33:42, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.46±10.17, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 30.94±10.18
2025-12-30 14:02:59,325 | INFO | [default | seed 20] elapsed_time 01:34:38, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.46±10.12, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0022, mean_reward_over_100_episodes_from_eval 30.94±10.13
2025-12-30 14:03:55,422 | INFO | [default | seed 20] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=31.00
2025-12-30 14:03:55,424 | INFO | [default | seed 20] elapsed_time 01:35:35, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.51±10.08, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0022, mean_reward_over_100_episodes_from_eval 31.00±10.09
2025-12-30 14:03:55,424 | INFO | [default | seed 20] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 14:33:02,811 | INFO | [default | seed 20] Training complete.
2025-12-30 14:33:02,811 | INFO | [default | seed 20] Solved (evaluation metric) at episode 100.
2025-12-30 14:33:02,811 | INFO | [default | seed 20] Final evaluation score 34.86±1.25 in 3888.65s training, 7482.40s wall.
2025-12-30 14:33:02,811 | INFO | [default | seed 20] Closing UnityVectorEnv (worker_id=20).
2025-12-30 14:33:02,812 | INFO | [Main] Requesting worker 20 to close Unity env.
2025-12-30 14:33:03,643 | INFO | [Main] Worker 20 joined. Unity env fully closed.
2025-12-30 14:33:03,643 | INFO | [default | seed 20] Final eval score: 34.86
2025-12-30 14:33:04,023 | INFO | [default | seed 20] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_20.png
2025-12-30 14:33:04,023 | INFO | [default | seed 20] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 14:33:04,235 | INFO | [default | seed 44] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 14:33:04,237 | INFO | [default | seed 44] === Starting run for seed 44 ===
2025-12-30 14:33:04,237 | INFO | [default | seed 44] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 14:33:04,239 | INFO | [default | seed 44] Launching UnityVectorEnv with worker_id=44, seed=44
2025-12-30 14:33:04,241 | INFO | [Main] Spawning worker 44 for Unity env (seed=44). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 14:33:04,275 | INFO | [Main] Worker 44 started (pid=87644).
2025-12-30 14:33:15,332 | INFO | [default | seed 44] Environment batched agents (train): 20
2025-12-30 14:33:47,324 | INFO | [default | seed 44] Environment batched agents (eval): 20
2025-12-30 14:34:03,624 | INFO | [default | seed 44] elapsed_time 00:00:59, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 02.170000, episode_sum_max_abs_reward_per_step 02.170000, mean_reward_over_100_episodes_from_training 00.12±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0114±0.0000, mean_reward_over_100_episodes_from_eval 00.08±00.00
2025-12-30 14:34:55,706 | INFO | [default | seed 44] elapsed_time 00:01:51, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 00.290000, episode_sum_max_abs_reward_per_step 00.290000, mean_reward_over_100_episodes_from_training 00.08±00.04, mean_exploration_ratio_over_100_episodes_from_training 0.0105±0.0009, mean_reward_over_100_episodes_from_eval 00.11±00.02
2025-12-30 14:35:47,967 | INFO | [default | seed 44] elapsed_time 00:02:43, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 00.980000, episode_sum_max_abs_reward_per_step 00.980000, mean_reward_over_100_episodes_from_training 00.07±00.04, mean_exploration_ratio_over_100_episodes_from_training 0.0106±0.0007, mean_reward_over_100_episodes_from_eval 00.09±00.03
2025-12-30 14:36:43,620 | INFO | [default | seed 44] elapsed_time 00:03:39, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 01.330000, episode_sum_max_abs_reward_per_step 01.330000, mean_reward_over_100_episodes_from_training 00.07±00.03, mean_exploration_ratio_over_100_episodes_from_training 0.0106±0.0006, mean_reward_over_100_episodes_from_eval 00.19±00.18
2025-12-30 14:37:41,011 | INFO | [default | seed 44] elapsed_time 00:04:36, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 05.700000, episode_sum_max_abs_reward_per_step 05.700000, mean_reward_over_100_episodes_from_training 00.13±00.12, mean_exploration_ratio_over_100_episodes_from_training 0.0108±0.0007, mean_reward_over_100_episodes_from_eval 00.20±00.16
2025-12-30 14:38:35,741 | INFO | [default | seed 44] elapsed_time 00:05:31, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 06.230000, episode_sum_max_abs_reward_per_step 06.230000, mean_reward_over_100_episodes_from_training 00.16±00.14, mean_exploration_ratio_over_100_episodes_from_training 0.0112±0.0011, mean_reward_over_100_episodes_from_eval 00.34±00.35
2025-12-30 14:39:32,442 | INFO | [default | seed 44] elapsed_time 00:06:28, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 19.460000, episode_sum_max_abs_reward_per_step 19.460000, mean_reward_over_100_episodes_from_training 00.32±00.40, mean_exploration_ratio_over_100_episodes_from_training 0.0114±0.0012, mean_reward_over_100_episodes_from_eval 00.47±00.46
2025-12-30 14:40:28,836 | INFO | [default | seed 44] elapsed_time 00:07:24, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 17.980000, episode_sum_max_abs_reward_per_step 17.980000, mean_reward_over_100_episodes_from_training 00.43±00.48, mean_exploration_ratio_over_100_episodes_from_training 0.0116±0.0012, mean_reward_over_100_episodes_from_eval 00.58±00.52
2025-12-30 14:41:25,910 | INFO | [default | seed 44] elapsed_time 00:08:21, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 25.499999, episode_sum_max_abs_reward_per_step 25.499999, mean_reward_over_100_episodes_from_training 00.60±00.66, mean_exploration_ratio_over_100_episodes_from_training 0.0117±0.0012, mean_reward_over_100_episodes_from_eval 00.70±00.59
2025-12-30 14:42:22,308 | INFO | [default | seed 44] elapsed_time 00:09:18, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 25.629999, episode_sum_max_abs_reward_per_step 25.629999, mean_reward_over_100_episodes_from_training 00.74±00.75, mean_exploration_ratio_over_100_episodes_from_training 0.0119±0.0012, mean_reward_over_100_episodes_from_eval 00.83±00.69
2025-12-30 14:43:18,143 | INFO | [default | seed 44] elapsed_time 00:10:13, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 27.529999, episode_sum_max_abs_reward_per_step 27.529999, mean_reward_over_100_episodes_from_training 00.92±00.92, mean_exploration_ratio_over_100_episodes_from_training 0.0119±0.0012, mean_reward_over_100_episodes_from_eval 01.06±00.97
2025-12-30 14:44:14,446 | INFO | [default | seed 44] elapsed_time 00:11:10, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 35.609999, episode_sum_max_abs_reward_per_step 35.609999, mean_reward_over_100_episodes_from_training 01.17±01.21, mean_exploration_ratio_over_100_episodes_from_training 0.0120±0.0011, mean_reward_over_100_episodes_from_eval 01.31±01.25
2025-12-30 14:45:10,407 | INFO | [default | seed 44] elapsed_time 00:12:06, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 36.809999, episode_sum_max_abs_reward_per_step 36.809999, mean_reward_over_100_episodes_from_training 01.46±01.53, mean_exploration_ratio_over_100_episodes_from_training 0.0120±0.0011, mean_reward_over_100_episodes_from_eval 01.74±01.91
2025-12-30 14:46:06,179 | INFO | [default | seed 44] elapsed_time 00:13:01, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 38.569999, episode_sum_max_abs_reward_per_step 38.569999, mean_reward_over_100_episodes_from_training 01.78±01.88, mean_exploration_ratio_over_100_episodes_from_training 0.0121±0.0011, mean_reward_over_100_episodes_from_eval 01.95±01.98
2025-12-30 14:47:02,548 | INFO | [default | seed 44] elapsed_time 00:13:58, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 38.579999, episode_sum_max_abs_reward_per_step 38.579999, mean_reward_over_100_episodes_from_training 02.23±02.47, mean_exploration_ratio_over_100_episodes_from_training 0.0121±0.0011, mean_reward_over_100_episodes_from_eval 02.34±02.41
2025-12-30 14:47:58,566 | INFO | [default | seed 44] elapsed_time 00:14:54, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.369999, episode_sum_max_abs_reward_per_step 39.369999, mean_reward_over_100_episodes_from_training 02.69±02.99, mean_exploration_ratio_over_100_episodes_from_training 0.0122±0.0011, mean_reward_over_100_episodes_from_eval 02.87±03.13
2025-12-30 14:48:55,976 | INFO | [default | seed 44] elapsed_time 00:15:51, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 03.26±03.67, mean_exploration_ratio_over_100_episodes_from_training 0.0123±0.0011, mean_reward_over_100_episodes_from_eval 03.53±04.02
2025-12-30 14:49:51,888 | INFO | [default | seed 44] elapsed_time 00:16:47, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 03.91±04.47, mean_exploration_ratio_over_100_episodes_from_training 0.0124±0.0011, mean_reward_over_100_episodes_from_eval 04.33±05.12
2025-12-30 14:50:47,841 | INFO | [default | seed 44] elapsed_time 00:17:43, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 04.81±05.77, mean_exploration_ratio_over_100_episodes_from_training 0.0125±0.0012, mean_reward_over_100_episodes_from_eval 05.27±06.37
2025-12-30 14:51:43,930 | INFO | [default | seed 44] elapsed_time 00:18:39, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 05.98±07.60, mean_exploration_ratio_over_100_episodes_from_training 0.0126±0.0013, mean_reward_over_100_episodes_from_eval 06.49±08.17
2025-12-30 14:52:40,721 | INFO | [default | seed 44] elapsed_time 00:19:36, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 07.24±09.31, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0013, mean_reward_over_100_episodes_from_eval 07.78±09.84
2025-12-30 14:53:36,451 | INFO | [default | seed 44] elapsed_time 00:20:32, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 08.52±10.84, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0016, mean_reward_over_100_episodes_from_eval 09.01±11.15
2025-12-30 14:54:33,716 | INFO | [default | seed 44] elapsed_time 00:21:29, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 09.65±11.86, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0016, mean_reward_over_100_episodes_from_eval 10.21±12.26
2025-12-30 14:55:30,538 | INFO | [default | seed 44] elapsed_time 00:22:26, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 10.78±12.81, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0017, mean_reward_over_100_episodes_from_eval 11.35±13.21
2025-12-30 14:56:26,795 | INFO | [default | seed 44] elapsed_time 00:23:22, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 11.85±13.59, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0017, mean_reward_over_100_episodes_from_eval 12.38±13.89
2025-12-30 14:57:23,395 | INFO | [default | seed 44] elapsed_time 00:24:19, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 12.80±14.15, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0017, mean_reward_over_100_episodes_from_eval 13.37±14.48
2025-12-30 14:58:20,066 | INFO | [default | seed 44] elapsed_time 00:25:15, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 13.71±14.64, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0018, mean_reward_over_100_episodes_from_eval 14.26±14.92
2025-12-30 14:59:16,728 | INFO | [default | seed 44] elapsed_time 00:26:12, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 14.46±14.90, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 14.96±15.10
2025-12-30 15:00:13,650 | INFO | [default | seed 44] elapsed_time 00:27:09, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 15.25±15.21, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 15.65±15.28
2025-12-30 15:01:09,507 | INFO | [default | seed 44] elapsed_time 00:28:05, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 15.91±15.39, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0018, mean_reward_over_100_episodes_from_eval 16.26±15.37
2025-12-30 15:02:05,939 | INFO | [default | seed 44] elapsed_time 00:29:01, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 16.51±15.49, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0018, mean_reward_over_100_episodes_from_eval 16.90±15.52
2025-12-30 15:03:01,521 | INFO | [default | seed 44] elapsed_time 00:29:57, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 17.12±15.62, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0017, mean_reward_over_100_episodes_from_eval 17.58±15.74
2025-12-30 15:03:58,417 | INFO | [default | seed 44] elapsed_time 00:30:54, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 17.67±15.69, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 18.11±15.79
2025-12-30 15:04:54,015 | INFO | [default | seed 44] elapsed_time 00:31:49, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 18.21±15.76, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 18.66±15.87
2025-12-30 15:05:50,458 | INFO | [default | seed 44] elapsed_time 00:32:46, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 18.68±15.78, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 19.14±15.89
2025-12-30 15:06:46,496 | INFO | [default | seed 44] elapsed_time 00:33:42, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 19.09±15.74, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 19.47±15.79
2025-12-30 15:07:43,748 | INFO | [default | seed 44] elapsed_time 00:34:39, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 19.53±15.75, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 19.91±15.80
2025-12-30 15:08:39,857 | INFO | [default | seed 44] elapsed_time 00:35:35, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 19.97±15.78, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 20.37±15.84
2025-12-30 15:09:36,641 | INFO | [default | seed 44] elapsed_time 00:36:32, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 20.31±15.71, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 20.71±15.77
2025-12-30 15:10:33,123 | INFO | [default | seed 44] elapsed_time 00:37:28, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.61±15.63, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 20.90±15.62
2025-12-30 15:11:29,265 | INFO | [default | seed 44] elapsed_time 00:38:25, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 20.92±15.56, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 21.28±15.61
2025-12-30 15:12:25,661 | INFO | [default | seed 44] elapsed_time 00:39:21, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 21.24±15.51, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 21.62±15.58
2025-12-30 15:13:21,435 | INFO | [default | seed 44] elapsed_time 00:40:17, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 21.52±15.43, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 21.88±15.49
2025-12-30 15:14:17,895 | INFO | [default | seed 44] elapsed_time 00:41:13, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 21.83±15.39, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 22.15±15.42
2025-12-30 15:15:15,175 | INFO | [default | seed 44] elapsed_time 00:42:10, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 22.12±15.34, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0016, mean_reward_over_100_episodes_from_eval 22.45±15.37
2025-12-30 15:16:12,258 | INFO | [default | seed 44] elapsed_time 00:43:08, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.37±15.27, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0015, mean_reward_over_100_episodes_from_eval 22.66±15.27
2025-12-30 15:17:09,090 | INFO | [default | seed 44] elapsed_time 00:44:04, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.65±15.22, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0015, mean_reward_over_100_episodes_from_eval 22.95±15.23
2025-12-30 15:18:03,925 | INFO | [default | seed 44] elapsed_time 00:44:59, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 22.90±15.16, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0015, mean_reward_over_100_episodes_from_eval 23.21±15.18
2025-12-30 15:18:59,986 | INFO | [default | seed 44] elapsed_time 00:45:55, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 23.13±15.09, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0015, mean_reward_over_100_episodes_from_eval 23.50±15.15
2025-12-30 15:19:57,022 | INFO | [default | seed 44] elapsed_time 00:46:52, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.39±15.05, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0015, mean_reward_over_100_episodes_from_eval 23.70±15.07
2025-12-30 15:20:53,297 | INFO | [default | seed 44] elapsed_time 00:47:49, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 23.62±14.99, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0015, mean_reward_over_100_episodes_from_eval 23.90±14.99
2025-12-30 15:21:49,755 | INFO | [default | seed 44] elapsed_time 00:48:45, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.83±14.92, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0015, mean_reward_over_100_episodes_from_eval 24.14±14.94
2025-12-30 15:22:47,270 | INFO | [default | seed 44] elapsed_time 00:49:43, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 24.01±14.83, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0015, mean_reward_over_100_episodes_from_eval 24.27±14.83
2025-12-30 15:23:43,524 | INFO | [default | seed 44] elapsed_time 00:50:39, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.24±14.79, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0015, mean_reward_over_100_episodes_from_eval 24.52±14.81
2025-12-30 15:24:38,062 | INFO | [default | seed 44] elapsed_time 00:51:33, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.44±14.73, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0015, mean_reward_over_100_episodes_from_eval 24.76±14.77
2025-12-30 15:25:35,661 | INFO | [default | seed 44] elapsed_time 00:52:31, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.61±14.65, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0015, mean_reward_over_100_episodes_from_eval 24.97±14.72
2025-12-30 15:26:32,628 | INFO | [default | seed 44] elapsed_time 00:53:28, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 24.81±14.60, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0015, mean_reward_over_100_episodes_from_eval 25.18±14.68
2025-12-30 15:27:30,587 | INFO | [default | seed 44] elapsed_time 00:54:26, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 24.96±14.52, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0015, mean_reward_over_100_episodes_from_eval 25.32±14.59
2025-12-30 15:28:26,167 | INFO | [default | seed 44] elapsed_time 00:55:21, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.10±14.43, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 25.50±14.53
2025-12-30 15:29:23,285 | INFO | [default | seed 44] elapsed_time 00:56:19, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 25.24±14.35, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 25.67±14.47
2025-12-30 15:30:20,850 | INFO | [default | seed 44] elapsed_time 00:57:16, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.40±14.28, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 25.81±14.39
2025-12-30 15:31:17,951 | INFO | [default | seed 44] elapsed_time 00:58:13, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.56±14.22, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 25.98±14.33
2025-12-30 15:32:13,363 | INFO | [default | seed 44] elapsed_time 00:59:09, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 25.73±14.18, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 26.16±14.29
2025-12-30 15:33:08,607 | INFO | [default | seed 44] elapsed_time 01:00:04, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.90±14.13, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0014, mean_reward_over_100_episodes_from_eval 26.32±14.24
2025-12-30 15:34:05,711 | INFO | [default | seed 44] elapsed_time 01:01:01, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.05±14.07, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 26.48±14.18
2025-12-30 15:35:04,378 | INFO | [default | seed 44] elapsed_time 01:02:00, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.19±14.01, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 26.57±14.09
2025-12-30 15:36:00,687 | INFO | [default | seed 44] elapsed_time 01:02:56, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 26.29±13.93, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0014, mean_reward_over_100_episodes_from_eval 26.63±14.00
2025-12-30 15:36:57,719 | INFO | [default | seed 44] elapsed_time 01:03:53, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 26.37±13.84, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0013, mean_reward_over_100_episodes_from_eval 26.74±13.93
2025-12-30 15:37:55,233 | INFO | [default | seed 44] elapsed_time 01:04:50, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.53±13.80, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 26.89±13.88
2025-12-30 15:38:52,308 | INFO | [default | seed 44] elapsed_time 01:05:48, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.63±13.73, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 26.97±13.79
2025-12-30 15:39:50,529 | INFO | [default | seed 44] elapsed_time 01:06:46, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 26.72±13.65, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.06±13.72
2025-12-30 15:40:47,401 | INFO | [default | seed 44] elapsed_time 01:07:43, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.77±13.56, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.13±13.63
2025-12-30 15:41:46,296 | INFO | [default | seed 44] elapsed_time 01:08:42, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.85±13.49, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.22±13.56
2025-12-30 15:42:42,819 | INFO | [default | seed 44] elapsed_time 01:09:38, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.89±13.40, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.33±13.50
2025-12-30 15:43:38,191 | INFO | [default | seed 44] elapsed_time 01:10:33, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 27.02±13.36, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.44±13.44
2025-12-30 15:44:33,965 | INFO | [default | seed 44] elapsed_time 01:11:29, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.14±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.57±13.40
2025-12-30 15:45:31,118 | INFO | [default | seed 44] elapsed_time 01:12:26, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 27.21±13.24, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.66±13.34
2025-12-30 15:46:28,774 | INFO | [default | seed 44] elapsed_time 01:13:24, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.26±13.16, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.71±13.26
2025-12-30 15:47:24,759 | INFO | [default | seed 44] elapsed_time 01:14:20, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.35±13.10, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.81±13.21
2025-12-30 15:48:21,006 | INFO | [default | seed 44] elapsed_time 01:15:16, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.46±13.06, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 27.91±13.15
2025-12-30 15:49:16,793 | INFO | [default | seed 44] elapsed_time 01:16:12, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.51±12.98, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 27.98±13.09
2025-12-30 15:50:13,426 | INFO | [default | seed 44] elapsed_time 01:17:09, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.55±12.91, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.03±13.01
2025-12-30 15:51:08,985 | INFO | [default | seed 44] elapsed_time 01:18:04, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.62±12.84, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.10±12.95
2025-12-30 15:52:05,423 | INFO | [default | seed 44] elapsed_time 01:19:01, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.68±12.78, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.13±12.88
2025-12-30 15:53:03,849 | INFO | [default | seed 44] elapsed_time 01:19:59, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 27.72±12.71, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.20±12.81
2025-12-30 15:54:00,377 | INFO | [default | seed 44] elapsed_time 01:20:56, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.78±12.65, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.27±12.76
2025-12-30 15:54:58,070 | INFO | [default | seed 44] elapsed_time 01:21:53, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.85±12.59, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.33±12.70
2025-12-30 15:55:54,224 | INFO | [default | seed 44] elapsed_time 01:22:49, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.92±12.54, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.39±12.64
2025-12-30 15:56:51,114 | INFO | [default | seed 44] elapsed_time 01:23:46, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 27.99±12.48, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.43±12.57
2025-12-30 15:57:47,256 | INFO | [default | seed 44] elapsed_time 01:24:43, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.04±12.42, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.47±12.51
2025-12-30 15:58:43,321 | INFO | [default | seed 44] elapsed_time 01:25:39, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.08±12.36, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.54±12.45
2025-12-30 15:59:39,483 | INFO | [default | seed 44] elapsed_time 01:26:35, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.15±12.31, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.62±12.41
2025-12-30 16:00:35,013 | INFO | [default | seed 44] elapsed_time 01:27:30, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 28.24±12.27, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.71±12.38
2025-12-30 16:01:31,584 | INFO | [default | seed 44] elapsed_time 01:28:27, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.27±12.21, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.71±12.31
2025-12-30 16:02:26,967 | INFO | [default | seed 44] elapsed_time 01:29:22, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 28.31±12.15, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.74±12.25
2025-12-30 16:03:23,767 | INFO | [default | seed 44] elapsed_time 01:30:19, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.29±12.09, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.78±12.19
2025-12-30 16:04:18,838 | INFO | [default | seed 44] elapsed_time 01:31:14, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.32±12.03, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.78±12.13
2025-12-30 16:05:15,104 | INFO | [default | seed 44] elapsed_time 01:32:10, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 28.35±11.97, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.81±12.07
2025-12-30 16:06:11,768 | INFO | [default | seed 44] elapsed_time 01:33:07, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.40±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.84±12.01
2025-12-30 16:07:07,949 | INFO | [default | seed 44] elapsed_time 01:34:03, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 28.41±11.86, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.85±11.95
2025-12-30 16:08:05,807 | INFO | [default | seed 44] elapsed_time 01:35:01, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.74±11.53, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.21±11.62
2025-12-30 16:09:02,631 | INFO | [default | seed 44] elapsed_time 01:35:58, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 29.06±11.16, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.56±11.25
2025-12-30 16:10:00,062 | INFO | [default | seed 44] elapsed_time 01:36:55, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.41±10.79, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0010, mean_reward_over_100_episodes_from_eval 29.90±10.87
2025-12-30 16:10:56,759 | INFO | [default | seed 44] Requirement met (evaluation metric): solved at episode 104 with mean_100_eval=30.22
2025-12-30 16:10:56,760 | INFO | [default | seed 44] elapsed_time 01:37:52, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 29.76±10.39, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0010, mean_reward_over_100_episodes_from_eval 30.22±10.46
2025-12-30 16:10:56,760 | INFO | [default | seed 44] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 16:41:10,703 | INFO | [default | seed 44] Training complete.
2025-12-30 16:41:10,720 | INFO | [default | seed 44] Solved (evaluation metric) at episode 104.
2025-12-30 16:41:10,721 | INFO | [default | seed 44] Final evaluation score 32.91±1.05 in 3991.62s training, 7686.46s wall.
2025-12-30 16:41:10,722 | INFO | [default | seed 44] Closing UnityVectorEnv (worker_id=44).
2025-12-30 16:41:10,724 | INFO | [Main] Requesting worker 44 to close Unity env.
2025-12-30 16:41:12,086 | INFO | [Main] Worker 44 joined. Unity env fully closed.
2025-12-30 16:41:12,091 | INFO | [default | seed 44] Final eval score: 32.91
2025-12-30 16:41:12,778 | INFO | [default | seed 44] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_44.png
2025-12-30 16:41:12,780 | INFO | [default | seed 44] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 16:41:13,451 | INFO | [default | seed 22] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 16:41:13,451 | INFO | [default | seed 22] === Starting run for seed 22 ===
2025-12-30 16:41:13,451 | INFO | [default | seed 22] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-30 16:41:13,467 | INFO | [default | seed 22] Launching UnityVectorEnv with worker_id=22, seed=22
2025-12-30 16:41:13,467 | INFO | [Main] Spawning worker 22 for Unity env (seed=22). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-30 16:41:13,509 | INFO | [Main] Worker 22 started (pid=91880).
2025-12-30 16:41:25,573 | INFO | [default | seed 22] Environment batched agents (train): 20
2025-12-30 16:41:57,118 | INFO | [default | seed 22] Environment batched agents (eval): 20
2025-12-30 16:42:17,947 | INFO | [default | seed 22] elapsed_time 00:01:04, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 05.190000, episode_sum_max_abs_reward_per_step 05.190000, mean_reward_over_100_episodes_from_training 00.29±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0000, mean_reward_over_100_episodes_from_eval 00.60±00.00
2025-12-30 16:43:07,020 | INFO | [default | seed 22] elapsed_time 00:01:53, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 15.260000, episode_sum_max_abs_reward_per_step 15.260000, mean_reward_over_100_episodes_from_training 00.58±00.30, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0001, mean_reward_over_100_episodes_from_eval 00.80±00.20
2025-12-30 16:43:57,657 | INFO | [default | seed 22] elapsed_time 00:02:44, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 19.670000, episode_sum_max_abs_reward_per_step 19.670000, mean_reward_over_100_episodes_from_training 00.79±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0002, mean_reward_over_100_episodes_from_eval 00.70±00.22
2025-12-30 16:44:46,433 | INFO | [default | seed 22] elapsed_time 00:03:32, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 17.250000, episode_sum_max_abs_reward_per_step 17.250000, mean_reward_over_100_episodes_from_training 00.88±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0004, mean_reward_over_100_episodes_from_eval 00.83±00.30
2025-12-30 16:45:36,730 | INFO | [default | seed 22] elapsed_time 00:04:23, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 14.290000, episode_sum_max_abs_reward_per_step 14.290000, mean_reward_over_100_episodes_from_training 00.90±00.33, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0004, mean_reward_over_100_episodes_from_eval 01.08±00.57
2025-12-30 16:46:26,866 | INFO | [default | seed 22] elapsed_time 00:05:13, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 25.599999, episode_sum_max_abs_reward_per_step 25.599999, mean_reward_over_100_episodes_from_training 01.03±00.42, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0004, mean_reward_over_100_episodes_from_eval 01.12±00.53
2025-12-30 16:47:15,105 | INFO | [default | seed 22] elapsed_time 00:06:01, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 20.100000, episode_sum_max_abs_reward_per_step 20.100000, mean_reward_over_100_episodes_from_training 01.08±00.41, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0005, mean_reward_over_100_episodes_from_eval 01.16±00.50
2025-12-30 16:48:04,506 | INFO | [default | seed 22] elapsed_time 00:06:51, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 20.650000, episode_sum_max_abs_reward_per_step 20.650000, mean_reward_over_100_episodes_from_training 01.13±00.40, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 01.37±00.73
2025-12-30 16:48:53,329 | INFO | [default | seed 22] elapsed_time 00:07:39, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 30.989999, episode_sum_max_abs_reward_per_step 30.989999, mean_reward_over_100_episodes_from_training 01.32±00.65, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0007, mean_reward_over_100_episodes_from_eval 01.61±00.96
2025-12-30 16:49:42,001 | INFO | [default | seed 22] elapsed_time 00:08:28, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 37.059999, episode_sum_max_abs_reward_per_step 37.059999, mean_reward_over_100_episodes_from_training 01.68±01.24, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 02.09±01.69
2025-12-30 16:50:31,383 | INFO | [default | seed 22] elapsed_time 00:09:17, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.109999, episode_sum_max_abs_reward_per_step 39.109999, mean_reward_over_100_episodes_from_training 02.16±01.94, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0006, mean_reward_over_100_episodes_from_eval 02.59±02.26
2025-12-30 16:51:23,608 | INFO | [default | seed 22] elapsed_time 00:10:10, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.419999, episode_sum_max_abs_reward_per_step 39.419999, mean_reward_over_100_episodes_from_training 02.73±02.64, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 03.16±02.87
2025-12-30 16:52:11,970 | INFO | [default | seed 22] elapsed_time 00:10:58, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 03.43±03.50, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0008, mean_reward_over_100_episodes_from_eval 03.92±03.83
2025-12-30 16:53:00,683 | INFO | [default | seed 22] elapsed_time 00:11:47, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 04.33±04.69, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0008, mean_reward_over_100_episodes_from_eval 04.94±05.21
2025-12-30 16:53:48,806 | INFO | [default | seed 22] elapsed_time 00:12:35, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 05.30±05.79, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 05.84±06.06
2025-12-30 16:54:38,916 | INFO | [default | seed 22] elapsed_time 00:13:25, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 06.48±07.26, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0012, mean_reward_over_100_episodes_from_eval 07.05±07.50
2025-12-30 16:55:27,167 | INFO | [default | seed 22] elapsed_time 00:14:13, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 07.66±08.46, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0013, mean_reward_over_100_episodes_from_eval 08.39±09.03
2025-12-30 16:56:15,609 | INFO | [default | seed 22] elapsed_time 00:15:02, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 08.87±09.63, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0014, mean_reward_over_100_episodes_from_eval 09.58±10.06
2025-12-30 16:57:04,164 | INFO | [default | seed 22] elapsed_time 00:15:50, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 10.05±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0014, mean_reward_over_100_episodes_from_eval 10.67±10.82
2025-12-30 16:57:52,673 | INFO | [default | seed 22] elapsed_time 00:16:39, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 11.09±11.30, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0015, mean_reward_over_100_episodes_from_eval 11.62±11.33
2025-12-30 16:58:41,612 | INFO | [default | seed 22] elapsed_time 00:17:28, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 12.19±12.07, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0015, mean_reward_over_100_episodes_from_eval 12.76±12.19
2025-12-30 16:59:30,462 | INFO | [default | seed 22] elapsed_time 00:18:17, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 13.17±12.62, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0016, mean_reward_over_100_episodes_from_eval 13.73±12.71
2025-12-30 17:00:19,355 | INFO | [default | seed 22] elapsed_time 00:19:05, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 14.12±13.13, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0016, mean_reward_over_100_episodes_from_eval 14.77±13.36
2025-12-30 17:01:08,324 | INFO | [default | seed 22] elapsed_time 00:19:54, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 15.09±13.67, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0015, mean_reward_over_100_episodes_from_eval 15.72±13.84
2025-12-30 17:01:56,173 | INFO | [default | seed 22] elapsed_time 00:20:42, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 15.95±14.04, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0015, mean_reward_over_100_episodes_from_eval 16.50±14.09
2025-12-30 17:02:44,933 | INFO | [default | seed 22] elapsed_time 00:21:31, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 16.66±14.21, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0015, mean_reward_over_100_episodes_from_eval 17.20±14.25
2025-12-30 17:03:35,504 | INFO | [default | seed 22] elapsed_time 00:22:22, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 17.32±14.34, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0015, mean_reward_over_100_episodes_from_eval 17.89±14.42
2025-12-30 17:04:24,011 | INFO | [default | seed 22] elapsed_time 00:23:10, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 17.93±14.44, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0015, mean_reward_over_100_episodes_from_eval 18.47±14.48
2025-12-30 17:05:12,282 | INFO | [default | seed 22] elapsed_time 00:23:58, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.34±14.36, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0014, mean_reward_over_100_episodes_from_eval 19.06±14.56
2025-12-30 17:06:00,882 | INFO | [default | seed 22] elapsed_time 00:24:47, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.75±14.29, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0014, mean_reward_over_100_episodes_from_eval 19.58±14.59
2025-12-30 17:06:50,389 | INFO | [default | seed 22] elapsed_time 00:25:36, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 19.29±14.36, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0014, mean_reward_over_100_episodes_from_eval 20.10±14.63
2025-12-30 17:07:39,053 | INFO | [default | seed 22] elapsed_time 00:26:25, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 19.78±14.40, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0014, mean_reward_over_100_episodes_from_eval 20.43±14.52
2025-12-30 17:08:27,392 | INFO | [default | seed 22] elapsed_time 00:27:13, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 20.14±14.32, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0014, mean_reward_over_100_episodes_from_eval 20.64±14.35
2025-12-30 17:09:16,302 | INFO | [default | seed 22] elapsed_time 00:28:02, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.749999, episode_sum_max_abs_reward_per_step 39.749999, mean_reward_over_100_episodes_from_training 20.48±14.24, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0013, mean_reward_over_100_episodes_from_eval 21.05±14.33
2025-12-30 17:10:05,853 | INFO | [default | seed 22] elapsed_time 00:28:52, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 20.90±14.26, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0013, mean_reward_over_100_episodes_from_eval 21.43±14.30
2025-12-30 17:10:55,211 | INFO | [default | seed 22] elapsed_time 00:29:41, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 21.28±14.23, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0013, mean_reward_over_100_episodes_from_eval 21.83±14.30
2025-12-30 17:11:44,461 | INFO | [default | seed 22] elapsed_time 00:30:31, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 21.66±14.22, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0013, mean_reward_over_100_episodes_from_eval 22.08±14.18
2025-12-30 17:12:34,315 | INFO | [default | seed 22] elapsed_time 00:31:20, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 21.91±14.12, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0013, mean_reward_over_100_episodes_from_eval 22.34±14.08
2025-12-30 17:13:24,854 | INFO | [default | seed 22] elapsed_time 00:32:11, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 22.26±14.10, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0013, mean_reward_over_100_episodes_from_eval 22.66±14.04
2025-12-30 17:14:13,738 | INFO | [default | seed 22] elapsed_time 00:33:00, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 22.62±14.10, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0013, mean_reward_over_100_episodes_from_eval 23.04±14.06
2025-12-30 17:15:02,975 | INFO | [default | seed 22] elapsed_time 00:33:49, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 22.95±14.08, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0013, mean_reward_over_100_episodes_from_eval 23.36±14.03
2025-12-30 17:15:51,671 | INFO | [default | seed 22] elapsed_time 00:34:38, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 23.17±13.99, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0013, mean_reward_over_100_episodes_from_eval 23.65±13.99
2025-12-30 17:16:41,143 | INFO | [default | seed 22] elapsed_time 00:35:27, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.46±13.95, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0013, mean_reward_over_100_episodes_from_eval 23.91±13.94
2025-12-30 17:17:30,156 | INFO | [default | seed 22] elapsed_time 00:36:16, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 23.68±13.86, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0013, mean_reward_over_100_episodes_from_eval 24.10±13.83
2025-12-30 17:18:20,248 | INFO | [default | seed 22] elapsed_time 00:37:06, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 23.92±13.80, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0013, mean_reward_over_100_episodes_from_eval 24.38±13.80
2025-12-30 17:19:08,614 | INFO | [default | seed 22] elapsed_time 00:37:55, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.17±13.75, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0013, mean_reward_over_100_episodes_from_eval 24.64±13.76
2025-12-30 17:19:57,944 | INFO | [default | seed 22] elapsed_time 00:38:44, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.39±13.69, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0013, mean_reward_over_100_episodes_from_eval 24.86±13.69
2025-12-30 17:20:47,406 | INFO | [default | seed 22] elapsed_time 00:39:33, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 24.61±13.63, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0013, mean_reward_over_100_episodes_from_eval 25.11±13.66
2025-12-30 17:21:37,661 | INFO | [default | seed 22] elapsed_time 00:40:24, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 24.80±13.55, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0013, mean_reward_over_100_episodes_from_eval 25.27±13.56
2025-12-30 17:22:28,386 | INFO | [default | seed 22] elapsed_time 00:41:14, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 24.96±13.46, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0013, mean_reward_over_100_episodes_from_eval 25.45±13.49
2025-12-30 17:23:16,609 | INFO | [default | seed 22] elapsed_time 00:42:03, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 25.11±13.37, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0013, mean_reward_over_100_episodes_from_eval 25.64±13.42
2025-12-30 17:24:04,939 | INFO | [default | seed 22] elapsed_time 00:42:51, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.31±13.32, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0013, mean_reward_over_100_episodes_from_eval 25.74±13.31
2025-12-30 17:24:53,690 | INFO | [default | seed 22] elapsed_time 00:43:40, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.46±13.24, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 25.90±13.23
2025-12-30 17:25:42,459 | INFO | [default | seed 22] elapsed_time 00:44:29, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.63±13.17, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.09±13.19
2025-12-30 17:26:31,160 | INFO | [default | seed 22] elapsed_time 00:45:17, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.81±13.11, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.27±13.13
2025-12-30 17:27:19,525 | INFO | [default | seed 22] elapsed_time 00:46:06, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.92±13.02, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.41±13.05
2025-12-30 17:28:08,448 | INFO | [default | seed 22] elapsed_time 00:46:54, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.05±12.94, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.54±12.97
2025-12-30 17:28:57,123 | INFO | [default | seed 22] elapsed_time 00:47:43, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.22±12.90, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.58±12.87
2025-12-30 17:29:46,314 | INFO | [default | seed 22] elapsed_time 00:48:32, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 26.36±12.83, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.76±12.83
2025-12-30 17:30:35,318 | INFO | [default | seed 22] elapsed_time 00:49:21, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 26.52±12.78, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 26.89±12.76
2025-12-30 17:31:24,100 | INFO | [default | seed 22] elapsed_time 00:50:10, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.65±12.72, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0013, mean_reward_over_100_episodes_from_eval 27.01±12.69
2025-12-30 17:32:14,005 | INFO | [default | seed 22] elapsed_time 00:51:00, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.78±12.66, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 27.14±12.63
2025-12-30 17:33:03,606 | INFO | [default | seed 22] elapsed_time 00:51:50, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.87±12.58, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 27.20±12.54
2025-12-30 17:33:52,502 | INFO | [default | seed 22] elapsed_time 00:52:39, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.89±12.48, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 27.32±12.48
2025-12-30 17:34:44,023 | INFO | [default | seed 22] elapsed_time 00:53:30, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.96±12.40, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 27.39±12.39
2025-12-30 17:35:32,754 | INFO | [default | seed 22] elapsed_time 00:54:19, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.06±12.33, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 27.41±12.30
2025-12-30 17:36:21,896 | INFO | [default | seed 22] elapsed_time 00:55:08, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.16±12.26, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0012, mean_reward_over_100_episodes_from_eval 27.49±12.22
2025-12-30 17:37:10,819 | INFO | [default | seed 22] elapsed_time 00:55:57, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 27.23±12.18, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 27.54±12.14
2025-12-30 17:37:59,184 | INFO | [default | seed 22] elapsed_time 00:56:45, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 27.35±12.13, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 27.65±12.09
2025-12-30 17:38:47,826 | INFO | [default | seed 22] elapsed_time 00:57:34, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 27.45±12.08, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 27.76±12.04
2025-12-30 17:39:36,889 | INFO | [default | seed 22] elapsed_time 00:58:23, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 27.55±12.02, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 27.87±11.99
2025-12-30 17:40:25,245 | INFO | [default | seed 22] elapsed_time 00:59:11, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 27.66±11.97, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.00±11.95
2025-12-30 17:41:15,023 | INFO | [default | seed 22] elapsed_time 01:00:01, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 27.77±11.93, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.09±11.89
2025-12-30 17:42:04,902 | INFO | [default | seed 22] elapsed_time 01:00:51, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.84±11.86, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.10±11.81
2025-12-30 17:42:53,919 | INFO | [default | seed 22] elapsed_time 01:01:40, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.92±11.80, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.20±11.77
2025-12-30 17:43:42,548 | INFO | [default | seed 22] elapsed_time 01:02:29, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.04±11.77, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.32±11.74
2025-12-30 17:44:32,403 | INFO | [default | seed 22] elapsed_time 01:03:18, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.13±11.72, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.39±11.67
2025-12-30 17:45:20,973 | INFO | [default | seed 22] elapsed_time 01:04:07, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.15±11.64, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.42±11.60
2025-12-30 17:46:10,142 | INFO | [default | seed 22] elapsed_time 01:04:56, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.23±11.59, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0012, mean_reward_over_100_episodes_from_eval 28.50±11.55
2025-12-30 17:46:58,403 | INFO | [default | seed 22] elapsed_time 01:05:44, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 28.28±11.52, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0012, mean_reward_over_100_episodes_from_eval 28.61±11.52
2025-12-30 17:47:47,456 | INFO | [default | seed 22] elapsed_time 01:06:34, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 28.36±11.48, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 28.69±11.47
2025-12-30 17:48:37,075 | INFO | [default | seed 22] elapsed_time 01:07:23, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.46±11.45, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 28.80±11.45
2025-12-30 17:49:25,917 | INFO | [default | seed 22] elapsed_time 01:08:12, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.58±11.42, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 28.89±11.40
2025-12-30 17:50:14,849 | INFO | [default | seed 22] elapsed_time 01:09:01, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 28.65±11.37, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 28.88±11.34
2025-12-30 17:51:03,579 | INFO | [default | seed 22] elapsed_time 01:09:50, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.71±11.32, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 28.95±11.28
2025-12-30 17:51:52,628 | INFO | [default | seed 22] elapsed_time 01:10:39, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.76±11.26, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 28.99±11.23
2025-12-30 17:52:41,291 | INFO | [default | seed 22] elapsed_time 01:11:27, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 28.84±11.22, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.02±11.16
2025-12-30 17:53:30,335 | INFO | [default | seed 22] elapsed_time 01:12:16, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 28.88±11.16, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.07±11.11
2025-12-30 17:54:19,561 | INFO | [default | seed 22] elapsed_time 01:13:06, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 28.95±11.12, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.12±11.06
2025-12-30 17:55:08,773 | INFO | [default | seed 22] elapsed_time 01:13:55, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.99±11.06, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.15±11.00
2025-12-30 17:55:57,066 | INFO | [default | seed 22] elapsed_time 01:14:43, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 29.03±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.18±10.94
2025-12-30 17:56:45,961 | INFO | [default | seed 22] elapsed_time 01:15:32, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 29.09±10.97, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.25±10.90
2025-12-30 17:57:35,083 | INFO | [default | seed 22] elapsed_time 01:16:21, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.16±10.93, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.31±10.86
2025-12-30 17:58:23,923 | INFO | [default | seed 22] elapsed_time 01:17:10, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.19±10.87, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.38±10.82
2025-12-30 17:59:12,960 | INFO | [default | seed 22] elapsed_time 01:17:59, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.22±10.82, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.40±10.77
2025-12-30 18:00:01,635 | INFO | [default | seed 22] elapsed_time 01:18:48, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.20±10.77, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.42±10.71
2025-12-30 18:00:51,303 | INFO | [default | seed 22] elapsed_time 01:19:37, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.22±10.71, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0011, mean_reward_over_100_episodes_from_eval 29.38±10.66
2025-12-30 18:01:40,021 | INFO | [default | seed 22] elapsed_time 01:20:26, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.22±10.66, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0011, mean_reward_over_100_episodes_from_eval 29.39±10.61
2025-12-30 18:02:29,360 | INFO | [default | seed 22] elapsed_time 01:21:15, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.26±10.61, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0011, mean_reward_over_100_episodes_from_eval 29.46±10.58
2025-12-30 18:03:18,794 | INFO | [default | seed 22] elapsed_time 01:22:05, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.30±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0011, mean_reward_over_100_episodes_from_eval 29.48±10.52
2025-12-30 18:04:07,234 | INFO | [default | seed 22] elapsed_time 01:22:53, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.65±10.17, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0011, mean_reward_over_100_episodes_from_eval 29.83±10.13
2025-12-30 18:04:56,681 | INFO | [default | seed 22] Requirement met (evaluation metric): solved at episode 102 with mean_100_eval=30.18
2025-12-30 18:04:56,683 | INFO | [default | seed 22] elapsed_time 01:23:43, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 29.96±09.75, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0011, mean_reward_over_100_episodes_from_eval 30.18±09.73
2025-12-30 18:04:56,683 | INFO | [default | seed 22] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-30 18:29:39,310 | INFO | [default | seed 22] Training complete.
2025-12-30 18:29:39,310 | INFO | [default | seed 22] Solved (evaluation metric) at episode 102.
2025-12-30 18:29:39,310 | INFO | [default | seed 22] Final evaluation score 36.71±0.66 in 3537.40s training, 6505.86s wall.
2025-12-30 18:29:39,311 | INFO | [default | seed 22] Closing UnityVectorEnv (worker_id=22).
2025-12-30 18:29:39,311 | INFO | [Main] Requesting worker 22 to close Unity env.
2025-12-30 18:29:40,552 | INFO | [Main] Worker 22 joined. Unity env fully closed.
2025-12-30 18:29:40,552 | INFO | [default | seed 22] Final eval score: 36.71
2025-12-30 18:29:40,885 | INFO | [default | seed 22] Per-seed evaluation plot saved to results\continuous_control\run_20251229_225041\plots\evaluation_mean100_default_seed_22.png
2025-12-30 18:29:40,885 | INFO | [default | seed 22] Summary appended to results\continuous_control\run_20251229_225041\plots_summary.csv
2025-12-30 18:29:41,028 | INFO | Default config final scores: [36.521, 30.046, 34.957, 33.106, 35.041, 32.525, 30.731, 34.857, 32.915, 36.707] | best seed score=36.707
2025-12-30 18:29:41,402 | INFO | Hypothesis tests over 10 seeds:
2025-12-30 18:29:41,404 | INFO | Final scores: [36.521, 30.046, 34.957, 33.106, 35.041, 32.525, 30.731, 34.857, 32.915, 36.707]
2025-12-30 18:29:41,404 | INFO | Mean=33.741, Std=2.266, Goal=30.000
2025-12-30 18:29:41,404 | INFO | Bootstrap 95% CI for mean: [32.370, 35.062]
2025-12-30 18:29:41,404 | INFO | Significant (mean > goal @95%)? Yes
2025-12-30 18:29:41,405 | INFO | Run finished.
