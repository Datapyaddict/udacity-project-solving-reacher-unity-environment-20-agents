2025-12-28 18:45:35,051 | INFO | Logging initialized. Log file: results\continuous_control\run_20251228_184535\run.log
2025-12-28 18:45:35,052 | INFO | Results will be saved to: results\continuous_control\run_20251228_184535
2025-12-28 18:45:35,052 | INFO | Seeds: (29,)
2025-12-28 18:45:35,052 | INFO | Unity exe: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-28 18:45:35,056 | INFO | Hyperparameter search enabled. Trials to run: 10 (max-trials=10)
2025-12-28 18:45:35,058 | INFO | [trial_001] Starting trial with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-28 18:45:35,060 | INFO | [trial_001 | seed 29] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-28 18:45:35,061 | INFO | [trial_001 | seed 29] === Starting run for seed 29 ===
2025-12-28 18:45:35,061 | INFO | [trial_001 | seed 29] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-28 18:45:35,071 | INFO | [trial_001 | seed 29] Launching UnityVectorEnv with worker_id=1029, seed=29
2025-12-28 18:45:35,072 | INFO | [Main] Spawning worker 1029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-28 18:45:35,088 | INFO | [Main] Worker 1029 started (pid=45520).
2025-12-28 18:45:43,630 | INFO | [trial_001 | seed 29] Environment batched agents (train): 20
2025-12-28 18:46:22,854 | INFO | [trial_001 | seed 29] Environment batched agents (eval): 20
2025-12-28 18:46:42,358 | INFO | [trial_001 | seed 29] elapsed_time 00:01:07, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 11.920000, episode_sum_max_abs_reward_per_step 11.920000, mean_reward_over_100_episodes_from_training 00.73±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0000, mean_reward_over_100_episodes_from_eval 00.97±00.00
2025-12-28 18:48:07,263 | INFO | [trial_001 | seed 29] elapsed_time 00:02:32, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 12.690000, episode_sum_max_abs_reward_per_step 12.690000, mean_reward_over_100_episodes_from_training 00.75±00.02, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0006, mean_reward_over_100_episodes_from_eval 01.55±00.58
2025-12-28 18:49:33,263 | INFO | [trial_001 | seed 29] elapsed_time 00:03:58, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 28.019999, episode_sum_max_abs_reward_per_step 28.019999, mean_reward_over_100_episodes_from_training 01.26±00.72, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0005, mean_reward_over_100_episodes_from_eval 01.57±00.48
2025-12-28 18:51:01,332 | INFO | [trial_001 | seed 29] elapsed_time 00:05:26, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 21.960000, episode_sum_max_abs_reward_per_step 21.960000, mean_reward_over_100_episodes_from_training 01.34±00.64, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0005, mean_reward_over_100_episodes_from_eval 01.80±00.57
2025-12-28 18:52:22,056 | INFO | [trial_001 | seed 29] elapsed_time 00:06:46, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 28.769999, episode_sum_max_abs_reward_per_step 28.769999, mean_reward_over_100_episodes_from_training 01.58±00.75, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0005, mean_reward_over_100_episodes_from_eval 01.96±00.61
2025-12-28 18:53:45,560 | INFO | [trial_001 | seed 29] elapsed_time 00:08:10, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 33.639999, episode_sum_max_abs_reward_per_step 33.639999, mean_reward_over_100_episodes_from_training 01.93±01.03, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0005, mean_reward_over_100_episodes_from_eval 02.15±00.69
2025-12-28 18:55:06,173 | INFO | [trial_001 | seed 29] elapsed_time 00:09:31, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 37.529999, episode_sum_max_abs_reward_per_step 37.529999, mean_reward_over_100_episodes_from_training 02.55±01.80, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0005, mean_reward_over_100_episodes_from_eval 02.88±01.91
2025-12-28 18:56:25,880 | INFO | [trial_001 | seed 29] elapsed_time 00:10:50, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 39.369999, episode_sum_max_abs_reward_per_step 39.369999, mean_reward_over_100_episodes_from_training 03.42±02.85, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0004, mean_reward_over_100_episodes_from_eval 03.84±03.11
2025-12-28 18:57:45,320 | INFO | [trial_001 | seed 29] elapsed_time 00:12:10, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 04.55±04.18, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0005, mean_reward_over_100_episodes_from_eval 05.75±06.13
2025-12-28 18:58:56,009 | INFO | [trial_001 | seed 29] elapsed_time 00:13:20, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 06.48±07.01, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0005, mean_reward_over_100_episodes_from_eval 07.74±08.33
2025-12-28 19:00:22,820 | INFO | [trial_001 | seed 29] elapsed_time 00:14:47, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 08.57±09.41, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0007, mean_reward_over_100_episodes_from_eval 09.69±10.06
2025-12-28 19:01:43,102 | INFO | [trial_001 | seed 29] elapsed_time 00:16:08, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 10.70±11.44, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0008, mean_reward_over_100_episodes_from_eval 11.80±11.92
2025-12-28 19:03:36,558 | INFO | [trial_001 | seed 29] elapsed_time 00:18:01, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 12.75±13.09, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0010, mean_reward_over_100_episodes_from_eval 13.81±13.39
2025-12-28 19:04:55,884 | INFO | [trial_001 | seed 29] elapsed_time 00:19:20, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 14.58±14.24, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0011, mean_reward_over_100_episodes_from_eval 15.56±14.37
2025-12-28 19:06:08,696 | INFO | [trial_001 | seed 29] elapsed_time 00:20:33, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 16.09±14.88, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0011, mean_reward_over_100_episodes_from_eval 17.10±15.03
2025-12-28 19:07:24,414 | INFO | [trial_001 | seed 29] elapsed_time 00:21:49, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 17.43±15.31, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0012, mean_reward_over_100_episodes_from_eval 18.44±15.45
2025-12-28 19:08:23,170 | INFO | [trial_001 | seed 29] elapsed_time 00:22:48, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 18.58±15.54, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 19.39±15.46
2025-12-28 19:09:17,400 | INFO | [trial_001 | seed 29] elapsed_time 00:23:42, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 19.46±15.54, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0013, mean_reward_over_100_episodes_from_eval 20.15±15.35
2025-12-28 19:10:13,493 | INFO | [trial_001 | seed 29] elapsed_time 00:24:38, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 20.10±15.36, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0014, mean_reward_over_100_episodes_from_eval 20.87±15.25
2025-12-28 19:11:07,745 | INFO | [trial_001 | seed 29] elapsed_time 00:25:32, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 20.82±15.30, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0013, mean_reward_over_100_episodes_from_eval 21.35±15.01
2025-12-28 19:12:02,106 | INFO | [trial_001 | seed 29] elapsed_time 00:26:27, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 21.39±15.15, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0013, mean_reward_over_100_episodes_from_eval 22.02±14.95
2025-12-28 19:12:59,135 | INFO | [trial_001 | seed 29] elapsed_time 00:27:24, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 21.96±15.03, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0013, mean_reward_over_100_episodes_from_eval 22.62±14.86
2025-12-28 19:13:59,271 | INFO | [trial_001 | seed 29] elapsed_time 00:28:24, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 22.51±14.92, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0013, mean_reward_over_100_episodes_from_eval 23.17±14.77
2025-12-28 19:14:54,044 | INFO | [trial_001 | seed 29] elapsed_time 00:29:18, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.97±14.77, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0013, mean_reward_over_100_episodes_from_eval 23.61±14.61
2025-12-28 19:15:48,298 | INFO | [trial_001 | seed 29] elapsed_time 00:30:13, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.52±14.72, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0013, mean_reward_over_100_episodes_from_eval 24.14±14.55
2025-12-28 19:16:42,926 | INFO | [trial_001 | seed 29] elapsed_time 00:31:07, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 24.03±14.66, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0014, mean_reward_over_100_episodes_from_eval 24.66±14.50
2025-12-28 19:17:35,216 | INFO | [trial_001 | seed 29] elapsed_time 00:32:00, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 24.44±14.54, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0013, mean_reward_over_100_episodes_from_eval 25.04±14.36
2025-12-28 19:18:30,412 | INFO | [trial_001 | seed 29] elapsed_time 00:32:55, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.83±14.42, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0013, mean_reward_over_100_episodes_from_eval 25.28±14.16
2025-12-28 19:19:26,338 | INFO | [trial_001 | seed 29] elapsed_time 00:33:51, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.10±14.24, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0013, mean_reward_over_100_episodes_from_eval 25.58±14.00
2025-12-28 19:20:22,444 | INFO | [trial_001 | seed 29] elapsed_time 00:34:47, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.43±14.11, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0013, mean_reward_over_100_episodes_from_eval 25.92±13.89
2025-12-28 19:21:17,855 | INFO | [trial_001 | seed 29] elapsed_time 00:35:42, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 25.76±14.00, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0013, mean_reward_over_100_episodes_from_eval 26.26±13.79
2025-12-28 19:22:11,549 | INFO | [trial_001 | seed 29] elapsed_time 00:36:36, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 26.10±13.91, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0013, mean_reward_over_100_episodes_from_eval 26.56±13.67
2025-12-28 19:23:04,438 | INFO | [trial_001 | seed 29] elapsed_time 00:37:29, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 26.34±13.76, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0013, mean_reward_over_100_episodes_from_eval 26.86±13.57
2025-12-28 19:23:59,049 | INFO | [trial_001 | seed 29] elapsed_time 00:38:23, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.65±13.68, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0012, mean_reward_over_100_episodes_from_eval 27.16±13.48
2025-12-28 19:24:56,038 | INFO | [trial_001 | seed 29] elapsed_time 00:39:20, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 26.86±13.54, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0012, mean_reward_over_100_episodes_from_eval 27.34±13.33
2025-12-28 19:25:49,729 | INFO | [trial_001 | seed 29] elapsed_time 00:40:14, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 27.02±13.38, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0012, mean_reward_over_100_episodes_from_eval 27.41±13.15
2025-12-28 19:26:43,912 | INFO | [trial_001 | seed 29] elapsed_time 00:41:08, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.15±13.22, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0012, mean_reward_over_100_episodes_from_eval 27.64±13.04
2025-12-28 19:27:37,188 | INFO | [trial_001 | seed 29] elapsed_time 00:42:02, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.34±13.10, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0012, mean_reward_over_100_episodes_from_eval 27.86±12.94
2025-12-28 19:28:31,135 | INFO | [trial_001 | seed 29] elapsed_time 00:42:56, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.46±12.95, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 27.95±12.78
2025-12-28 19:29:25,468 | INFO | [trial_001 | seed 29] elapsed_time 00:43:50, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.62±12.82, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 28.16±12.69
2025-12-28 19:30:19,867 | INFO | [trial_001 | seed 29] elapsed_time 00:44:44, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 27.75±12.70, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 28.35±12.60
2025-12-28 19:31:14,136 | INFO | [trial_001 | seed 29] elapsed_time 00:45:39, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.81±12.55, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 28.52±12.49
2025-12-28 19:32:06,915 | INFO | [trial_001 | seed 29] elapsed_time 00:46:31, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 27.97±12.45, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0013, mean_reward_over_100_episodes_from_eval 28.71±12.41
2025-12-28 19:33:11,977 | INFO | [trial_001 | seed 29] elapsed_time 00:47:36, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 28.18±12.38, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0013, mean_reward_over_100_episodes_from_eval 28.88±12.32
2025-12-28 19:34:15,656 | INFO | [trial_001 | seed 29] elapsed_time 00:48:40, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.30±12.27, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0013, mean_reward_over_100_episodes_from_eval 28.93±12.18
2025-12-28 19:35:10,289 | INFO | [trial_001 | seed 29] elapsed_time 00:49:35, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.39±12.15, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0014, mean_reward_over_100_episodes_from_eval 28.99±12.06
2025-12-28 19:36:05,463 | INFO | [trial_001 | seed 29] elapsed_time 00:50:30, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 28.47±12.03, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0014, mean_reward_over_100_episodes_from_eval 29.03±11.93
2025-12-28 19:37:01,071 | INFO | [trial_001 | seed 29] elapsed_time 00:51:26, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.55±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0014, mean_reward_over_100_episodes_from_eval 29.19±11.86
2025-12-28 19:37:55,952 | INFO | [trial_001 | seed 29] elapsed_time 00:52:20, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 28.68±11.83, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0014, mean_reward_over_100_episodes_from_eval 29.29±11.76
2025-12-28 19:38:51,343 | INFO | [trial_001 | seed 29] elapsed_time 00:53:16, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.83±11.76, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0014, mean_reward_over_100_episodes_from_eval 29.40±11.66
2025-12-28 19:39:48,602 | INFO | [trial_001 | seed 29] elapsed_time 00:54:13, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.94±11.67, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 29.55±11.59
2025-12-28 19:40:44,106 | INFO | [trial_001 | seed 29] elapsed_time 00:55:09, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.07±11.59, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 29.68±11.52
2025-12-28 19:41:38,656 | INFO | [trial_001 | seed 29] elapsed_time 00:56:03, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.21±11.52, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0014, mean_reward_over_100_episodes_from_eval 29.84±11.47
2025-12-28 19:42:34,220 | INFO | [trial_001 | seed 29] elapsed_time 00:56:59, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.34±11.46, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0015, mean_reward_over_100_episodes_from_eval 29.92±11.38
2025-12-28 19:43:29,567 | INFO | [trial_001 | seed 29] elapsed_time 00:57:54, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.45±11.38, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0015, mean_reward_over_100_episodes_from_eval 30.00±11.29
2025-12-28 19:44:27,069 | INFO | [trial_001 | seed 29] elapsed_time 00:58:52, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.55±11.30, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0015, mean_reward_over_100_episodes_from_eval 30.09±11.21
2025-12-28 19:45:22,103 | INFO | [trial_001 | seed 29] elapsed_time 00:59:47, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.64±11.23, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0015, mean_reward_over_100_episodes_from_eval 30.11±11.11
2025-12-28 19:46:16,595 | INFO | [trial_001 | seed 29] elapsed_time 01:00:41, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.75±11.16, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0016, mean_reward_over_100_episodes_from_eval 30.23±11.05
2025-12-28 19:47:10,526 | INFO | [trial_001 | seed 29] elapsed_time 01:01:35, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.83±11.08, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0016, mean_reward_over_100_episodes_from_eval 30.31±10.98
2025-12-28 19:48:06,142 | INFO | [trial_001 | seed 29] elapsed_time 01:02:31, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.91±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0016, mean_reward_over_100_episodes_from_eval 30.38±10.90
2025-12-28 19:49:04,778 | INFO | [trial_001 | seed 29] elapsed_time 01:03:29, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 29.96±10.92, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0016, mean_reward_over_100_episodes_from_eval 30.43±10.82
2025-12-28 19:50:08,008 | INFO | [trial_001 | seed 29] elapsed_time 01:04:32, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.99±10.84, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0017, mean_reward_over_100_episodes_from_eval 30.45±10.73
2025-12-28 19:51:14,537 | INFO | [trial_001 | seed 29] elapsed_time 01:05:39, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 30.07±10.77, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0017, mean_reward_over_100_episodes_from_eval 30.54±10.67
2025-12-28 19:52:48,889 | INFO | [trial_001 | seed 29] elapsed_time 01:07:13, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.14±10.70, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0017, mean_reward_over_100_episodes_from_eval 30.57±10.59
2025-12-28 19:53:52,806 | INFO | [trial_001 | seed 29] elapsed_time 01:08:17, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.18±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0017, mean_reward_over_100_episodes_from_eval 30.57±10.51
2025-12-28 19:55:46,076 | INFO | [trial_001 | seed 29] elapsed_time 01:10:11, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.22±10.54, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0018, mean_reward_over_100_episodes_from_eval 30.68±10.46
2025-12-28 19:57:34,081 | INFO | [trial_001 | seed 29] elapsed_time 01:11:59, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.32±10.50, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0018, mean_reward_over_100_episodes_from_eval 30.73±10.39
2025-12-28 19:59:25,415 | INFO | [trial_001 | seed 29] elapsed_time 01:13:50, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.33±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0018, mean_reward_over_100_episodes_from_eval 30.73±10.32
2025-12-28 20:01:19,169 | INFO | [trial_001 | seed 29] elapsed_time 01:15:44, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 30.36±10.35, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0018, mean_reward_over_100_episodes_from_eval 30.76±10.25
2025-12-28 20:02:49,219 | INFO | [trial_001 | seed 29] elapsed_time 01:17:14, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.41±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0019, mean_reward_over_100_episodes_from_eval 30.80±10.18
2025-12-28 20:04:05,218 | INFO | [trial_001 | seed 29] elapsed_time 01:18:30, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.44±10.21, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0019, mean_reward_over_100_episodes_from_eval 30.85±10.12
2025-12-28 20:05:33,060 | INFO | [trial_001 | seed 29] elapsed_time 01:19:57, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.749999, episode_sum_max_abs_reward_per_step 39.749999, mean_reward_over_100_episodes_from_training 30.49±10.15, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0019, mean_reward_over_100_episodes_from_eval 30.89±10.05
2025-12-28 20:06:54,486 | INFO | [trial_001 | seed 29] elapsed_time 01:21:19, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.56±10.10, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0019, mean_reward_over_100_episodes_from_eval 30.99±10.02
2025-12-28 20:08:31,413 | INFO | [trial_001 | seed 29] elapsed_time 01:22:56, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.65±10.06, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0020, mean_reward_over_100_episodes_from_eval 31.06±09.97
2025-12-28 20:09:59,648 | INFO | [trial_001 | seed 29] elapsed_time 01:24:24, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.73±10.01, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0020, mean_reward_over_100_episodes_from_eval 31.11±09.91
2025-12-28 20:11:22,689 | INFO | [trial_001 | seed 29] elapsed_time 01:25:47, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.82±09.98, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0020, mean_reward_over_100_episodes_from_eval 31.15±09.85
2025-12-28 20:12:46,065 | INFO | [trial_001 | seed 29] elapsed_time 01:27:11, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 30.87±09.92, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0020, mean_reward_over_100_episodes_from_eval 31.18±09.79
2025-12-28 20:14:20,945 | INFO | [trial_001 | seed 29] elapsed_time 01:28:45, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.93±09.87, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0020, mean_reward_over_100_episodes_from_eval 31.23±09.74
2025-12-28 20:15:43,651 | INFO | [trial_001 | seed 29] elapsed_time 01:30:08, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 31.01±09.83, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0021, mean_reward_over_100_episodes_from_eval 31.29±09.69
2025-12-28 20:17:06,716 | INFO | [trial_001 | seed 29] elapsed_time 01:31:31, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 31.07±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0021, mean_reward_over_100_episodes_from_eval 31.35±09.65
2025-12-28 20:18:38,329 | INFO | [trial_001 | seed 29] elapsed_time 01:33:03, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 31.12±09.74, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0021, mean_reward_over_100_episodes_from_eval 31.40±09.60
2025-12-28 20:20:02,892 | INFO | [trial_001 | seed 29] elapsed_time 01:34:27, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 31.11±09.68, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0021, mean_reward_over_100_episodes_from_eval 31.42±09.54
2025-12-28 20:21:22,109 | INFO | [trial_001 | seed 29] elapsed_time 01:35:47, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 31.13±09.62, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0021, mean_reward_over_100_episodes_from_eval 31.47±09.49
2025-12-28 20:22:41,141 | INFO | [trial_001 | seed 29] elapsed_time 01:37:06, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 31.19±09.58, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0021, mean_reward_over_100_episodes_from_eval 31.53±09.45
2025-12-28 20:23:58,241 | INFO | [trial_001 | seed 29] elapsed_time 01:38:23, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 31.25±09.54, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0021, mean_reward_over_100_episodes_from_eval 31.55±09.40
2025-12-28 20:25:15,951 | INFO | [trial_001 | seed 29] elapsed_time 01:39:40, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 31.28±09.49, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0021, mean_reward_over_100_episodes_from_eval 31.59±09.35
2025-12-28 20:26:32,477 | INFO | [trial_001 | seed 29] elapsed_time 01:40:57, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 31.33±09.45, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0021, mean_reward_over_100_episodes_from_eval 31.64±09.31
2025-12-28 20:27:58,642 | INFO | [trial_001 | seed 29] elapsed_time 01:42:23, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 31.40±09.41, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 31.70±09.27
2025-12-28 20:29:32,716 | INFO | [trial_001 | seed 29] elapsed_time 01:43:57, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 31.45±09.37, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 31.76±09.24
2025-12-28 20:30:56,162 | INFO | [trial_001 | seed 29] elapsed_time 01:45:21, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 31.52±09.34, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0021, mean_reward_over_100_episodes_from_eval 31.83±09.21
2025-12-28 20:32:22,160 | INFO | [trial_001 | seed 29] elapsed_time 01:46:47, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 31.57±09.30, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0022, mean_reward_over_100_episodes_from_eval 31.88±09.17
2025-12-28 20:33:44,245 | INFO | [trial_001 | seed 29] elapsed_time 01:48:09, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 31.63±09.27, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0022, mean_reward_over_100_episodes_from_eval 31.88±09.12
2025-12-28 20:35:04,346 | INFO | [trial_001 | seed 29] elapsed_time 01:49:29, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 31.66±09.22, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0022, mean_reward_over_100_episodes_from_eval 31.88±09.07
2025-12-28 20:36:29,219 | INFO | [trial_001 | seed 29] elapsed_time 01:50:54, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 31.68±09.18, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0022, mean_reward_over_100_episodes_from_eval 31.92±09.03
2025-12-28 20:37:53,826 | INFO | [trial_001 | seed 29] elapsed_time 01:52:18, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 31.67±09.13, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0022, mean_reward_over_100_episodes_from_eval 31.89±08.99
2025-12-28 20:39:25,581 | INFO | [trial_001 | seed 29] elapsed_time 01:53:50, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 31.71±09.09, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0022, mean_reward_over_100_episodes_from_eval 31.92±08.94
2025-12-28 20:40:48,796 | INFO | [trial_001 | seed 29] elapsed_time 01:55:13, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 31.73±09.04, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0022, mean_reward_over_100_episodes_from_eval 31.90±08.90
2025-12-28 20:42:07,327 | INFO | [trial_001 | seed 29] elapsed_time 01:56:32, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 31.74±09.00, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0022, mean_reward_over_100_episodes_from_eval 31.92±08.85
2025-12-28 20:43:35,822 | INFO | [trial_001 | seed 29] elapsed_time 01:58:00, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 31.77±08.96, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0022, mean_reward_over_100_episodes_from_eval 31.98±08.83
2025-12-28 20:44:55,860 | INFO | [trial_001 | seed 29] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=32.03
2025-12-28 20:44:55,864 | INFO | [trial_001 | seed 29] elapsed_time 01:59:20, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 31.83±08.93, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0022, mean_reward_over_100_episodes_from_eval 32.03±08.80
2025-12-28 20:44:55,864 | INFO | [trial_001 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-28 21:26:52,771 | INFO | [trial_001 | seed 29] Training complete.
2025-12-28 21:26:52,774 | INFO | [trial_001 | seed 29] Solved (evaluation metric) at episode 100.
2025-12-28 21:26:52,775 | INFO | [trial_001 | seed 29] Final evaluation score 37.71±0.53 in 4890.90s training, 9677.71s wall.
2025-12-28 21:26:52,775 | INFO | [trial_001 | seed 29] Closing UnityVectorEnv (worker_id=1029).
2025-12-28 21:26:52,776 | INFO | [Main] Requesting worker 1029 to close Unity env.
2025-12-28 21:26:54,402 | INFO | [Main] Worker 1029 joined. Unity env fully closed.
2025-12-28 21:26:54,406 | INFO | [trial_001 | seed 29] Final eval score: 37.71
2025-12-28 21:26:54,989 | INFO | [trial_001 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_001_seed_29.png
2025-12-28 21:26:54,991 | INFO | [trial_001 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-28 21:26:55,392 | INFO | [trial_001] Final scores across seeds: [37.713]
2025-12-28 21:26:55,392 | INFO | [trial_001] Avg=37.713 ± 0.000, Best seed score=37.713
2025-12-28 21:26:55,394 | INFO | [trial_002] Starting trial with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[64,64],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-28 21:26:55,397 | INFO | [trial_002 | seed 29] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[64,64],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-28 21:26:55,397 | INFO | [trial_002 | seed 29] === Starting run for seed 29 ===
2025-12-28 21:26:55,398 | INFO | [trial_002 | seed 29] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[64,64],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-28 21:26:55,446 | INFO | [trial_002 | seed 29] Launching UnityVectorEnv with worker_id=2029, seed=29
2025-12-28 21:26:55,447 | INFO | [Main] Spawning worker 2029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-28 21:26:55,470 | INFO | [Main] Worker 2029 started (pid=50508).
2025-12-28 21:27:02,667 | INFO | [trial_002 | seed 29] Environment batched agents (train): 20
2025-12-28 21:27:48,494 | INFO | [trial_002 | seed 29] Environment batched agents (eval): 20
2025-12-28 21:28:10,327 | INFO | [trial_002 | seed 29] elapsed_time 00:01:14, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 13.570000, episode_sum_max_abs_reward_per_step 13.570000, mean_reward_over_100_episodes_from_training 00.78±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0317±0.0000, mean_reward_over_100_episodes_from_eval 01.05±00.00
2025-12-28 21:29:21,557 | INFO | [trial_002 | seed 29] elapsed_time 00:02:26, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 14.710000, episode_sum_max_abs_reward_per_step 14.710000, mean_reward_over_100_episodes_from_training 00.85±00.07, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0019, mean_reward_over_100_episodes_from_eval 00.85±00.20
2025-12-28 21:30:31,712 | INFO | [trial_002 | seed 29] elapsed_time 00:03:36, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 16.960000, episode_sum_max_abs_reward_per_step 16.960000, mean_reward_over_100_episodes_from_training 00.93±00.13, mean_exploration_ratio_over_100_episodes_from_training 0.0289±0.0020, mean_reward_over_100_episodes_from_eval 00.96±00.23
2025-12-28 21:31:38,132 | INFO | [trial_002 | seed 29] elapsed_time 00:04:42, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 23.759999, episode_sum_max_abs_reward_per_step 23.759999, mean_reward_over_100_episodes_from_training 01.12±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0018, mean_reward_over_100_episodes_from_eval 01.18±00.43
2025-12-28 21:32:46,365 | INFO | [trial_002 | seed 29] elapsed_time 00:05:50, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 23.899999, episode_sum_max_abs_reward_per_step 23.899999, mean_reward_over_100_episodes_from_training 01.25±00.41, mean_exploration_ratio_over_100_episodes_from_training 0.0284±0.0017, mean_reward_over_100_episodes_from_eval 01.17±00.38
2025-12-28 21:34:02,623 | INFO | [trial_002 | seed 29] elapsed_time 00:07:07, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 18.220000, episode_sum_max_abs_reward_per_step 18.220000, mean_reward_over_100_episodes_from_training 01.25±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0016, mean_reward_over_100_episodes_from_eval 01.21±00.36
2025-12-28 21:35:13,742 | INFO | [trial_002 | seed 29] elapsed_time 00:08:18, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 21.020000, episode_sum_max_abs_reward_per_step 21.020000, mean_reward_over_100_episodes_from_training 01.28±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0019, mean_reward_over_100_episodes_from_eval 01.29±00.39
2025-12-28 21:36:22,456 | INFO | [trial_002 | seed 29] elapsed_time 00:09:27, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 24.629999, episode_sum_max_abs_reward_per_step 24.629999, mean_reward_over_100_episodes_from_training 01.35±00.39, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0019, mean_reward_over_100_episodes_from_eval 01.33±00.38
2025-12-28 21:37:32,985 | INFO | [trial_002 | seed 29] elapsed_time 00:10:37, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 29.209999, episode_sum_max_abs_reward_per_step 29.209999, mean_reward_over_100_episodes_from_training 01.50±00.55, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0018, mean_reward_over_100_episodes_from_eval 01.41±00.42
2025-12-28 21:38:41,694 | INFO | [trial_002 | seed 29] elapsed_time 00:11:46, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 30.779999, episode_sum_max_abs_reward_per_step 30.779999, mean_reward_over_100_episodes_from_training 01.67±00.73, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0018, mean_reward_over_100_episodes_from_eval 01.62±00.75
2025-12-28 21:39:53,344 | INFO | [trial_002 | seed 29] elapsed_time 00:12:57, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 33.029999, episode_sum_max_abs_reward_per_step 33.029999, mean_reward_over_100_episodes_from_training 01.84±00.89, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0018, mean_reward_over_100_episodes_from_eval 02.00±01.40
2025-12-28 21:41:03,530 | INFO | [trial_002 | seed 29] elapsed_time 00:14:08, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 36.159999, episode_sum_max_abs_reward_per_step 36.159999, mean_reward_over_100_episodes_from_training 02.14±01.30, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0017, mean_reward_over_100_episodes_from_eval 02.49±02.10
2025-12-28 21:42:13,755 | INFO | [trial_002 | seed 29] elapsed_time 00:15:18, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.239999, episode_sum_max_abs_reward_per_step 39.239999, mean_reward_over_100_episodes_from_training 02.54±01.88, mean_exploration_ratio_over_100_episodes_from_training 0.0270±0.0016, mean_reward_over_100_episodes_from_eval 02.92±02.51
2025-12-28 21:43:23,973 | INFO | [trial_002 | seed 29] elapsed_time 00:16:28, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 03.05±02.57, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0017, mean_reward_over_100_episodes_from_eval 03.38±02.94
2025-12-28 21:44:34,468 | INFO | [trial_002 | seed 29] elapsed_time 00:17:39, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 38.519999, episode_sum_max_abs_reward_per_step 38.519999, mean_reward_over_100_episodes_from_training 03.34±02.70, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0017, mean_reward_over_100_episodes_from_eval 03.85±03.34
2025-12-28 21:45:48,149 | INFO | [trial_002 | seed 29] elapsed_time 00:18:52, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 03.81±03.19, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0018, mean_reward_over_100_episodes_from_eval 04.41±03.88
2025-12-28 21:46:56,972 | INFO | [trial_002 | seed 29] elapsed_time 00:20:01, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 04.49±04.14, mean_exploration_ratio_over_100_episodes_from_training 0.0278±0.0021, mean_reward_over_100_episodes_from_eval 05.19±04.90
2025-12-28 21:48:09,530 | INFO | [trial_002 | seed 29] elapsed_time 00:21:14, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 05.20±04.97, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0022, mean_reward_over_100_episodes_from_eval 05.93±05.65
2025-12-28 21:49:35,242 | INFO | [trial_002 | seed 29] elapsed_time 00:22:39, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 06.07±06.08, mean_exploration_ratio_over_100_episodes_from_training 0.0284±0.0026, mean_reward_over_100_episodes_from_eval 06.81±06.66
2025-12-28 21:50:48,125 | INFO | [trial_002 | seed 29] elapsed_time 00:23:52, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 07.04±07.28, mean_exploration_ratio_over_100_episodes_from_training 0.0287±0.0029, mean_reward_over_100_episodes_from_eval 08.02±08.37
2025-12-28 21:51:52,416 | INFO | [trial_002 | seed 29] elapsed_time 00:24:57, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 08.13±08.61, mean_exploration_ratio_over_100_episodes_from_training 0.0291±0.0033, mean_reward_over_100_episodes_from_eval 09.16±09.61
2025-12-28 21:53:00,698 | INFO | [trial_002 | seed 29] elapsed_time 00:26:05, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 09.21±09.76, mean_exploration_ratio_over_100_episodes_from_training 0.0294±0.0035, mean_reward_over_100_episodes_from_eval 10.38±10.93
2025-12-28 21:54:06,257 | INFO | [trial_002 | seed 29] elapsed_time 00:27:10, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 10.31±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0038, mean_reward_over_100_episodes_from_eval 11.50±11.92
2025-12-28 21:55:18,381 | INFO | [trial_002 | seed 29] elapsed_time 00:28:22, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 11.37±11.78, mean_exploration_ratio_over_100_episodes_from_training 0.0301±0.0041, mean_reward_over_100_episodes_from_eval 12.45±12.53
2025-12-28 21:56:27,868 | INFO | [trial_002 | seed 29] elapsed_time 00:29:32, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 12.24±12.31, mean_exploration_ratio_over_100_episodes_from_training 0.0304±0.0042, mean_reward_over_100_episodes_from_eval 13.28±12.92
2025-12-28 21:57:36,072 | INFO | [trial_002 | seed 29] elapsed_time 00:30:40, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 12.94±12.57, mean_exploration_ratio_over_100_episodes_from_training 0.0306±0.0043, mean_reward_over_100_episodes_from_eval 13.84±12.97
2025-12-28 21:58:44,806 | INFO | [trial_002 | seed 29] elapsed_time 00:31:49, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 13.65±12.86, mean_exploration_ratio_over_100_episodes_from_training 0.0309±0.0045, mean_reward_over_100_episodes_from_eval 14.65±13.39
2025-12-28 21:59:51,566 | INFO | [trial_002 | seed 29] elapsed_time 00:32:56, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 14.37±13.15, mean_exploration_ratio_over_100_episodes_from_training 0.0312±0.0046, mean_reward_over_100_episodes_from_eval 15.06±13.33
2025-12-28 22:00:58,346 | INFO | [trial_002 | seed 29] elapsed_time 00:34:02, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 15.02±13.38, mean_exploration_ratio_over_100_episodes_from_training 0.0314±0.0047, mean_reward_over_100_episodes_from_eval 15.63±13.43
2025-12-28 22:02:04,729 | INFO | [trial_002 | seed 29] elapsed_time 00:35:09, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 15.68±13.63, mean_exploration_ratio_over_100_episodes_from_training 0.0316±0.0048, mean_reward_over_100_episodes_from_eval 16.32±13.72
2025-12-28 22:03:10,738 | INFO | [trial_002 | seed 29] elapsed_time 00:36:15, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 16.37±13.93, mean_exploration_ratio_over_100_episodes_from_training 0.0318±0.0049, mean_reward_over_100_episodes_from_eval 17.01±14.01
2025-12-28 22:04:17,397 | INFO | [trial_002 | seed 29] elapsed_time 00:37:22, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 17.01±14.17, mean_exploration_ratio_over_100_episodes_from_training 0.0320±0.0049, mean_reward_over_100_episodes_from_eval 17.65±14.25
2025-12-28 22:05:24,443 | INFO | [trial_002 | seed 29] elapsed_time 00:38:29, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 17.57±14.30, mean_exploration_ratio_over_100_episodes_from_training 0.0323±0.0050, mean_reward_over_100_episodes_from_eval 18.21±14.39
2025-12-28 22:06:31,068 | INFO | [trial_002 | seed 29] elapsed_time 00:39:35, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 17.98±14.29, mean_exploration_ratio_over_100_episodes_from_training 0.0324±0.0050, mean_reward_over_100_episodes_from_eval 18.52±14.29
2025-12-28 22:07:38,860 | INFO | [trial_002 | seed 29] elapsed_time 00:40:43, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 18.35±14.25, mean_exploration_ratio_over_100_episodes_from_training 0.0326±0.0051, mean_reward_over_100_episodes_from_eval 18.90±14.25
2025-12-28 22:08:44,568 | INFO | [trial_002 | seed 29] elapsed_time 00:41:49, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 18.61±14.13, mean_exploration_ratio_over_100_episodes_from_training 0.0328±0.0051, mean_reward_over_100_episodes_from_eval 19.08±14.09
2025-12-28 22:09:56,121 | INFO | [trial_002 | seed 29] elapsed_time 00:43:00, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 18.90±14.05, mean_exploration_ratio_over_100_episodes_from_training 0.0330±0.0051, mean_reward_over_100_episodes_from_eval 19.42±14.05
2025-12-28 22:11:02,178 | INFO | [trial_002 | seed 29] elapsed_time 00:44:06, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 19.32±14.10, mean_exploration_ratio_over_100_episodes_from_training 0.0331±0.0052, mean_reward_over_100_episodes_from_eval 19.85±14.11
2025-12-28 22:12:07,691 | INFO | [trial_002 | seed 29] elapsed_time 00:45:12, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 19.62±14.04, mean_exploration_ratio_over_100_episodes_from_training 0.0332±0.0051, mean_reward_over_100_episodes_from_eval 20.23±14.12
2025-12-28 22:13:17,708 | INFO | [trial_002 | seed 29] elapsed_time 00:46:22, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 19.96±14.02, mean_exploration_ratio_over_100_episodes_from_training 0.0333±0.0052, mean_reward_over_100_episodes_from_eval 20.52±14.06
2025-12-28 22:14:34,353 | INFO | [trial_002 | seed 29] elapsed_time 00:47:38, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 20.16±13.91, mean_exploration_ratio_over_100_episodes_from_training 0.0334±0.0051, mean_reward_over_100_episodes_from_eval 20.73±13.95
2025-12-28 22:15:52,557 | INFO | [trial_002 | seed 29] elapsed_time 00:48:57, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 20.25±13.75, mean_exploration_ratio_over_100_episodes_from_training 0.0335±0.0051, mean_reward_over_100_episodes_from_eval 20.93±13.84
2025-12-28 22:17:08,618 | INFO | [trial_002 | seed 29] elapsed_time 00:50:13, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 20.43±13.64, mean_exploration_ratio_over_100_episodes_from_training 0.0336±0.0051, mean_reward_over_100_episodes_from_eval 20.94±13.68
2025-12-28 22:18:21,401 | INFO | [trial_002 | seed 29] elapsed_time 00:51:26, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 20.50±13.49, mean_exploration_ratio_over_100_episodes_from_training 0.0337±0.0050, mean_reward_over_100_episodes_from_eval 21.15±13.59
2025-12-28 22:19:35,497 | INFO | [trial_002 | seed 29] elapsed_time 00:52:40, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 20.72±13.42, mean_exploration_ratio_over_100_episodes_from_training 0.0338±0.0050, mean_reward_over_100_episodes_from_eval 21.40±13.55
2025-12-28 22:20:48,045 | INFO | [trial_002 | seed 29] elapsed_time 00:53:52, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.01±13.42, mean_exploration_ratio_over_100_episodes_from_training 0.0339±0.0050, mean_reward_over_100_episodes_from_eval 21.58±13.45
2025-12-28 22:22:00,600 | INFO | [trial_002 | seed 29] elapsed_time 00:55:05, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.29±13.41, mean_exploration_ratio_over_100_episodes_from_training 0.0340±0.0050, mean_reward_over_100_episodes_from_eval 21.80±13.39
2025-12-28 22:23:14,541 | INFO | [trial_002 | seed 29] elapsed_time 00:56:19, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 21.54±13.38, mean_exploration_ratio_over_100_episodes_from_training 0.0341±0.0050, mean_reward_over_100_episodes_from_eval 22.06±13.37
2025-12-28 22:24:28,370 | INFO | [trial_002 | seed 29] elapsed_time 00:57:32, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 21.78±13.34, mean_exploration_ratio_over_100_episodes_from_training 0.0342±0.0050, mean_reward_over_100_episodes_from_eval 22.23±13.29
2025-12-28 22:25:42,008 | INFO | [trial_002 | seed 29] elapsed_time 00:58:46, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.97±13.28, mean_exploration_ratio_over_100_episodes_from_training 0.0342±0.0050, mean_reward_over_100_episodes_from_eval 22.36±13.18
2025-12-28 22:26:51,129 | INFO | [trial_002 | seed 29] elapsed_time 00:59:55, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.15±13.21, mean_exploration_ratio_over_100_episodes_from_training 0.0343±0.0049, mean_reward_over_100_episodes_from_eval 22.62±13.19
2025-12-28 22:28:02,205 | INFO | [trial_002 | seed 29] elapsed_time 01:01:06, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.40±13.20, mean_exploration_ratio_over_100_episodes_from_training 0.0344±0.0049, mean_reward_over_100_episodes_from_eval 22.86±13.16
2025-12-28 22:29:13,025 | INFO | [trial_002 | seed 29] elapsed_time 01:02:17, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 22.63±13.18, mean_exploration_ratio_over_100_episodes_from_training 0.0344±0.0049, mean_reward_over_100_episodes_from_eval 23.03±13.10
2025-12-28 22:30:24,709 | INFO | [trial_002 | seed 29] elapsed_time 01:03:29, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 22.79±13.11, mean_exploration_ratio_over_100_episodes_from_training 0.0345±0.0049, mean_reward_over_100_episodes_from_eval 23.21±13.04
2025-12-28 22:31:33,753 | INFO | [trial_002 | seed 29] elapsed_time 01:04:38, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 22.92±13.03, mean_exploration_ratio_over_100_episodes_from_training 0.0346±0.0049, mean_reward_over_100_episodes_from_eval 23.37±12.98
2025-12-28 22:32:43,411 | INFO | [trial_002 | seed 29] elapsed_time 01:05:48, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.08±12.97, mean_exploration_ratio_over_100_episodes_from_training 0.0346±0.0048, mean_reward_over_100_episodes_from_eval 23.57±12.94
2025-12-28 22:33:57,391 | INFO | [trial_002 | seed 29] elapsed_time 01:07:01, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.26±12.92, mean_exploration_ratio_over_100_episodes_from_training 0.0347±0.0048, mean_reward_over_100_episodes_from_eval 23.76±12.91
2025-12-28 22:35:18,836 | INFO | [trial_002 | seed 29] elapsed_time 01:08:23, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.39±12.85, mean_exploration_ratio_over_100_episodes_from_training 0.0348±0.0048, mean_reward_over_100_episodes_from_eval 23.90±12.84
2025-12-28 22:36:41,260 | INFO | [trial_002 | seed 29] elapsed_time 01:09:45, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 23.59±12.83, mean_exploration_ratio_over_100_episodes_from_training 0.0348±0.0048, mean_reward_over_100_episodes_from_eval 24.13±12.86
2025-12-28 22:37:53,297 | INFO | [trial_002 | seed 29] elapsed_time 01:10:57, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.81±12.83, mean_exploration_ratio_over_100_episodes_from_training 0.0348±0.0047, mean_reward_over_100_episodes_from_eval 24.31±12.82
2025-12-28 22:39:05,323 | INFO | [trial_002 | seed 29] elapsed_time 01:12:09, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 23.88±12.73, mean_exploration_ratio_over_100_episodes_from_training 0.0349±0.0047, mean_reward_over_100_episodes_from_eval 24.38±12.72
2025-12-28 22:40:18,782 | INFO | [trial_002 | seed 29] elapsed_time 01:13:23, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 23.98±12.65, mean_exploration_ratio_over_100_episodes_from_training 0.0349±0.0047, mean_reward_over_100_episodes_from_eval 24.54±12.68
2025-12-28 22:41:31,108 | INFO | [trial_002 | seed 29] elapsed_time 01:14:35, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 24.13±12.61, mean_exploration_ratio_over_100_episodes_from_training 0.0349±0.0047, mean_reward_over_100_episodes_from_eval 24.65±12.61
2025-12-28 22:42:41,687 | INFO | [trial_002 | seed 29] elapsed_time 01:15:46, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 24.18±12.52, mean_exploration_ratio_over_100_episodes_from_training 0.0350±0.0046, mean_reward_over_100_episodes_from_eval 24.69±12.52
2025-12-28 22:43:55,866 | INFO | [trial_002 | seed 29] elapsed_time 01:17:00, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 24.30±12.46, mean_exploration_ratio_over_100_episodes_from_training 0.0350±0.0046, mean_reward_over_100_episodes_from_eval 24.76±12.44
2025-12-28 22:45:07,688 | INFO | [trial_002 | seed 29] elapsed_time 01:18:12, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 24.42±12.41, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0046, mean_reward_over_100_episodes_from_eval 24.84±12.36
2025-12-28 22:46:18,927 | INFO | [trial_002 | seed 29] elapsed_time 01:19:23, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 24.53±12.34, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0046, mean_reward_over_100_episodes_from_eval 24.81±12.27
2025-12-28 22:47:30,014 | INFO | [trial_002 | seed 29] elapsed_time 01:20:34, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 24.58±12.26, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0045, mean_reward_over_100_episodes_from_eval 24.78±12.18
2025-12-28 22:48:40,504 | INFO | [trial_002 | seed 29] elapsed_time 01:21:45, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 24.65±12.18, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0045, mean_reward_over_100_episodes_from_eval 24.83±12.10
2025-12-28 22:49:51,157 | INFO | [trial_002 | seed 29] elapsed_time 01:22:55, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 24.70±12.10, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0045, mean_reward_over_100_episodes_from_eval 24.92±12.03
2025-12-28 22:51:02,339 | INFO | [trial_002 | seed 29] elapsed_time 01:24:06, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 24.82±12.06, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0044, mean_reward_over_100_episodes_from_eval 25.04±11.99
2025-12-28 22:52:12,658 | INFO | [trial_002 | seed 29] elapsed_time 01:25:17, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 24.91±12.00, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0044, mean_reward_over_100_episodes_from_eval 24.93±11.94
2025-12-28 22:53:23,208 | INFO | [trial_002 | seed 29] elapsed_time 01:26:27, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 24.92±11.91, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0044, mean_reward_over_100_episodes_from_eval 25.03±11.89
2025-12-28 22:54:33,439 | INFO | [trial_002 | seed 29] elapsed_time 01:27:38, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 25.04±11.88, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0043, mean_reward_over_100_episodes_from_eval 25.10±11.83
2025-12-28 22:55:46,040 | INFO | [trial_002 | seed 29] elapsed_time 01:28:50, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 25.17±11.85, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0043, mean_reward_over_100_episodes_from_eval 25.27±11.84
2025-12-28 22:56:55,244 | INFO | [trial_002 | seed 29] elapsed_time 01:29:59, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 25.29±11.82, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0043, mean_reward_over_100_episodes_from_eval 25.40±11.81
2025-12-28 22:58:06,885 | INFO | [trial_002 | seed 29] elapsed_time 01:31:11, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 25.37±11.76, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0043, mean_reward_over_100_episodes_from_eval 25.45±11.74
2025-12-28 22:59:18,511 | INFO | [trial_002 | seed 29] elapsed_time 01:32:23, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 25.40±11.69, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0042, mean_reward_over_100_episodes_from_eval 25.43±11.66
2025-12-28 23:00:30,080 | INFO | [trial_002 | seed 29] elapsed_time 01:33:34, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 25.44±11.62, mean_exploration_ratio_over_100_episodes_from_training 0.0352±0.0042, mean_reward_over_100_episodes_from_eval 25.45±11.59
2025-12-28 23:01:40,485 | INFO | [trial_002 | seed 29] elapsed_time 01:34:45, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 25.51±11.57, mean_exploration_ratio_over_100_episodes_from_training 0.0352±0.0042, mean_reward_over_100_episodes_from_eval 25.59±11.58
2025-12-28 23:02:50,719 | INFO | [trial_002 | seed 29] elapsed_time 01:35:55, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 25.64±11.55, mean_exploration_ratio_over_100_episodes_from_training 0.0352±0.0042, mean_reward_over_100_episodes_from_eval 25.73±11.57
2025-12-28 23:03:59,916 | INFO | [trial_002 | seed 29] elapsed_time 01:37:04, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.77±11.54, mean_exploration_ratio_over_100_episodes_from_training 0.0352±0.0042, mean_reward_over_100_episodes_from_eval 25.83±11.54
2025-12-28 23:05:10,399 | INFO | [trial_002 | seed 29] elapsed_time 01:38:15, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 25.89±11.52, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0041, mean_reward_over_100_episodes_from_eval 25.88±11.48
2025-12-28 23:06:21,856 | INFO | [trial_002 | seed 29] elapsed_time 01:39:26, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 25.99±11.49, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0041, mean_reward_over_100_episodes_from_eval 25.91±11.41
2025-12-28 23:07:29,590 | INFO | [trial_002 | seed 29] elapsed_time 01:40:34, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.07±11.44, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0041, mean_reward_over_100_episodes_from_eval 26.01±11.39
2025-12-28 23:08:39,356 | INFO | [trial_002 | seed 29] elapsed_time 01:41:43, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 26.18±11.43, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0041, mean_reward_over_100_episodes_from_eval 26.09±11.34
2025-12-28 23:09:51,451 | INFO | [trial_002 | seed 29] elapsed_time 01:42:56, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.26±11.38, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0041, mean_reward_over_100_episodes_from_eval 26.20±11.32
2025-12-28 23:11:01,071 | INFO | [trial_002 | seed 29] elapsed_time 01:44:05, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 26.34±11.34, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0041, mean_reward_over_100_episodes_from_eval 26.22±11.26
2025-12-28 23:12:09,792 | INFO | [trial_002 | seed 29] elapsed_time 01:45:14, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 26.38±11.28, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0040, mean_reward_over_100_episodes_from_eval 26.32±11.24
2025-12-28 23:13:29,142 | INFO | [trial_002 | seed 29] elapsed_time 01:46:33, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 26.45±11.24, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0040, mean_reward_over_100_episodes_from_eval 26.35±11.18
2025-12-28 23:14:37,979 | INFO | [trial_002 | seed 29] elapsed_time 01:47:42, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 26.49±11.19, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0040, mean_reward_over_100_episodes_from_eval 26.39±11.13
2025-12-28 23:15:49,984 | INFO | [trial_002 | seed 29] elapsed_time 01:48:54, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.49±11.13, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0040, mean_reward_over_100_episodes_from_eval 26.42±11.07
2025-12-28 23:16:58,919 | INFO | [trial_002 | seed 29] elapsed_time 01:50:03, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 26.56±11.08, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0040, mean_reward_over_100_episodes_from_eval 26.49±11.03
2025-12-28 23:18:08,046 | INFO | [trial_002 | seed 29] elapsed_time 01:51:12, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.63±11.05, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0040, mean_reward_over_100_episodes_from_eval 26.57±11.00
2025-12-28 23:19:26,136 | INFO | [trial_002 | seed 29] elapsed_time 01:52:30, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 26.70±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0039, mean_reward_over_100_episodes_from_eval 26.62±10.95
2025-12-28 23:20:49,682 | INFO | [trial_002 | seed 29] elapsed_time 01:53:54, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 26.74±10.96, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0039, mean_reward_over_100_episodes_from_eval 26.64±10.90
2025-12-28 23:22:10,351 | INFO | [trial_002 | seed 29] elapsed_time 01:55:14, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 26.79±10.91, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0039, mean_reward_over_100_episodes_from_eval 26.73±10.88
2025-12-28 23:23:23,311 | INFO | [trial_002 | seed 29] elapsed_time 01:56:27, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 26.84±10.87, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0039, mean_reward_over_100_episodes_from_eval 26.82±10.86
2025-12-28 23:24:34,686 | INFO | [trial_002 | seed 29] elapsed_time 01:57:39, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.91±10.84, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0039, mean_reward_over_100_episodes_from_eval 26.88±10.82
2025-12-28 23:25:46,832 | INFO | [trial_002 | seed 29] elapsed_time 01:58:51, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 26.97±10.80, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0039, mean_reward_over_100_episodes_from_eval 26.93±10.78
2025-12-28 23:27:03,792 | INFO | [trial_002 | seed 29] elapsed_time 02:00:08, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.29±10.49, mean_exploration_ratio_over_100_episodes_from_training 0.0356±0.0038, mean_reward_over_100_episodes_from_eval 27.26±10.48
2025-12-28 23:28:19,500 | INFO | [trial_002 | seed 29] elapsed_time 02:01:24, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.59±10.15, mean_exploration_ratio_over_100_episodes_from_training 0.0357±0.0038, mean_reward_over_100_episodes_from_eval 27.55±10.14
2025-12-28 23:29:32,400 | INFO | [trial_002 | seed 29] elapsed_time 02:02:37, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 27.88±09.80, mean_exploration_ratio_over_100_episodes_from_training 0.0358±0.0037, mean_reward_over_100_episodes_from_eval 27.84±09.79
2025-12-28 23:30:47,176 | INFO | [trial_002 | seed 29] elapsed_time 02:03:51, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 28.16±09.44, mean_exploration_ratio_over_100_episodes_from_training 0.0358±0.0036, mean_reward_over_100_episodes_from_eval 28.16±09.45
2025-12-28 23:32:00,470 | INFO | [trial_002 | seed 29] elapsed_time 02:05:05, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 28.43±09.06, mean_exploration_ratio_over_100_episodes_from_training 0.0359±0.0035, mean_reward_over_100_episodes_from_eval 28.48±09.06
2025-12-28 23:33:14,954 | INFO | [trial_002 | seed 29] elapsed_time 02:06:19, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.73±08.64, mean_exploration_ratio_over_100_episodes_from_training 0.0360±0.0034, mean_reward_over_100_episodes_from_eval 28.77±08.64
2025-12-28 23:34:28,053 | INFO | [trial_002 | seed 29] elapsed_time 02:07:32, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.04±08.20, mean_exploration_ratio_over_100_episodes_from_training 0.0361±0.0032, mean_reward_over_100_episodes_from_eval 29.03±08.21
2025-12-28 23:35:40,058 | INFO | [trial_002 | seed 29] elapsed_time 02:08:44, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.33±07.74, mean_exploration_ratio_over_100_episodes_from_training 0.0362±0.0030, mean_reward_over_100_episodes_from_eval 29.26±07.74
2025-12-28 23:36:50,549 | INFO | [trial_002 | seed 29] elapsed_time 02:09:55, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 29.54±07.28, mean_exploration_ratio_over_100_episodes_from_training 0.0362±0.0029, mean_reward_over_100_episodes_from_eval 29.45±07.29
2025-12-28 23:38:01,215 | INFO | [trial_002 | seed 29] elapsed_time 02:11:05, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.74±06.82, mean_exploration_ratio_over_100_episodes_from_training 0.0363±0.0027, mean_reward_over_100_episodes_from_eval 29.65±06.85
2025-12-28 23:39:13,302 | INFO | [trial_002 | seed 29] elapsed_time 02:12:17, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 30.02±06.29, mean_exploration_ratio_over_100_episodes_from_training 0.0364±0.0025, mean_reward_over_100_episodes_from_eval 29.89±06.41
2025-12-28 23:40:25,498 | INFO | [trial_002 | seed 29] Requirement met (evaluation metric): solved at episode 112 with mean_100_eval=30.09
2025-12-28 23:40:25,501 | INFO | [trial_002 | seed 29] elapsed_time 02:13:30, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 30.27±05.78, mean_exploration_ratio_over_100_episodes_from_training 0.0365±0.0023, mean_reward_over_100_episodes_from_eval 30.09±06.03
2025-12-28 23:40:25,502 | INFO | [trial_002 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 00:18:01,379 | INFO | [trial_002 | seed 29] Training complete.
2025-12-29 00:18:01,380 | INFO | [trial_002 | seed 29] Solved (evaluation metric) at episode 112.
2025-12-29 00:18:01,380 | INFO | [trial_002 | seed 29] Final evaluation score 27.16±1.07 in 5504.67s training, 10265.98s wall.
2025-12-29 00:18:01,380 | INFO | [trial_002 | seed 29] Closing UnityVectorEnv (worker_id=2029).
2025-12-29 00:18:01,380 | INFO | [Main] Requesting worker 2029 to close Unity env.
2025-12-29 00:18:02,479 | INFO | [Main] Worker 2029 joined. Unity env fully closed.
2025-12-29 00:18:02,480 | INFO | [trial_002 | seed 29] Final eval score: 27.16
2025-12-29 00:18:02,861 | INFO | [trial_002 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_002_seed_29.png
2025-12-29 00:18:02,862 | INFO | [trial_002 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 00:18:03,062 | INFO | [trial_002] Final scores across seeds: [27.165]
2025-12-29 00:18:03,062 | INFO | [trial_002] Avg=27.165 ± 0.000, Best seed score=27.165
2025-12-29 00:18:03,064 | INFO | [trial_003] Starting trial with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 00:18:03,066 | INFO | [trial_003 | seed 29] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 00:18:03,067 | INFO | [trial_003 | seed 29] === Starting run for seed 29 ===
2025-12-29 00:18:03,067 | INFO | [trial_003 | seed 29] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 00:18:03,069 | INFO | [trial_003 | seed 29] Launching UnityVectorEnv with worker_id=3029, seed=29
2025-12-29 00:18:03,069 | INFO | [Main] Spawning worker 3029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 00:18:03,084 | INFO | [Main] Worker 3029 started (pid=66228).
2025-12-29 00:18:07,678 | INFO | [trial_003 | seed 29] Environment batched agents (train): 20
2025-12-29 00:18:53,535 | INFO | [trial_003 | seed 29] Environment batched agents (eval): 20
2025-12-29 00:19:17,613 | INFO | [trial_003 | seed 29] elapsed_time 00:01:14, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 13.730000, episode_sum_max_abs_reward_per_step 13.730000, mean_reward_over_100_episodes_from_training 00.84±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0289±0.0000, mean_reward_over_100_episodes_from_eval 01.01±00.00
2025-12-29 00:20:30,918 | INFO | [trial_003 | seed 29] elapsed_time 00:02:27, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 18.650000, episode_sum_max_abs_reward_per_step 18.650000, mean_reward_over_100_episodes_from_training 01.06±00.22, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0003, mean_reward_over_100_episodes_from_eval 01.01±00.00
2025-12-29 00:21:51,888 | INFO | [trial_003 | seed 29] elapsed_time 00:03:48, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 11.480000, episode_sum_max_abs_reward_per_step 11.480000, mean_reward_over_100_episodes_from_training 00.95±00.24, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0003, mean_reward_over_100_episodes_from_eval 01.21±00.27
2025-12-29 00:23:06,095 | INFO | [trial_003 | seed 29] elapsed_time 00:05:03, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 21.050000, episode_sum_max_abs_reward_per_step 21.050000, mean_reward_over_100_episodes_from_training 01.10±00.33, mean_exploration_ratio_over_100_episodes_from_training 0.0283±0.0004, mean_reward_over_100_episodes_from_eval 01.36±00.36
2025-12-29 00:24:30,730 | INFO | [trial_003 | seed 29] elapsed_time 00:06:27, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 27.029999, episode_sum_max_abs_reward_per_step 27.029999, mean_reward_over_100_episodes_from_training 01.31±00.51, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0007, mean_reward_over_100_episodes_from_eval 01.56±00.51
2025-12-29 00:25:51,184 | INFO | [trial_003 | seed 29] elapsed_time 00:07:48, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 31.829999, episode_sum_max_abs_reward_per_step 31.829999, mean_reward_over_100_episodes_from_training 01.64±00.87, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0008, mean_reward_over_100_episodes_from_eval 02.14±01.37
2025-12-29 00:27:09,419 | INFO | [trial_003 | seed 29] elapsed_time 00:09:06, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 37.399999, episode_sum_max_abs_reward_per_step 37.399999, mean_reward_over_100_episodes_from_training 02.10±01.40, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0009, mean_reward_over_100_episodes_from_eval 02.44±01.47
2025-12-29 00:28:36,492 | INFO | [trial_003 | seed 29] elapsed_time 00:10:33, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 38.579999, episode_sum_max_abs_reward_per_step 38.579999, mean_reward_over_100_episodes_from_training 02.65±01.95, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0009, mean_reward_over_100_episodes_from_eval 03.13±02.28
2025-12-29 00:29:57,085 | INFO | [trial_003 | seed 29] elapsed_time 00:11:54, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 39.429999, episode_sum_max_abs_reward_per_step 39.429999, mean_reward_over_100_episodes_from_training 03.37±02.75, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0010, mean_reward_over_100_episodes_from_eval 03.76±02.79
2025-12-29 00:31:17,056 | INFO | [trial_003 | seed 29] elapsed_time 00:13:13, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 04.47±04.19, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0010, mean_reward_over_100_episodes_from_eval 05.34±05.42
2025-12-29 00:32:34,493 | INFO | [trial_003 | seed 29] elapsed_time 00:14:31, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 05.82±05.87, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0009, mean_reward_over_100_episodes_from_eval 06.75±06.82
2025-12-29 00:33:53,703 | INFO | [trial_003 | seed 29] elapsed_time 00:15:50, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 07.29±07.44, mean_exploration_ratio_over_100_episodes_from_training 0.0279±0.0024, mean_reward_over_100_episodes_from_eval 08.40±08.54
2025-12-29 00:35:11,756 | INFO | [trial_003 | seed 29] elapsed_time 00:17:08, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 08.93±09.11, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0024, mean_reward_over_100_episodes_from_eval 09.82±09.56
2025-12-29 00:36:28,909 | INFO | [trial_003 | seed 29] elapsed_time 00:18:25, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 10.36±10.19, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0027, mean_reward_over_100_episodes_from_eval 11.34±10.71
2025-12-29 00:37:45,899 | INFO | [trial_003 | seed 29] elapsed_time 00:19:42, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 11.94±11.48, mean_exploration_ratio_over_100_episodes_from_training 0.0287±0.0027, mean_reward_over_100_episodes_from_eval 12.85±11.80
2025-12-29 00:39:05,176 | INFO | [trial_003 | seed 29] elapsed_time 00:21:02, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 13.44±12.55, mean_exploration_ratio_over_100_episodes_from_training 0.0290±0.0030, mean_reward_over_100_episodes_from_eval 14.18±12.53
2025-12-29 00:40:25,116 | INFO | [trial_003 | seed 29] elapsed_time 00:22:22, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 14.65±13.10, mean_exploration_ratio_over_100_episodes_from_training 0.0292±0.0030, mean_reward_over_100_episodes_from_eval 15.41±13.12
2025-12-29 00:41:43,866 | INFO | [trial_003 | seed 29] elapsed_time 00:23:40, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 15.81±13.59, mean_exploration_ratio_over_100_episodes_from_training 0.0294±0.0030, mean_reward_over_100_episodes_from_eval 16.43±13.42
2025-12-29 00:43:02,958 | INFO | [trial_003 | seed 29] elapsed_time 00:24:59, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 16.85±13.96, mean_exploration_ratio_over_100_episodes_from_training 0.0296±0.0031, mean_reward_over_100_episodes_from_eval 17.40±13.69
2025-12-29 00:44:20,421 | INFO | [trial_003 | seed 29] elapsed_time 00:26:17, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 17.78±14.19, mean_exploration_ratio_over_100_episodes_from_training 0.0296±0.0030, mean_reward_over_100_episodes_from_eval 18.29±13.90
2025-12-29 00:45:39,509 | INFO | [trial_003 | seed 29] elapsed_time 00:27:36, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 18.62±14.35, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0029, mean_reward_over_100_episodes_from_eval 19.20±14.17
2025-12-29 00:47:06,924 | INFO | [trial_003 | seed 29] elapsed_time 00:29:03, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 19.42±14.48, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0029, mean_reward_over_100_episodes_from_eval 20.00±14.31
2025-12-29 00:48:39,405 | INFO | [trial_003 | seed 29] elapsed_time 00:30:36, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 20.14±14.56, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0028, mean_reward_over_100_episodes_from_eval 20.61±14.29
2025-12-29 00:50:11,375 | INFO | [trial_003 | seed 29] elapsed_time 00:32:08, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.76±14.56, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0028, mean_reward_over_100_episodes_from_eval 21.28±14.35
2025-12-29 00:51:33,711 | INFO | [trial_003 | seed 29] elapsed_time 00:33:30, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.30±14.52, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0027, mean_reward_over_100_episodes_from_eval 21.90±14.38
2025-12-29 00:52:53,639 | INFO | [trial_003 | seed 29] elapsed_time 00:34:50, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.74±14.40, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0027, mean_reward_over_100_episodes_from_eval 22.28±14.24
2025-12-29 00:54:11,481 | INFO | [trial_003 | seed 29] elapsed_time 00:36:08, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 22.13±14.27, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0026, mean_reward_over_100_episodes_from_eval 22.73±14.15
2025-12-29 00:55:30,648 | INFO | [trial_003 | seed 29] elapsed_time 00:37:27, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 22.52±14.16, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0026, mean_reward_over_100_episodes_from_eval 23.10±14.03
2025-12-29 00:56:50,937 | INFO | [trial_003 | seed 29] elapsed_time 00:38:47, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.94±14.09, mean_exploration_ratio_over_100_episodes_from_training 0.0299±0.0026, mean_reward_over_100_episodes_from_eval 23.48±13.93
2025-12-29 00:58:09,873 | INFO | [trial_003 | seed 29] elapsed_time 00:40:06, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.32±14.00, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0026, mean_reward_over_100_episodes_from_eval 23.81±13.81
2025-12-29 00:59:31,686 | INFO | [trial_003 | seed 29] elapsed_time 00:41:28, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.54±13.83, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0026, mean_reward_over_100_episodes_from_eval 23.95±13.61
2025-12-29 01:00:51,415 | INFO | [trial_003 | seed 29] elapsed_time 00:42:48, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 23.73±13.65, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0025, mean_reward_over_100_episodes_from_eval 24.26±13.50
2025-12-29 01:02:10,207 | INFO | [trial_003 | seed 29] elapsed_time 00:44:07, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.04±13.56, mean_exploration_ratio_over_100_episodes_from_training 0.0296±0.0025, mean_reward_over_100_episodes_from_eval 24.51±13.38
2025-12-29 01:03:30,364 | INFO | [trial_003 | seed 29] elapsed_time 00:45:27, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.31±13.45, mean_exploration_ratio_over_100_episodes_from_training 0.0295±0.0025, mean_reward_over_100_episodes_from_eval 24.72±13.23
2025-12-29 01:04:47,172 | INFO | [trial_003 | seed 29] elapsed_time 00:46:44, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.59±13.35, mean_exploration_ratio_over_100_episodes_from_training 0.0294±0.0025, mean_reward_over_100_episodes_from_eval 24.95±13.11
2025-12-29 01:06:07,228 | INFO | [trial_003 | seed 29] elapsed_time 00:48:04, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 24.82±13.23, mean_exploration_ratio_over_100_episodes_from_training 0.0293±0.0026, mean_reward_over_100_episodes_from_eval 25.24±13.04
2025-12-29 01:07:26,845 | INFO | [trial_003 | seed 29] elapsed_time 00:49:23, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.07±13.14, mean_exploration_ratio_over_100_episodes_from_training 0.0293±0.0026, mean_reward_over_100_episodes_from_eval 25.51±12.96
2025-12-29 01:08:44,724 | INFO | [trial_003 | seed 29] elapsed_time 00:50:41, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 25.31±13.05, mean_exploration_ratio_over_100_episodes_from_training 0.0292±0.0026, mean_reward_over_100_episodes_from_eval 25.76±12.88
2025-12-29 01:10:03,053 | INFO | [trial_003 | seed 29] elapsed_time 00:51:59, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 25.53±12.95, mean_exploration_ratio_over_100_episodes_from_training 0.0291±0.0027, mean_reward_over_100_episodes_from_eval 25.94±12.77
2025-12-29 01:11:20,713 | INFO | [trial_003 | seed 29] elapsed_time 00:53:17, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.74±12.86, mean_exploration_ratio_over_100_episodes_from_training 0.0290±0.0026, mean_reward_over_100_episodes_from_eval 26.21±12.72
2025-12-29 01:12:39,017 | INFO | [trial_003 | seed 29] elapsed_time 00:54:35, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.96±12.77, mean_exploration_ratio_over_100_episodes_from_training 0.0290±0.0026, mean_reward_over_100_episodes_from_eval 26.44±12.64
2025-12-29 01:14:08,223 | INFO | [trial_003 | seed 29] elapsed_time 00:56:05, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.18±12.70, mean_exploration_ratio_over_100_episodes_from_training 0.0289±0.0026, mean_reward_over_100_episodes_from_eval 26.65±12.57
2025-12-29 01:15:28,222 | INFO | [trial_003 | seed 29] elapsed_time 00:57:25, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.39±12.62, mean_exploration_ratio_over_100_episodes_from_training 0.0288±0.0027, mean_reward_over_100_episodes_from_eval 26.86±12.49
2025-12-29 01:16:46,853 | INFO | [trial_003 | seed 29] elapsed_time 00:58:43, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.55±12.52, mean_exploration_ratio_over_100_episodes_from_training 0.0287±0.0027, mean_reward_over_100_episodes_from_eval 26.94±12.36
2025-12-29 01:18:05,794 | INFO | [trial_003 | seed 29] elapsed_time 01:00:02, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 26.69±12.42, mean_exploration_ratio_over_100_episodes_from_training 0.0287±0.0027, mean_reward_over_100_episodes_from_eval 27.10±12.27
2025-12-29 01:19:24,362 | INFO | [trial_003 | seed 29] elapsed_time 01:01:21, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.83±12.32, mean_exploration_ratio_over_100_episodes_from_training 0.0286±0.0027, mean_reward_over_100_episodes_from_eval 27.26±12.18
2025-12-29 01:20:42,517 | INFO | [trial_003 | seed 29] elapsed_time 01:02:39, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 27.03±12.27, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0028, mean_reward_over_100_episodes_from_eval 27.48±12.14
2025-12-29 01:22:03,365 | INFO | [trial_003 | seed 29] elapsed_time 01:04:00, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 27.20±12.19, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0027, mean_reward_over_100_episodes_from_eval 27.65±12.07
2025-12-29 01:23:22,946 | INFO | [trial_003 | seed 29] elapsed_time 01:05:19, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 27.36±12.12, mean_exploration_ratio_over_100_episodes_from_training 0.0284±0.0028, mean_reward_over_100_episodes_from_eval 27.84±12.02
2025-12-29 01:24:43,112 | INFO | [trial_003 | seed 29] elapsed_time 01:06:40, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 27.51±12.04, mean_exploration_ratio_over_100_episodes_from_training 0.0283±0.0028, mean_reward_over_100_episodes_from_eval 27.91±11.91
2025-12-29 01:26:01,786 | INFO | [trial_003 | seed 29] elapsed_time 01:07:58, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.65±11.97, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0029, mean_reward_over_100_episodes_from_eval 28.05±11.83
2025-12-29 01:27:20,132 | INFO | [trial_003 | seed 29] elapsed_time 01:09:17, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 27.75±11.87, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0029, mean_reward_over_100_episodes_from_eval 28.16±11.75
2025-12-29 01:28:41,991 | INFO | [trial_003 | seed 29] elapsed_time 01:10:38, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.84±11.77, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0029, mean_reward_over_100_episodes_from_eval 28.24±11.65
2025-12-29 01:30:02,216 | INFO | [trial_003 | seed 29] elapsed_time 01:11:59, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.92±11.68, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0029, mean_reward_over_100_episodes_from_eval 28.34±11.56
2025-12-29 01:31:22,044 | INFO | [trial_003 | seed 29] elapsed_time 01:13:18, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.01±11.59, mean_exploration_ratio_over_100_episodes_from_training 0.0279±0.0029, mean_reward_over_100_episodes_from_eval 28.37±11.46
2025-12-29 01:32:38,436 | INFO | [trial_003 | seed 29] elapsed_time 01:14:35, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.14±11.53, mean_exploration_ratio_over_100_episodes_from_training 0.0279±0.0029, mean_reward_over_100_episodes_from_eval 28.51±11.41
2025-12-29 01:33:56,671 | INFO | [trial_003 | seed 29] elapsed_time 01:15:53, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 28.27±11.46, mean_exploration_ratio_over_100_episodes_from_training 0.0278±0.0029, mean_reward_over_100_episodes_from_eval 28.63±11.34
2025-12-29 01:35:29,222 | INFO | [trial_003 | seed 29] elapsed_time 01:17:26, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.36±11.39, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0030, mean_reward_over_100_episodes_from_eval 28.73±11.27
2025-12-29 01:37:00,833 | INFO | [trial_003 | seed 29] elapsed_time 01:18:57, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 28.49±11.34, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0030, mean_reward_over_100_episodes_from_eval 28.86±11.22
2025-12-29 01:38:20,125 | INFO | [trial_003 | seed 29] elapsed_time 01:20:17, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 28.56±11.25, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0030, mean_reward_over_100_episodes_from_eval 28.91±11.13
2025-12-29 01:39:39,926 | INFO | [trial_003 | seed 29] elapsed_time 01:21:36, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.57±11.16, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0030, mean_reward_over_100_episodes_from_eval 28.89±11.04
2025-12-29 01:41:01,469 | INFO | [trial_003 | seed 29] elapsed_time 01:22:58, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.66±11.09, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0031, mean_reward_over_100_episodes_from_eval 29.02±10.99
2025-12-29 01:42:21,072 | INFO | [trial_003 | seed 29] elapsed_time 01:24:18, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.73±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0031, mean_reward_over_100_episodes_from_eval 29.09±10.92
2025-12-29 01:43:40,518 | INFO | [trial_003 | seed 29] elapsed_time 01:25:37, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.83±10.96, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0031, mean_reward_over_100_episodes_from_eval 29.21±10.88
2025-12-29 01:45:02,544 | INFO | [trial_003 | seed 29] elapsed_time 01:26:59, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 28.91±10.89, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0031, mean_reward_over_100_episodes_from_eval 29.29±10.81
2025-12-29 01:46:22,483 | INFO | [trial_003 | seed 29] elapsed_time 01:28:19, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.00±10.83, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0032, mean_reward_over_100_episodes_from_eval 29.31±10.73
2025-12-29 01:47:41,339 | INFO | [trial_003 | seed 29] elapsed_time 01:29:38, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.11±10.79, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0032, mean_reward_over_100_episodes_from_eval 29.38±10.67
2025-12-29 01:49:02,189 | INFO | [trial_003 | seed 29] elapsed_time 01:30:59, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.18±10.73, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0032, mean_reward_over_100_episodes_from_eval 29.47±10.61
2025-12-29 01:50:21,732 | INFO | [trial_003 | seed 29] elapsed_time 01:32:18, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.28±10.68, mean_exploration_ratio_over_100_episodes_from_training 0.0270±0.0032, mean_reward_over_100_episodes_from_eval 29.58±10.57
2025-12-29 01:51:39,570 | INFO | [trial_003 | seed 29] elapsed_time 01:33:36, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.37±10.63, mean_exploration_ratio_over_100_episodes_from_training 0.0269±0.0033, mean_reward_over_100_episodes_from_eval 29.67±10.52
2025-12-29 01:53:00,273 | INFO | [trial_003 | seed 29] elapsed_time 01:34:57, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.42±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0033, mean_reward_over_100_episodes_from_eval 29.73±10.46
2025-12-29 01:54:19,356 | INFO | [trial_003 | seed 29] elapsed_time 01:36:16, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.46±10.50, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0033, mean_reward_over_100_episodes_from_eval 29.79±10.40
2025-12-29 01:55:38,668 | INFO | [trial_003 | seed 29] elapsed_time 01:37:35, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 29.52±10.43, mean_exploration_ratio_over_100_episodes_from_training 0.0267±0.0033, mean_reward_over_100_episodes_from_eval 29.85±10.34
2025-12-29 01:56:56,794 | INFO | [trial_003 | seed 29] elapsed_time 01:38:53, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.56±10.37, mean_exploration_ratio_over_100_episodes_from_training 0.0267±0.0033, mean_reward_over_100_episodes_from_eval 29.87±10.28
2025-12-29 01:58:13,879 | INFO | [trial_003 | seed 29] elapsed_time 01:40:10, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.61±10.31, mean_exploration_ratio_over_100_episodes_from_training 0.0266±0.0033, mean_reward_over_100_episodes_from_eval 29.92±10.22
2025-12-29 01:59:34,573 | INFO | [trial_003 | seed 29] elapsed_time 01:41:31, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 29.65±10.25, mean_exploration_ratio_over_100_episodes_from_training 0.0266±0.0033, mean_reward_over_100_episodes_from_eval 29.93±10.15
2025-12-29 02:00:53,977 | INFO | [trial_003 | seed 29] elapsed_time 01:42:50, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.69±10.18, mean_exploration_ratio_over_100_episodes_from_training 0.0265±0.0034, mean_reward_over_100_episodes_from_eval 29.99±10.10
2025-12-29 02:02:12,392 | INFO | [trial_003 | seed 29] elapsed_time 01:44:09, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 29.73±10.13, mean_exploration_ratio_over_100_episodes_from_training 0.0265±0.0034, mean_reward_over_100_episodes_from_eval 29.97±10.03
2025-12-29 02:03:29,718 | INFO | [trial_003 | seed 29] elapsed_time 01:45:26, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 29.75±10.06, mean_exploration_ratio_over_100_episodes_from_training 0.0265±0.0033, mean_reward_over_100_episodes_from_eval 30.04±09.99
2025-12-29 02:04:48,108 | INFO | [trial_003 | seed 29] elapsed_time 01:46:45, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.82±10.02, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0033, mean_reward_over_100_episodes_from_eval 30.13±09.95
2025-12-29 02:06:07,458 | INFO | [trial_003 | seed 29] elapsed_time 01:48:04, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.87±09.97, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0033, mean_reward_over_100_episodes_from_eval 30.16±09.90
2025-12-29 02:07:25,902 | INFO | [trial_003 | seed 29] elapsed_time 01:49:22, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 29.89±09.91, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0033, mean_reward_over_100_episodes_from_eval 30.19±09.84
2025-12-29 02:08:44,777 | INFO | [trial_003 | seed 29] elapsed_time 01:50:41, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.92±09.85, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0033, mean_reward_over_100_episodes_from_eval 30.24±09.79
2025-12-29 02:10:04,220 | INFO | [trial_003 | seed 29] elapsed_time 01:52:01, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.00±09.82, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0033, mean_reward_over_100_episodes_from_eval 30.33±09.77
2025-12-29 02:11:23,357 | INFO | [trial_003 | seed 29] elapsed_time 01:53:20, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.08±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0033, mean_reward_over_100_episodes_from_eval 30.40±09.73
2025-12-29 02:12:40,416 | INFO | [trial_003 | seed 29] elapsed_time 01:54:37, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.15±09.76, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0033, mean_reward_over_100_episodes_from_eval 30.47±09.70
2025-12-29 02:14:05,905 | INFO | [trial_003 | seed 29] elapsed_time 01:56:02, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 30.21±09.72, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0033, mean_reward_over_100_episodes_from_eval 30.55±09.67
2025-12-29 02:15:22,536 | INFO | [trial_003 | seed 29] elapsed_time 01:57:19, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 30.27±09.68, mean_exploration_ratio_over_100_episodes_from_training 0.0261±0.0033, mean_reward_over_100_episodes_from_eval 30.64±09.65
2025-12-29 02:16:36,653 | INFO | [trial_003 | seed 29] elapsed_time 01:58:33, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.34±09.64, mean_exploration_ratio_over_100_episodes_from_training 0.0261±0.0033, mean_reward_over_100_episodes_from_eval 30.66±09.59
2025-12-29 02:17:52,076 | INFO | [trial_003 | seed 29] elapsed_time 01:59:49, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.40±09.61, mean_exploration_ratio_over_100_episodes_from_training 0.0261±0.0033, mean_reward_over_100_episodes_from_eval 30.72±09.56
2025-12-29 02:19:05,895 | INFO | [trial_003 | seed 29] elapsed_time 02:01:02, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.48±09.58, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0033, mean_reward_over_100_episodes_from_eval 30.76±09.51
2025-12-29 02:20:22,718 | INFO | [trial_003 | seed 29] elapsed_time 02:02:19, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 30.52±09.54, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0033, mean_reward_over_100_episodes_from_eval 30.83±09.49
2025-12-29 02:21:37,519 | INFO | [trial_003 | seed 29] elapsed_time 02:03:34, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 30.55±09.49, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0033, mean_reward_over_100_episodes_from_eval 30.85±09.43
2025-12-29 02:22:50,982 | INFO | [trial_003 | seed 29] elapsed_time 02:04:47, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.55±09.44, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0033, mean_reward_over_100_episodes_from_eval 30.86±09.39
2025-12-29 02:24:07,668 | INFO | [trial_003 | seed 29] elapsed_time 02:06:04, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 30.57±09.39, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0033, mean_reward_over_100_episodes_from_eval 30.91±09.35
2025-12-29 02:25:27,458 | INFO | [trial_003 | seed 29] elapsed_time 02:07:24, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.64±09.37, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0033, mean_reward_over_100_episodes_from_eval 30.97±09.32
2025-12-29 02:26:42,128 | INFO | [trial_003 | seed 29] elapsed_time 02:08:39, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.69±09.33, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0033, mean_reward_over_100_episodes_from_eval 31.04±09.30
2025-12-29 02:27:58,482 | INFO | [trial_003 | seed 29] elapsed_time 02:09:55, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.75±09.30, mean_exploration_ratio_over_100_episodes_from_training 0.0258±0.0033, mean_reward_over_100_episodes_from_eval 31.10±09.27
2025-12-29 02:29:15,459 | INFO | [trial_003 | seed 29] elapsed_time 02:11:12, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 30.79±09.27, mean_exploration_ratio_over_100_episodes_from_training 0.0258±0.0033, mean_reward_over_100_episodes_from_eval 31.13±09.23
2025-12-29 02:30:41,384 | INFO | [trial_003 | seed 29] Requirement met (evaluation metric): solved at episode 100 with mean_100_eval=31.13
2025-12-29 02:30:41,386 | INFO | [trial_003 | seed 29] elapsed_time 02:12:38, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.81±09.22, mean_exploration_ratio_over_100_episodes_from_training 0.0258±0.0033, mean_reward_over_100_episodes_from_eval 31.13±09.18
2025-12-29 02:30:41,386 | INFO | [trial_003 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 03:10:19,532 | INFO | [trial_003 | seed 29] Training complete.
2025-12-29 03:10:19,533 | INFO | [trial_003 | seed 29] Solved (evaluation metric) at episode 100.
2025-12-29 03:10:19,533 | INFO | [trial_003 | seed 29] Final evaluation score 33.07±1.66 in 5435.43s training, 10336.47s wall.
2025-12-29 03:10:19,534 | INFO | [trial_003 | seed 29] Closing UnityVectorEnv (worker_id=3029).
2025-12-29 03:10:19,534 | INFO | [Main] Requesting worker 3029 to close Unity env.
2025-12-29 03:10:20,339 | INFO | [Main] Worker 3029 joined. Unity env fully closed.
2025-12-29 03:10:20,340 | INFO | [trial_003 | seed 29] Final eval score: 33.07
2025-12-29 03:10:20,680 | INFO | [trial_003 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_003_seed_29.png
2025-12-29 03:10:20,681 | INFO | [trial_003 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 03:10:20,881 | INFO | [trial_003] Final scores across seeds: [33.073]
2025-12-29 03:10:20,881 | INFO | [trial_003] Avg=33.073 ± 0.000, Best seed score=33.073
2025-12-29 03:10:20,883 | INFO | [trial_004] Starting trial with hparams: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[128,128],"lr":0.0001,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":10,"tau":0.005}
2025-12-29 03:10:20,886 | INFO | [trial_004 | seed 29] Start training with hparams: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[128,128],"lr":0.0001,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":10,"tau":0.005}
2025-12-29 03:10:20,888 | INFO | [trial_004 | seed 29] === Starting run for seed 29 ===
2025-12-29 03:10:20,888 | INFO | [trial_004 | seed 29] Hyperparameters: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[128,128],"lr":0.0001,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":10,"tau":0.005}
2025-12-29 03:10:20,890 | INFO | [trial_004 | seed 29] Launching UnityVectorEnv with worker_id=4029, seed=29
2025-12-29 03:10:20,890 | INFO | [Main] Spawning worker 4029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 03:10:20,910 | INFO | [Main] Worker 4029 started (pid=70880).
2025-12-29 03:10:25,812 | INFO | [trial_004 | seed 29] Environment batched agents (train): 20
2025-12-29 03:11:10,925 | INFO | [trial_004 | seed 29] Environment batched agents (eval): 20
2025-12-29 03:11:34,803 | INFO | [trial_004 | seed 29] elapsed_time 00:01:13, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 13.000000, episode_sum_max_abs_reward_per_step 13.000000, mean_reward_over_100_episodes_from_training 00.78±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0301±0.0000, mean_reward_over_100_episodes_from_eval 00.71±00.00
2025-12-29 03:12:42,665 | INFO | [trial_004 | seed 29] elapsed_time 00:02:21, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 12.310000, episode_sum_max_abs_reward_per_step 12.310000, mean_reward_over_100_episodes_from_training 00.74±00.04, mean_exploration_ratio_over_100_episodes_from_training 0.0290±0.0011, mean_reward_over_100_episodes_from_eval 00.86±00.16
2025-12-29 03:13:59,744 | INFO | [trial_004 | seed 29] elapsed_time 00:03:38, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 12.570000, episode_sum_max_abs_reward_per_step 12.570000, mean_reward_over_100_episodes_from_training 00.74±00.03, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0014, mean_reward_over_100_episodes_from_eval 00.84±00.13
2025-12-29 03:15:09,396 | INFO | [trial_004 | seed 29] elapsed_time 00:04:48, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 11.350000, episode_sum_max_abs_reward_per_step 11.350000, mean_reward_over_100_episodes_from_training 00.71±00.06, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0013, mean_reward_over_100_episodes_from_eval 00.80±00.13
2025-12-29 03:16:19,628 | INFO | [trial_004 | seed 29] elapsed_time 00:05:58, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 13.380000, episode_sum_max_abs_reward_per_step 13.380000, mean_reward_over_100_episodes_from_training 00.74±00.08, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0013, mean_reward_over_100_episodes_from_eval 00.87±00.19
2025-12-29 03:17:30,647 | INFO | [trial_004 | seed 29] elapsed_time 00:07:09, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 15.350000, episode_sum_max_abs_reward_per_step 15.350000, mean_reward_over_100_episodes_from_training 00.79±00.12, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0013, mean_reward_over_100_episodes_from_eval 00.92±00.20
2025-12-29 03:18:40,399 | INFO | [trial_004 | seed 29] elapsed_time 00:08:19, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 15.080000, episode_sum_max_abs_reward_per_step 15.080000, mean_reward_over_100_episodes_from_training 00.83±00.15, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0012, mean_reward_over_100_episodes_from_eval 00.91±00.19
2025-12-29 03:19:52,014 | INFO | [trial_004 | seed 29] elapsed_time 00:09:31, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 17.460000, episode_sum_max_abs_reward_per_step 17.460000, mean_reward_over_100_episodes_from_training 00.87±00.18, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0011, mean_reward_over_100_episodes_from_eval 00.97±00.23
2025-12-29 03:21:01,646 | INFO | [trial_004 | seed 29] elapsed_time 00:10:40, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 17.130000, episode_sum_max_abs_reward_per_step 17.130000, mean_reward_over_100_episodes_from_training 00.89±00.18, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0011, mean_reward_over_100_episodes_from_eval 01.01±00.25
2025-12-29 03:22:12,440 | INFO | [trial_004 | seed 29] elapsed_time 00:11:51, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 20.030000, episode_sum_max_abs_reward_per_step 20.030000, mean_reward_over_100_episodes_from_training 00.95±00.25, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0013, mean_reward_over_100_episodes_from_eval 01.08±00.31
2025-12-29 03:23:24,300 | INFO | [trial_004 | seed 29] elapsed_time 00:13:03, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 14.710000, episode_sum_max_abs_reward_per_step 14.710000, mean_reward_over_100_episodes_from_training 00.95±00.24, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0014, mean_reward_over_100_episodes_from_eval 01.01±00.36
2025-12-29 03:24:47,283 | INFO | [trial_004 | seed 29] elapsed_time 00:14:26, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 04.120000, episode_sum_max_abs_reward_per_step 04.120000, mean_reward_over_100_episodes_from_training 00.90±00.30, mean_exploration_ratio_over_100_episodes_from_training 0.0267±0.0020, mean_reward_over_100_episodes_from_eval 00.94±00.42
2025-12-29 03:26:09,205 | INFO | [trial_004 | seed 29] elapsed_time 00:15:48, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 03.800000, episode_sum_max_abs_reward_per_step 03.800000, mean_reward_over_100_episodes_from_training 00.84±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0022, mean_reward_over_100_episodes_from_eval 00.92±00.41
2025-12-29 03:27:28,697 | INFO | [trial_004 | seed 29] elapsed_time 00:17:07, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 24.949999, episode_sum_max_abs_reward_per_step 24.949999, mean_reward_over_100_episodes_from_training 00.92±00.42, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0022, mean_reward_over_100_episodes_from_eval 01.01±00.49
2025-12-29 03:28:40,388 | INFO | [trial_004 | seed 29] elapsed_time 00:18:19, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 25.439999, episode_sum_max_abs_reward_per_step 25.439999, mean_reward_over_100_episodes_from_training 01.00±00.51, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0021, mean_reward_over_100_episodes_from_eval 01.06±00.51
2025-12-29 03:29:52,931 | INFO | [trial_004 | seed 29] elapsed_time 00:19:32, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 22.260000, episode_sum_max_abs_reward_per_step 22.260000, mean_reward_over_100_episodes_from_training 01.06±00.54, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0021, mean_reward_over_100_episodes_from_eval 01.09±00.51
2025-12-29 03:31:04,181 | INFO | [trial_004 | seed 29] elapsed_time 00:20:43, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 05.310000, episode_sum_max_abs_reward_per_step 05.310000, mean_reward_over_100_episodes_from_training 01.02±00.54, mean_exploration_ratio_over_100_episodes_from_training 0.0261±0.0021, mean_reward_over_100_episodes_from_eval 01.05±00.51
2025-12-29 03:32:14,864 | INFO | [trial_004 | seed 29] elapsed_time 00:21:53, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 18.970000, episode_sum_max_abs_reward_per_step 18.970000, mean_reward_over_100_episodes_from_training 01.03±00.53, mean_exploration_ratio_over_100_episodes_from_training 0.0261±0.0020, mean_reward_over_100_episodes_from_eval 01.06±00.50
2025-12-29 03:33:27,113 | INFO | [trial_004 | seed 29] elapsed_time 00:23:06, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 16.390000, episode_sum_max_abs_reward_per_step 16.390000, mean_reward_over_100_episodes_from_training 01.04±00.52, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0020, mean_reward_over_100_episodes_from_eval 01.05±00.49
2025-12-29 03:34:37,794 | INFO | [trial_004 | seed 29] elapsed_time 00:24:16, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 16.720000, episode_sum_max_abs_reward_per_step 16.720000, mean_reward_over_100_episodes_from_training 01.04±00.50, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0020, mean_reward_over_100_episodes_from_eval 01.03±00.48
2025-12-29 03:35:49,820 | INFO | [trial_004 | seed 29] elapsed_time 00:25:28, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 21.970000, episode_sum_max_abs_reward_per_step 21.970000, mean_reward_over_100_episodes_from_training 01.07±00.50, mean_exploration_ratio_over_100_episodes_from_training 0.0258±0.0020, mean_reward_over_100_episodes_from_eval 01.07±00.49
2025-12-29 03:37:00,551 | INFO | [trial_004 | seed 29] elapsed_time 00:26:39, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 25.639999, episode_sum_max_abs_reward_per_step 25.639999, mean_reward_over_100_episodes_from_training 01.11±00.53, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0020, mean_reward_over_100_episodes_from_eval 01.13±00.56
2025-12-29 03:38:11,113 | INFO | [trial_004 | seed 29] elapsed_time 00:27:50, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 29.839999, episode_sum_max_abs_reward_per_step 29.839999, mean_reward_over_100_episodes_from_training 01.17±00.60, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0020, mean_reward_over_100_episodes_from_eval 01.20±00.63
2025-12-29 03:39:23,066 | INFO | [trial_004 | seed 29] elapsed_time 00:29:02, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 32.979999, episode_sum_max_abs_reward_per_step 32.979999, mean_reward_over_100_episodes_from_training 01.26±00.72, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0019, mean_reward_over_100_episodes_from_eval 01.28±00.73
2025-12-29 03:40:34,557 | INFO | [trial_004 | seed 29] elapsed_time 00:30:13, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 34.189999, episode_sum_max_abs_reward_per_step 34.189999, mean_reward_over_100_episodes_from_training 01.34±00.82, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0019, mean_reward_over_100_episodes_from_eval 01.38±00.87
2025-12-29 03:41:45,207 | INFO | [trial_004 | seed 29] elapsed_time 00:31:24, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 32.829999, episode_sum_max_abs_reward_per_step 32.829999, mean_reward_over_100_episodes_from_training 01.43±00.90, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0019, mean_reward_over_100_episodes_from_eval 01.48±01.00
2025-12-29 03:42:56,141 | INFO | [trial_004 | seed 29] elapsed_time 00:32:35, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 36.599999, episode_sum_max_abs_reward_per_step 36.599999, mean_reward_over_100_episodes_from_training 01.53±01.03, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0018, mean_reward_over_100_episodes_from_eval 01.63±01.24
2025-12-29 03:44:07,442 | INFO | [trial_004 | seed 29] elapsed_time 00:33:46, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 38.189999, episode_sum_max_abs_reward_per_step 38.189999, mean_reward_over_100_episodes_from_training 01.67±01.24, mean_exploration_ratio_over_100_episodes_from_training 0.0258±0.0018, mean_reward_over_100_episodes_from_eval 01.77±01.42
2025-12-29 03:45:18,330 | INFO | [trial_004 | seed 29] elapsed_time 00:34:57, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 38.529999, episode_sum_max_abs_reward_per_step 38.529999, mean_reward_over_100_episodes_from_training 01.84±01.51, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0018, mean_reward_over_100_episodes_from_eval 01.97±01.74
2025-12-29 03:46:29,407 | INFO | [trial_004 | seed 29] elapsed_time 00:36:08, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.249999, episode_sum_max_abs_reward_per_step 39.249999, mean_reward_over_100_episodes_from_training 02.05±01.89, mean_exploration_ratio_over_100_episodes_from_training 0.0258±0.0018, mean_reward_over_100_episodes_from_eval 02.17±02.02
2025-12-29 03:47:40,109 | INFO | [trial_004 | seed 29] elapsed_time 00:37:19, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 38.569999, episode_sum_max_abs_reward_per_step 38.569999, mean_reward_over_100_episodes_from_training 02.23±02.10, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0018, mean_reward_over_100_episodes_from_eval 02.35±02.22
2025-12-29 03:48:51,309 | INFO | [trial_004 | seed 29] elapsed_time 00:38:30, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 38.999999, episode_sum_max_abs_reward_per_step 38.999999, mean_reward_over_100_episodes_from_training 02.40±02.26, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0018, mean_reward_over_100_episodes_from_eval 02.52±02.39
2025-12-29 03:50:02,506 | INFO | [trial_004 | seed 29] elapsed_time 00:39:41, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 37.479999, episode_sum_max_abs_reward_per_step 37.479999, mean_reward_over_100_episodes_from_training 02.52±02.34, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0018, mean_reward_over_100_episodes_from_eval 02.69±02.54
2025-12-29 03:51:13,442 | INFO | [trial_004 | seed 29] elapsed_time 00:40:52, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 02.71±02.53, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0018, mean_reward_over_100_episodes_from_eval 02.87±02.70
2025-12-29 03:52:24,802 | INFO | [trial_004 | seed 29] elapsed_time 00:42:03, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 02.89±02.70, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0018, mean_reward_over_100_episodes_from_eval 03.02±02.80
2025-12-29 03:53:35,887 | INFO | [trial_004 | seed 29] elapsed_time 00:43:14, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.359999, episode_sum_max_abs_reward_per_step 39.359999, mean_reward_over_100_episodes_from_training 03.08±02.91, mean_exploration_ratio_over_100_episodes_from_training 0.0260±0.0018, mean_reward_over_100_episodes_from_eval 03.19±02.95
2025-12-29 03:54:51,920 | INFO | [trial_004 | seed 29] elapsed_time 00:44:31, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 03.29±03.13, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0019, mean_reward_over_100_episodes_from_eval 03.38±03.12
2025-12-29 03:56:02,774 | INFO | [trial_004 | seed 29] elapsed_time 00:45:41, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 03.47±03.27, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0019, mean_reward_over_100_episodes_from_eval 03.58±03.31
2025-12-29 03:57:13,146 | INFO | [trial_004 | seed 29] elapsed_time 00:46:52, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 03.64±03.40, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0019, mean_reward_over_100_episodes_from_eval 03.76±03.45
2025-12-29 03:58:23,911 | INFO | [trial_004 | seed 29] elapsed_time 00:48:03, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 03.80±03.50, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0019, mean_reward_over_100_episodes_from_eval 03.93±03.57
2025-12-29 03:59:37,561 | INFO | [trial_004 | seed 29] elapsed_time 00:49:16, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 03.97±03.62, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0019, mean_reward_over_100_episodes_from_eval 04.12±03.72
2025-12-29 04:00:48,073 | INFO | [trial_004 | seed 29] elapsed_time 00:50:27, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.429999, episode_sum_max_abs_reward_per_step 39.429999, mean_reward_over_100_episodes_from_training 04.09±03.66, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0019, mean_reward_over_100_episodes_from_eval 04.29±03.83
2025-12-29 04:02:01,608 | INFO | [trial_004 | seed 29] elapsed_time 00:51:40, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 04.23±03.73, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0019, mean_reward_over_100_episodes_from_eval 04.46±03.94
2025-12-29 04:03:23,452 | INFO | [trial_004 | seed 29] elapsed_time 00:53:02, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 04.39±03.83, mean_exploration_ratio_over_100_episodes_from_training 0.0265±0.0019, mean_reward_over_100_episodes_from_eval 04.60±04.00
2025-12-29 04:04:44,838 | INFO | [trial_004 | seed 29] elapsed_time 00:54:23, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.209999, episode_sum_max_abs_reward_per_step 39.209999, mean_reward_over_100_episodes_from_training 04.48±03.84, mean_exploration_ratio_over_100_episodes_from_training 0.0265±0.0019, mean_reward_over_100_episodes_from_eval 04.75±04.08
2025-12-29 04:05:53,067 | INFO | [trial_004 | seed 29] elapsed_time 00:55:32, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 04.61±03.89, mean_exploration_ratio_over_100_episodes_from_training 0.0266±0.0019, mean_reward_over_100_episodes_from_eval 04.86±04.11
2025-12-29 04:06:45,026 | INFO | [trial_004 | seed 29] elapsed_time 00:56:24, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 04.78±04.02, mean_exploration_ratio_over_100_episodes_from_training 0.0266±0.0019, mean_reward_over_100_episodes_from_eval 05.01±04.18
2025-12-29 04:07:37,812 | INFO | [trial_004 | seed 29] elapsed_time 00:57:16, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 04.90±04.07, mean_exploration_ratio_over_100_episodes_from_training 0.0267±0.0019, mean_reward_over_100_episodes_from_eval 05.14±04.24
2025-12-29 04:08:30,282 | INFO | [trial_004 | seed 29] elapsed_time 00:58:09, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.429999, episode_sum_max_abs_reward_per_step 39.429999, mean_reward_over_100_episodes_from_training 05.00±04.08, mean_exploration_ratio_over_100_episodes_from_training 0.0267±0.0019, mean_reward_over_100_episodes_from_eval 05.21±04.23
2025-12-29 04:09:22,691 | INFO | [trial_004 | seed 29] elapsed_time 00:59:01, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.429999, episode_sum_max_abs_reward_per_step 39.429999, mean_reward_over_100_episodes_from_training 05.12±04.12, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0019, mean_reward_over_100_episodes_from_eval 05.33±04.26
2025-12-29 04:10:15,374 | INFO | [trial_004 | seed 29] elapsed_time 00:59:54, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.149999, episode_sum_max_abs_reward_per_step 39.149999, mean_reward_over_100_episodes_from_training 05.22±04.15, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0019, mean_reward_over_100_episodes_from_eval 05.41±04.26
2025-12-29 04:11:08,091 | INFO | [trial_004 | seed 29] elapsed_time 01:00:47, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 05.32±04.17, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0019, mean_reward_over_100_episodes_from_eval 05.50±04.27
2025-12-29 04:12:00,544 | INFO | [trial_004 | seed 29] elapsed_time 01:01:39, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.389999, episode_sum_max_abs_reward_per_step 39.389999, mean_reward_over_100_episodes_from_training 05.41±04.17, mean_exploration_ratio_over_100_episodes_from_training 0.0269±0.0019, mean_reward_over_100_episodes_from_eval 05.55±04.24
2025-12-29 04:12:53,022 | INFO | [trial_004 | seed 29] elapsed_time 01:02:32, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 05.47±04.16, mean_exploration_ratio_over_100_episodes_from_training 0.0269±0.0019, mean_reward_over_100_episodes_from_eval 05.66±04.28
2025-12-29 04:13:52,392 | INFO | [trial_004 | seed 29] elapsed_time 01:03:31, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 05.60±04.23, mean_exploration_ratio_over_100_episodes_from_training 0.0270±0.0020, mean_reward_over_100_episodes_from_eval 05.77±04.32
2025-12-29 04:14:45,367 | INFO | [trial_004 | seed 29] elapsed_time 01:04:24, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 05.71±04.27, mean_exploration_ratio_over_100_episodes_from_training 0.0270±0.0020, mean_reward_over_100_episodes_from_eval 05.84±04.31
2025-12-29 04:15:38,705 | INFO | [trial_004 | seed 29] elapsed_time 01:05:17, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 05.83±04.32, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0020, mean_reward_over_100_episodes_from_eval 05.96±04.36
2025-12-29 04:16:30,774 | INFO | [trial_004 | seed 29] elapsed_time 01:06:09, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 05.92±04.34, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0021, mean_reward_over_100_episodes_from_eval 06.01±04.34
2025-12-29 04:17:23,961 | INFO | [trial_004 | seed 29] elapsed_time 01:07:03, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.419999, episode_sum_max_abs_reward_per_step 39.419999, mean_reward_over_100_episodes_from_training 06.00±04.35, mean_exploration_ratio_over_100_episodes_from_training 0.0271±0.0020, mean_reward_over_100_episodes_from_eval 06.10±04.36
2025-12-29 04:18:15,677 | INFO | [trial_004 | seed 29] elapsed_time 01:07:54, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 06.14±04.44, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0021, mean_reward_over_100_episodes_from_eval 06.20±04.38
2025-12-29 04:19:08,308 | INFO | [trial_004 | seed 29] elapsed_time 01:08:47, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 06.22±04.45, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0021, mean_reward_over_100_episodes_from_eval 06.29±04.40
2025-12-29 04:20:01,377 | INFO | [trial_004 | seed 29] elapsed_time 01:09:40, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 06.32±04.48, mean_exploration_ratio_over_100_episodes_from_training 0.0272±0.0021, mean_reward_over_100_episodes_from_eval 06.36±04.40
2025-12-29 04:20:54,361 | INFO | [trial_004 | seed 29] elapsed_time 01:10:33, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 06.42±04.52, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0021, mean_reward_over_100_episodes_from_eval 06.46±04.44
2025-12-29 04:21:46,260 | INFO | [trial_004 | seed 29] elapsed_time 01:11:25, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 06.49±04.51, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0021, mean_reward_over_100_episodes_from_eval 06.55±04.46
2025-12-29 04:22:38,669 | INFO | [trial_004 | seed 29] elapsed_time 01:12:17, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 06.58±04.53, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0020, mean_reward_over_100_episodes_from_eval 06.64±04.48
2025-12-29 04:23:31,150 | INFO | [trial_004 | seed 29] elapsed_time 01:13:10, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 06.64±04.52, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0021, mean_reward_over_100_episodes_from_eval 06.70±04.48
2025-12-29 04:24:23,769 | INFO | [trial_004 | seed 29] elapsed_time 01:14:02, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 06.73±04.55, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0021, mean_reward_over_100_episodes_from_eval 06.76±04.46
2025-12-29 04:25:18,354 | INFO | [trial_004 | seed 29] elapsed_time 01:14:57, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 06.80±04.55, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0020, mean_reward_over_100_episodes_from_eval 06.80±04.45
2025-12-29 04:26:11,005 | INFO | [trial_004 | seed 29] elapsed_time 01:15:50, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 06.88±04.57, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0020, mean_reward_over_100_episodes_from_eval 06.85±04.43
2025-12-29 04:27:03,229 | INFO | [trial_004 | seed 29] elapsed_time 01:16:42, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 06.95±04.57, mean_exploration_ratio_over_100_episodes_from_training 0.0274±0.0020, mean_reward_over_100_episodes_from_eval 06.95±04.47
2025-12-29 04:27:55,656 | INFO | [trial_004 | seed 29] elapsed_time 01:17:34, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 07.02±04.58, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0020, mean_reward_over_100_episodes_from_eval 07.03±04.50
2025-12-29 04:28:47,704 | INFO | [trial_004 | seed 29] elapsed_time 01:18:26, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 07.09±04.59, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0020, mean_reward_over_100_episodes_from_eval 07.09±04.50
2025-12-29 04:29:40,995 | INFO | [trial_004 | seed 29] elapsed_time 01:19:20, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 07.16±04.59, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0020, mean_reward_over_100_episodes_from_eval 07.16±04.50
2025-12-29 04:30:33,582 | INFO | [trial_004 | seed 29] elapsed_time 01:20:12, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 07.20±04.57, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0020, mean_reward_over_100_episodes_from_eval 07.23±04.51
2025-12-29 04:31:25,909 | INFO | [trial_004 | seed 29] elapsed_time 01:21:05, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 07.26±04.57, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0020, mean_reward_over_100_episodes_from_eval 07.26±04.48
2025-12-29 04:32:16,999 | INFO | [trial_004 | seed 29] elapsed_time 01:21:56, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 07.33±04.58, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0020, mean_reward_over_100_episodes_from_eval 07.31±04.48
2025-12-29 04:33:09,105 | INFO | [trial_004 | seed 29] elapsed_time 01:22:48, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 07.42±04.63, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0020, mean_reward_over_100_episodes_from_eval 07.36±04.47
2025-12-29 04:34:01,839 | INFO | [trial_004 | seed 29] elapsed_time 01:23:40, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 07.49±04.63, mean_exploration_ratio_over_100_episodes_from_training 0.0276±0.0020, mean_reward_over_100_episodes_from_eval 07.38±04.45
2025-12-29 04:34:54,106 | INFO | [trial_004 | seed 29] elapsed_time 01:24:33, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 07.55±04.63, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0020, mean_reward_over_100_episodes_from_eval 07.42±04.43
2025-12-29 04:35:45,957 | INFO | [trial_004 | seed 29] elapsed_time 01:25:25, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 07.58±04.61, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0020, mean_reward_over_100_episodes_from_eval 07.48±04.44
2025-12-29 04:36:38,252 | INFO | [trial_004 | seed 29] elapsed_time 01:26:17, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 07.61±04.59, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0021, mean_reward_over_100_episodes_from_eval 07.52±04.42
2025-12-29 04:37:31,295 | INFO | [trial_004 | seed 29] elapsed_time 01:27:10, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 07.68±04.60, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0020, mean_reward_over_100_episodes_from_eval 07.54±04.40
2025-12-29 04:38:23,617 | INFO | [trial_004 | seed 29] elapsed_time 01:28:02, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.269999, episode_sum_max_abs_reward_per_step 39.269999, mean_reward_over_100_episodes_from_training 07.71±04.58, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0020, mean_reward_over_100_episodes_from_eval 07.58±04.39
2025-12-29 04:39:15,012 | INFO | [trial_004 | seed 29] elapsed_time 01:28:54, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 07.76±04.58, mean_exploration_ratio_over_100_episodes_from_training 0.0278±0.0020, mean_reward_over_100_episodes_from_eval 07.63±04.39
2025-12-29 04:40:07,730 | INFO | [trial_004 | seed 29] elapsed_time 01:29:46, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 07.82±04.59, mean_exploration_ratio_over_100_episodes_from_training 0.0278±0.0020, mean_reward_over_100_episodes_from_eval 07.69±04.40
2025-12-29 04:41:00,593 | INFO | [trial_004 | seed 29] elapsed_time 01:30:39, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 07.90±04.62, mean_exploration_ratio_over_100_episodes_from_training 0.0278±0.0020, mean_reward_over_100_episodes_from_eval 07.74±04.39
2025-12-29 04:41:53,356 | INFO | [trial_004 | seed 29] elapsed_time 01:31:32, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 07.94±04.60, mean_exploration_ratio_over_100_episodes_from_training 0.0278±0.0020, mean_reward_over_100_episodes_from_eval 07.78±04.38
2025-12-29 04:42:44,970 | INFO | [trial_004 | seed 29] elapsed_time 01:32:24, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 08.00±04.61, mean_exploration_ratio_over_100_episodes_from_training 0.0279±0.0020, mean_reward_over_100_episodes_from_eval 07.83±04.39
2025-12-29 04:43:37,668 | INFO | [trial_004 | seed 29] elapsed_time 01:33:16, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 08.04±04.60, mean_exploration_ratio_over_100_episodes_from_training 0.0279±0.0021, mean_reward_over_100_episodes_from_eval 07.90±04.40
2025-12-29 04:44:31,436 | INFO | [trial_004 | seed 29] elapsed_time 01:34:10, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 08.11±04.63, mean_exploration_ratio_over_100_episodes_from_training 0.0279±0.0021, mean_reward_over_100_episodes_from_eval 08.00±04.49
2025-12-29 04:45:23,869 | INFO | [trial_004 | seed 29] elapsed_time 01:35:02, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 08.19±04.66, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0021, mean_reward_over_100_episodes_from_eval 08.06±04.50
2025-12-29 04:46:15,623 | INFO | [trial_004 | seed 29] elapsed_time 01:35:54, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 08.27±04.71, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0021, mean_reward_over_100_episodes_from_eval 08.16±04.56
2025-12-29 04:47:07,908 | INFO | [trial_004 | seed 29] elapsed_time 01:36:47, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 08.35±04.75, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0021, mean_reward_over_100_episodes_from_eval 08.25±04.63
2025-12-29 04:48:00,286 | INFO | [trial_004 | seed 29] elapsed_time 01:37:39, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 08.46±04.83, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0021, mean_reward_over_100_episodes_from_eval 08.32±04.66
2025-12-29 04:48:52,724 | INFO | [trial_004 | seed 29] elapsed_time 01:38:31, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 08.51±04.83, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0022, mean_reward_over_100_episodes_from_eval 08.39±04.67
2025-12-29 04:49:44,677 | INFO | [trial_004 | seed 29] elapsed_time 01:39:23, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 08.58±04.86, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0022, mean_reward_over_100_episodes_from_eval 08.44±04.68
2025-12-29 04:50:37,217 | INFO | [trial_004 | seed 29] elapsed_time 01:40:16, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 08.64±04.86, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0021, mean_reward_over_100_episodes_from_eval 08.49±04.68
2025-12-29 04:51:30,004 | INFO | [trial_004 | seed 29] elapsed_time 01:41:09, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 08.71±04.88, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0022, mean_reward_over_100_episodes_from_eval 08.58±04.74
2025-12-29 04:52:22,409 | INFO | [trial_004 | seed 29] elapsed_time 01:42:01, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 08.78±04.91, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0022, mean_reward_over_100_episodes_from_eval 08.67±04.79
2025-12-29 04:53:15,343 | INFO | [trial_004 | seed 29] elapsed_time 01:42:54, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 08.84±04.92, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0022, mean_reward_over_100_episodes_from_eval 08.74±04.82
2025-12-29 04:54:08,094 | INFO | [trial_004 | seed 29] elapsed_time 01:43:47, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 09.02±04.96, mean_exploration_ratio_over_100_episodes_from_training 0.0283±0.0022, mean_reward_over_100_episodes_from_eval 08.90±04.82
2025-12-29 04:55:01,198 | INFO | [trial_004 | seed 29] elapsed_time 01:44:40, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 09.17±04.93, mean_exploration_ratio_over_100_episodes_from_training 0.0283±0.0023, mean_reward_over_100_episodes_from_eval 09.06±04.83
2025-12-29 04:55:53,788 | INFO | [trial_004 | seed 29] elapsed_time 01:45:32, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 09.32±04.90, mean_exploration_ratio_over_100_episodes_from_training 0.0284±0.0024, mean_reward_over_100_episodes_from_eval 09.22±04.81
2025-12-29 04:56:45,764 | INFO | [trial_004 | seed 29] elapsed_time 01:46:24, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 09.50±04.90, mean_exploration_ratio_over_100_episodes_from_training 0.0284±0.0024, mean_reward_over_100_episodes_from_eval 09.39±04.81
2025-12-29 04:57:37,851 | INFO | [trial_004 | seed 29] elapsed_time 01:47:16, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 09.64±04.86, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0024, mean_reward_over_100_episodes_from_eval 09.56±04.82
2025-12-29 04:58:30,574 | INFO | [trial_004 | seed 29] elapsed_time 01:48:09, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 09.79±04.82, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0024, mean_reward_over_100_episodes_from_eval 09.72±04.79
2025-12-29 04:59:23,471 | INFO | [trial_004 | seed 29] elapsed_time 01:49:02, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 10.01±04.92, mean_exploration_ratio_over_100_episodes_from_training 0.0286±0.0024, mean_reward_over_100_episodes_from_eval 09.87±04.75
2025-12-29 05:00:15,851 | INFO | [trial_004 | seed 29] elapsed_time 01:49:54, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 10.22±04.99, mean_exploration_ratio_over_100_episodes_from_training 0.0286±0.0024, mean_reward_over_100_episodes_from_eval 10.07±04.80
2025-12-29 05:01:08,184 | INFO | [trial_004 | seed 29] elapsed_time 01:50:47, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 10.41±04.99, mean_exploration_ratio_over_100_episodes_from_training 0.0287±0.0025, mean_reward_over_100_episodes_from_eval 10.25±04.82
2025-12-29 05:02:00,714 | INFO | [trial_004 | seed 29] elapsed_time 01:51:39, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 10.61±05.03, mean_exploration_ratio_over_100_episodes_from_training 0.0287±0.0025, mean_reward_over_100_episodes_from_eval 10.47±04.91
2025-12-29 05:02:53,064 | INFO | [trial_004 | seed 29] elapsed_time 01:52:32, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 10.82±05.06, mean_exploration_ratio_over_100_episodes_from_training 0.0288±0.0025, mean_reward_over_100_episodes_from_eval 10.70±04.98
2025-12-29 05:03:44,724 | INFO | [trial_004 | seed 29] elapsed_time 01:53:23, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 11.05±05.10, mean_exploration_ratio_over_100_episodes_from_training 0.0290±0.0025, mean_reward_over_100_episodes_from_eval 10.94±05.03
2025-12-29 05:04:37,155 | INFO | [trial_004 | seed 29] elapsed_time 01:54:16, episode 0112, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 11.29±05.14, mean_exploration_ratio_over_100_episodes_from_training 0.0291±0.0025, mean_reward_over_100_episodes_from_eval 11.17±05.08
2025-12-29 05:05:30,198 | INFO | [trial_004 | seed 29] elapsed_time 01:55:09, episode 0113, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 11.54±05.30, mean_exploration_ratio_over_100_episodes_from_training 0.0292±0.0025, mean_reward_over_100_episodes_from_eval 11.45±05.36
2025-12-29 05:06:22,785 | INFO | [trial_004 | seed 29] elapsed_time 01:56:01, episode 0114, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 11.80±05.47, mean_exploration_ratio_over_100_episodes_from_training 0.0293±0.0026, mean_reward_over_100_episodes_from_eval 11.72±05.53
2025-12-29 05:07:14,615 | INFO | [trial_004 | seed 29] elapsed_time 01:56:53, episode 0115, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 12.07±05.64, mean_exploration_ratio_over_100_episodes_from_training 0.0294±0.0026, mean_reward_over_100_episodes_from_eval 11.99±05.70
2025-12-29 05:08:06,663 | INFO | [trial_004 | seed 29] elapsed_time 01:57:45, episode 0116, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 12.37±05.80, mean_exploration_ratio_over_100_episodes_from_training 0.0295±0.0026, mean_reward_over_100_episodes_from_eval 12.28±05.84
2025-12-29 05:08:59,064 | INFO | [trial_004 | seed 29] elapsed_time 01:58:38, episode 0117, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 12.64±05.89, mean_exploration_ratio_over_100_episodes_from_training 0.0296±0.0026, mean_reward_over_100_episodes_from_eval 12.56±05.95
2025-12-29 05:09:54,705 | INFO | [trial_004 | seed 29] elapsed_time 01:59:33, episode 0118, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 12.86±05.88, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0026, mean_reward_over_100_episodes_from_eval 12.84±06.06
2025-12-29 05:10:47,002 | INFO | [trial_004 | seed 29] elapsed_time 02:00:26, episode 0119, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 13.16±06.03, mean_exploration_ratio_over_100_episodes_from_training 0.0298±0.0026, mean_reward_over_100_episodes_from_eval 13.13±06.18
2025-12-29 05:11:39,626 | INFO | [trial_004 | seed 29] elapsed_time 02:01:18, episode 0120, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 13.45±06.17, mean_exploration_ratio_over_100_episodes_from_training 0.0299±0.0026, mean_reward_over_100_episodes_from_eval 13.44±06.36
2025-12-29 05:12:32,235 | INFO | [trial_004 | seed 29] elapsed_time 02:02:11, episode 0121, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 13.74±06.30, mean_exploration_ratio_over_100_episodes_from_training 0.0300±0.0027, mean_reward_over_100_episodes_from_eval 13.71±06.47
2025-12-29 05:13:28,856 | INFO | [trial_004 | seed 29] elapsed_time 02:03:07, episode 0122, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 14.03±06.44, mean_exploration_ratio_over_100_episodes_from_training 0.0301±0.0027, mean_reward_over_100_episodes_from_eval 14.01±06.64
2025-12-29 05:14:32,837 | INFO | [trial_004 | seed 29] elapsed_time 02:04:11, episode 0123, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 14.34±06.65, mean_exploration_ratio_over_100_episodes_from_training 0.0302±0.0027, mean_reward_over_100_episodes_from_eval 14.31±06.80
2025-12-29 05:15:28,756 | INFO | [trial_004 | seed 29] elapsed_time 02:05:07, episode 0124, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 14.62±06.78, mean_exploration_ratio_over_100_episodes_from_training 0.0303±0.0027, mean_reward_over_100_episodes_from_eval 14.57±06.91
2025-12-29 05:16:23,814 | INFO | [trial_004 | seed 29] elapsed_time 02:06:02, episode 0125, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 14.91±06.90, mean_exploration_ratio_over_100_episodes_from_training 0.0304±0.0027, mean_reward_over_100_episodes_from_eval 14.85±07.04
2025-12-29 05:17:18,190 | INFO | [trial_004 | seed 29] elapsed_time 02:06:57, episode 0126, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 15.18±07.02, mean_exploration_ratio_over_100_episodes_from_training 0.0305±0.0027, mean_reward_over_100_episodes_from_eval 15.09±07.12
2025-12-29 05:18:13,090 | INFO | [trial_004 | seed 29] elapsed_time 02:07:52, episode 0127, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 15.42±07.10, mean_exploration_ratio_over_100_episodes_from_training 0.0306±0.0027, mean_reward_over_100_episodes_from_eval 15.27±07.11
2025-12-29 05:19:08,182 | INFO | [trial_004 | seed 29] elapsed_time 02:08:47, episode 0128, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 15.64±07.15, mean_exploration_ratio_over_100_episodes_from_training 0.0307±0.0027, mean_reward_over_100_episodes_from_eval 15.48±07.19
2025-12-29 05:20:04,142 | INFO | [trial_004 | seed 29] elapsed_time 02:09:43, episode 0129, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 15.85±07.25, mean_exploration_ratio_over_100_episodes_from_training 0.0308±0.0028, mean_reward_over_100_episodes_from_eval 15.67±07.24
2025-12-29 05:21:00,862 | INFO | [trial_004 | seed 29] elapsed_time 02:10:39, episode 0130, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 16.06±07.30, mean_exploration_ratio_over_100_episodes_from_training 0.0309±0.0028, mean_reward_over_100_episodes_from_eval 15.88±07.31
2025-12-29 05:21:56,352 | INFO | [trial_004 | seed 29] elapsed_time 02:11:35, episode 0131, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 16.28±07.37, mean_exploration_ratio_over_100_episodes_from_training 0.0310±0.0030, mean_reward_over_100_episodes_from_eval 16.11±07.41
2025-12-29 05:22:51,653 | INFO | [trial_004 | seed 29] elapsed_time 02:12:30, episode 0132, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 16.52±07.44, mean_exploration_ratio_over_100_episodes_from_training 0.0311±0.0030, mean_reward_over_100_episodes_from_eval 16.34±07.52
2025-12-29 05:23:46,823 | INFO | [trial_004 | seed 29] elapsed_time 02:13:25, episode 0133, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 16.76±07.58, mean_exploration_ratio_over_100_episodes_from_training 0.0312±0.0030, mean_reward_over_100_episodes_from_eval 16.59±07.67
2025-12-29 05:24:42,665 | INFO | [trial_004 | seed 29] elapsed_time 02:14:21, episode 0134, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 17.01±07.72, mean_exploration_ratio_over_100_episodes_from_training 0.0313±0.0031, mean_reward_over_100_episodes_from_eval 16.85±07.81
2025-12-29 05:25:39,209 | INFO | [trial_004 | seed 29] elapsed_time 02:15:18, episode 0135, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 17.23±07.83, mean_exploration_ratio_over_100_episodes_from_training 0.0314±0.0031, mean_reward_over_100_episodes_from_eval 17.08±07.93
2025-12-29 05:26:34,536 | INFO | [trial_004 | seed 29] elapsed_time 02:16:13, episode 0136, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 17.46±07.97, mean_exploration_ratio_over_100_episodes_from_training 0.0315±0.0031, mean_reward_over_100_episodes_from_eval 17.33±08.10
2025-12-29 05:27:30,592 | INFO | [trial_004 | seed 29] elapsed_time 02:17:09, episode 0137, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 17.71±08.13, mean_exploration_ratio_over_100_episodes_from_training 0.0316±0.0032, mean_reward_over_100_episodes_from_eval 17.59±08.30
2025-12-29 05:28:26,506 | INFO | [trial_004 | seed 29] elapsed_time 02:18:05, episode 0138, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 17.96±08.29, mean_exploration_ratio_over_100_episodes_from_training 0.0317±0.0032, mean_reward_over_100_episodes_from_eval 17.85±08.49
2025-12-29 05:29:22,731 | INFO | [trial_004 | seed 29] elapsed_time 02:19:01, episode 0139, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 18.23±08.45, mean_exploration_ratio_over_100_episodes_from_training 0.0318±0.0032, mean_reward_over_100_episodes_from_eval 18.12±08.68
2025-12-29 05:30:19,217 | INFO | [trial_004 | seed 29] elapsed_time 02:19:58, episode 0140, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 18.48±08.60, mean_exploration_ratio_over_100_episodes_from_training 0.0319±0.0033, mean_reward_over_100_episodes_from_eval 18.36±08.82
2025-12-29 05:31:14,506 | INFO | [trial_004 | seed 29] elapsed_time 02:20:53, episode 0141, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 18.72±08.67, mean_exploration_ratio_over_100_episodes_from_training 0.0320±0.0033, mean_reward_over_100_episodes_from_eval 18.58±08.91
2025-12-29 05:32:09,530 | INFO | [trial_004 | seed 29] elapsed_time 02:21:48, episode 0142, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 18.95±08.75, mean_exploration_ratio_over_100_episodes_from_training 0.0321±0.0033, mean_reward_over_100_episodes_from_eval 18.80±09.01
2025-12-29 05:33:04,761 | INFO | [trial_004 | seed 29] elapsed_time 02:22:43, episode 0143, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 19.16±08.81, mean_exploration_ratio_over_100_episodes_from_training 0.0322±0.0033, mean_reward_over_100_episodes_from_eval 19.01±09.07
2025-12-29 05:34:00,835 | INFO | [trial_004 | seed 29] elapsed_time 02:23:39, episode 0144, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 19.37±08.81, mean_exploration_ratio_over_100_episodes_from_training 0.0323±0.0034, mean_reward_over_100_episodes_from_eval 19.23±09.14
2025-12-29 05:34:56,782 | INFO | [trial_004 | seed 29] elapsed_time 02:24:35, episode 0145, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 19.62±08.90, mean_exploration_ratio_over_100_episodes_from_training 0.0323±0.0034, mean_reward_over_100_episodes_from_eval 19.48±09.23
2025-12-29 05:35:52,730 | INFO | [trial_004 | seed 29] elapsed_time 02:25:31, episode 0146, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 19.84±08.99, mean_exploration_ratio_over_100_episodes_from_training 0.0324±0.0034, mean_reward_over_100_episodes_from_eval 19.71±09.31
2025-12-29 05:36:47,905 | INFO | [trial_004 | seed 29] elapsed_time 02:26:27, episode 0147, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 20.04±09.01, mean_exploration_ratio_over_100_episodes_from_training 0.0325±0.0034, mean_reward_over_100_episodes_from_eval 19.88±09.31
2025-12-29 05:37:43,542 | INFO | [trial_004 | seed 29] elapsed_time 02:27:22, episode 0148, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 20.26±09.02, mean_exploration_ratio_over_100_episodes_from_training 0.0326±0.0035, mean_reward_over_100_episodes_from_eval 20.12±09.33
2025-12-29 05:38:38,898 | INFO | [trial_004 | seed 29] elapsed_time 02:28:18, episode 0149, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 20.48±09.06, mean_exploration_ratio_over_100_episodes_from_training 0.0327±0.0035, mean_reward_over_100_episodes_from_eval 20.33±09.36
2025-12-29 05:39:35,746 | INFO | [trial_004 | seed 29] elapsed_time 02:29:14, episode 0150, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 20.72±09.11, mean_exploration_ratio_over_100_episodes_from_training 0.0328±0.0035, mean_reward_over_100_episodes_from_eval 20.57±09.40
2025-12-29 05:40:31,492 | INFO | [trial_004 | seed 29] elapsed_time 02:30:10, episode 0151, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 20.97±09.16, mean_exploration_ratio_over_100_episodes_from_training 0.0329±0.0035, mean_reward_over_100_episodes_from_eval 20.81±09.43
2025-12-29 05:41:27,415 | INFO | [trial_004 | seed 29] elapsed_time 02:31:06, episode 0152, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 21.20±09.17, mean_exploration_ratio_over_100_episodes_from_training 0.0330±0.0035, mean_reward_over_100_episodes_from_eval 21.07±09.43
2025-12-29 05:42:23,048 | INFO | [trial_004 | seed 29] elapsed_time 02:32:02, episode 0153, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 21.47±09.20, mean_exploration_ratio_over_100_episodes_from_training 0.0331±0.0036, mean_reward_over_100_episodes_from_eval 21.29±09.47
2025-12-29 05:43:17,752 | INFO | [trial_004 | seed 29] elapsed_time 02:32:56, episode 0154, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 21.70±09.26, mean_exploration_ratio_over_100_episodes_from_training 0.0332±0.0036, mean_reward_over_100_episodes_from_eval 21.54±09.53
2025-12-29 05:44:13,748 | INFO | [trial_004 | seed 29] elapsed_time 02:33:52, episode 0155, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 21.93±09.31, mean_exploration_ratio_over_100_episodes_from_training 0.0333±0.0036, mean_reward_over_100_episodes_from_eval 21.79±09.55
2025-12-29 05:45:10,416 | INFO | [trial_004 | seed 29] elapsed_time 02:34:49, episode 0156, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 22.17±09.35, mean_exploration_ratio_over_100_episodes_from_training 0.0333±0.0036, mean_reward_over_100_episodes_from_eval 21.97±09.54
2025-12-29 05:46:06,218 | INFO | [trial_004 | seed 29] elapsed_time 02:35:45, episode 0157, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 22.40±09.37, mean_exploration_ratio_over_100_episodes_from_training 0.0334±0.0037, mean_reward_over_100_episodes_from_eval 22.24±09.56
2025-12-29 05:47:02,567 | INFO | [trial_004 | seed 29] elapsed_time 02:36:41, episode 0158, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 22.65±09.38, mean_exploration_ratio_over_100_episodes_from_training 0.0335±0.0037, mean_reward_over_100_episodes_from_eval 22.48±09.59
2025-12-29 05:47:58,982 | INFO | [trial_004 | seed 29] elapsed_time 02:37:38, episode 0159, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 22.83±09.40, mean_exploration_ratio_over_100_episodes_from_training 0.0336±0.0037, mean_reward_over_100_episodes_from_eval 22.71±09.60
2025-12-29 05:48:55,399 | INFO | [trial_004 | seed 29] elapsed_time 02:38:34, episode 0160, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 23.02±09.35, mean_exploration_ratio_over_100_episodes_from_training 0.0337±0.0037, mean_reward_over_100_episodes_from_eval 22.91±09.58
2025-12-29 05:49:51,336 | INFO | [trial_004 | seed 29] elapsed_time 02:39:30, episode 0161, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.25±09.36, mean_exploration_ratio_over_100_episodes_from_training 0.0338±0.0037, mean_reward_over_100_episodes_from_eval 23.16±09.59
2025-12-29 05:50:46,543 | INFO | [trial_004 | seed 29] elapsed_time 02:40:25, episode 0162, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 23.47±09.38, mean_exploration_ratio_over_100_episodes_from_training 0.0339±0.0036, mean_reward_over_100_episodes_from_eval 23.37±09.59
2025-12-29 05:51:42,377 | INFO | [trial_004 | seed 29] elapsed_time 02:41:21, episode 0163, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 23.70±09.35, mean_exploration_ratio_over_100_episodes_from_training 0.0340±0.0036, mean_reward_over_100_episodes_from_eval 23.56±09.55
2025-12-29 05:52:38,190 | INFO | [trial_004 | seed 29] elapsed_time 02:42:17, episode 0164, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 23.91±09.31, mean_exploration_ratio_over_100_episodes_from_training 0.0341±0.0036, mean_reward_over_100_episodes_from_eval 23.76±09.52
2025-12-29 05:53:34,879 | INFO | [trial_004 | seed 29] elapsed_time 02:43:13, episode 0165, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 24.15±09.28, mean_exploration_ratio_over_100_episodes_from_training 0.0341±0.0036, mean_reward_over_100_episodes_from_eval 24.02±09.51
2025-12-29 05:54:30,452 | INFO | [trial_004 | seed 29] elapsed_time 02:44:09, episode 0166, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 24.37±09.26, mean_exploration_ratio_over_100_episodes_from_training 0.0342±0.0036, mean_reward_over_100_episodes_from_eval 24.21±09.43
2025-12-29 05:55:26,406 | INFO | [trial_004 | seed 29] elapsed_time 02:45:05, episode 0167, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 24.57±09.20, mean_exploration_ratio_over_100_episodes_from_training 0.0343±0.0036, mean_reward_over_100_episodes_from_eval 24.45±09.36
2025-12-29 05:56:22,112 | INFO | [trial_004 | seed 29] elapsed_time 02:46:01, episode 0168, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 24.77±09.16, mean_exploration_ratio_over_100_episodes_from_training 0.0344±0.0036, mean_reward_over_100_episodes_from_eval 24.71±09.33
2025-12-29 05:57:17,027 | INFO | [trial_004 | seed 29] elapsed_time 02:46:56, episode 0169, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.01±09.13, mean_exploration_ratio_over_100_episodes_from_training 0.0345±0.0035, mean_reward_over_100_episodes_from_eval 24.93±09.32
2025-12-29 05:58:12,434 | INFO | [trial_004 | seed 29] elapsed_time 02:47:51, episode 0170, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 25.24±09.08, mean_exploration_ratio_over_100_episodes_from_training 0.0346±0.0035, mean_reward_over_100_episodes_from_eval 25.15±09.29
2025-12-29 05:59:08,136 | INFO | [trial_004 | seed 29] elapsed_time 02:48:47, episode 0171, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 25.47±09.04, mean_exploration_ratio_over_100_episodes_from_training 0.0347±0.0035, mean_reward_over_100_episodes_from_eval 25.36±09.22
2025-12-29 06:00:05,504 | INFO | [trial_004 | seed 29] elapsed_time 02:49:44, episode 0172, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.65±08.95, mean_exploration_ratio_over_100_episodes_from_training 0.0348±0.0035, mean_reward_over_100_episodes_from_eval 25.52±09.13
2025-12-29 06:01:01,942 | INFO | [trial_004 | seed 29] elapsed_time 02:50:41, episode 0173, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.89±08.85, mean_exploration_ratio_over_100_episodes_from_training 0.0349±0.0034, mean_reward_over_100_episodes_from_eval 25.75±09.08
2025-12-29 06:01:57,461 | INFO | [trial_004 | seed 29] elapsed_time 02:51:36, episode 0174, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 26.12±08.77, mean_exploration_ratio_over_100_episodes_from_training 0.0350±0.0034, mean_reward_over_100_episodes_from_eval 25.94±08.93
2025-12-29 06:02:53,521 | INFO | [trial_004 | seed 29] elapsed_time 02:52:32, episode 0175, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.34±08.71, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0033, mean_reward_over_100_episodes_from_eval 26.20±08.88
2025-12-29 06:03:48,603 | INFO | [trial_004 | seed 29] elapsed_time 02:53:27, episode 0176, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.57±08.70, mean_exploration_ratio_over_100_episodes_from_training 0.0352±0.0033, mean_reward_over_100_episodes_from_eval 26.46±08.81
2025-12-29 06:04:44,276 | INFO | [trial_004 | seed 29] elapsed_time 02:54:23, episode 0177, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 26.79±08.61, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0033, mean_reward_over_100_episodes_from_eval 26.73±08.69
2025-12-29 06:06:17,132 | INFO | [trial_004 | seed 29] elapsed_time 02:55:56, episode 0178, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 27.00±08.51, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0033, mean_reward_over_100_episodes_from_eval 26.98±08.57
2025-12-29 06:07:29,578 | INFO | [trial_004 | seed 29] elapsed_time 02:57:08, episode 0179, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.24±08.37, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0032, mean_reward_over_100_episodes_from_eval 27.20±08.47
2025-12-29 06:08:34,214 | INFO | [trial_004 | seed 29] elapsed_time 02:58:13, episode 0180, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 27.49±08.22, mean_exploration_ratio_over_100_episodes_from_training 0.0355±0.0032, mean_reward_over_100_episodes_from_eval 27.42±08.32
2025-12-29 06:09:38,001 | INFO | [trial_004 | seed 29] elapsed_time 02:59:17, episode 0181, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.70±08.12, mean_exploration_ratio_over_100_episodes_from_training 0.0356±0.0032, mean_reward_over_100_episodes_from_eval 27.67±08.15
2025-12-29 06:10:38,967 | INFO | [trial_004 | seed 29] elapsed_time 03:00:18, episode 0182, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.95±07.97, mean_exploration_ratio_over_100_episodes_from_training 0.0357±0.0031, mean_reward_over_100_episodes_from_eval 27.91±08.00
2025-12-29 06:10:38,967 | INFO | [trial_004 | seed 29] --> reached_max_minutes x
2025-12-29 06:40:37,100 | INFO | [trial_004 | seed 29] Training complete.
2025-12-29 06:40:37,102 | INFO | [trial_004 | seed 29] Solved (evaluation metric) episode not reached within the run.
2025-12-29 06:40:37,103 | INFO | [trial_004 | seed 29] Final evaluation score 35.30±0.92 in 7215.53s training, 12616.21s wall.
2025-12-29 06:40:37,103 | INFO | [trial_004 | seed 29] Closing UnityVectorEnv (worker_id=4029).
2025-12-29 06:40:37,103 | INFO | [Main] Requesting worker 4029 to close Unity env.
2025-12-29 06:40:38,948 | INFO | [Main] Worker 4029 joined. Unity env fully closed.
2025-12-29 06:40:38,949 | INFO | [trial_004 | seed 29] Final eval score: 35.30
2025-12-29 06:40:39,435 | INFO | [trial_004 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_004_seed_29.png
2025-12-29 06:40:39,436 | INFO | [trial_004 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 06:40:39,874 | INFO | [trial_004] Final scores across seeds: [35.302]
2025-12-29 06:40:39,875 | INFO | [trial_004] Avg=35.302 ± 0.000, Best seed score=35.302
2025-12-29 06:40:39,878 | INFO | [trial_005] Starting trial with hparams: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[64,64],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.005}
2025-12-29 06:40:39,881 | INFO | [trial_005 | seed 29] Start training with hparams: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[64,64],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.005}
2025-12-29 06:40:39,883 | INFO | [trial_005 | seed 29] === Starting run for seed 29 ===
2025-12-29 06:40:39,884 | INFO | [trial_005 | seed 29] Hyperparameters: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.1,"hidden_dims":[64,64],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.005}
2025-12-29 06:40:39,888 | INFO | [trial_005 | seed 29] Launching UnityVectorEnv with worker_id=5029, seed=29
2025-12-29 06:40:39,889 | INFO | [Main] Spawning worker 5029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 06:40:39,916 | INFO | [Main] Worker 5029 started (pid=52012).
2025-12-29 06:40:46,609 | INFO | [trial_005 | seed 29] Environment batched agents (train): 20
2025-12-29 06:41:18,838 | INFO | [trial_005 | seed 29] Environment batched agents (eval): 20
2025-12-29 06:41:36,627 | INFO | [trial_005 | seed 29] elapsed_time 00:00:56, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 17.600000, episode_sum_max_abs_reward_per_step 17.600000, mean_reward_over_100_episodes_from_training 01.16±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0299±0.0000, mean_reward_over_100_episodes_from_eval 01.10±00.00
2025-12-29 06:42:27,113 | INFO | [trial_005 | seed 29] elapsed_time 00:01:47, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 13.080000, episode_sum_max_abs_reward_per_step 13.080000, mean_reward_over_100_episodes_from_training 01.00±00.16, mean_exploration_ratio_over_100_episodes_from_training 0.0288±0.0010, mean_reward_over_100_episodes_from_eval 01.04±00.07
2025-12-29 06:43:17,730 | INFO | [trial_005 | seed 29] elapsed_time 00:02:37, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 18.110000, episode_sum_max_abs_reward_per_step 18.110000, mean_reward_over_100_episodes_from_training 01.08±00.18, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0009, mean_reward_over_100_episodes_from_eval 01.26±00.32
2025-12-29 06:44:09,252 | INFO | [trial_005 | seed 29] elapsed_time 00:03:29, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 16.470000, episode_sum_max_abs_reward_per_step 16.470000, mean_reward_over_100_episodes_from_training 01.07±00.16, mean_exploration_ratio_over_100_episodes_from_training 0.0281±0.0011, mean_reward_over_100_episodes_from_eval 01.13±00.37
2025-12-29 06:45:02,825 | INFO | [trial_005 | seed 29] elapsed_time 00:04:22, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 16.300000, episode_sum_max_abs_reward_per_step 16.300000, mean_reward_over_100_episodes_from_training 01.05±00.14, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0014, mean_reward_over_100_episodes_from_eval 01.06±00.35
2025-12-29 06:45:55,402 | INFO | [trial_005 | seed 29] elapsed_time 00:05:15, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 17.090000, episode_sum_max_abs_reward_per_step 17.090000, mean_reward_over_100_episodes_from_training 01.05±00.13, mean_exploration_ratio_over_100_episodes_from_training 0.0270±0.0020, mean_reward_over_100_episodes_from_eval 01.00±00.35
2025-12-29 06:46:47,000 | INFO | [trial_005 | seed 29] elapsed_time 00:06:07, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 24.589999, episode_sum_max_abs_reward_per_step 24.589999, mean_reward_over_100_episodes_from_training 01.15±00.29, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0019, mean_reward_over_100_episodes_from_eval 01.11±00.41
2025-12-29 06:47:38,699 | INFO | [trial_005 | seed 29] elapsed_time 00:06:58, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 31.179999, episode_sum_max_abs_reward_per_step 31.179999, mean_reward_over_100_episodes_from_training 01.36±00.60, mean_exploration_ratio_over_100_episodes_from_training 0.0266±0.0019, mean_reward_over_100_episodes_from_eval 01.24±00.51
2025-12-29 06:48:30,275 | INFO | [trial_005 | seed 29] elapsed_time 00:07:50, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 27.779999, episode_sum_max_abs_reward_per_step 27.779999, mean_reward_over_100_episodes_from_training 01.48±00.67, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0019, mean_reward_over_100_episodes_from_eval 01.33±00.55
2025-12-29 06:49:22,809 | INFO | [trial_005 | seed 29] elapsed_time 00:08:42, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 22.170000, episode_sum_max_abs_reward_per_step 22.170000, mean_reward_over_100_episodes_from_training 01.48±00.64, mean_exploration_ratio_over_100_episodes_from_training 0.0263±0.0018, mean_reward_over_100_episodes_from_eval 01.42±00.59
2025-12-29 06:50:14,147 | INFO | [trial_005 | seed 29] elapsed_time 00:09:34, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 22.070000, episode_sum_max_abs_reward_per_step 22.070000, mean_reward_over_100_episodes_from_training 01.50±00.61, mean_exploration_ratio_over_100_episodes_from_training 0.0262±0.0018, mean_reward_over_100_episodes_from_eval 01.49±00.61
2025-12-29 06:51:06,462 | INFO | [trial_005 | seed 29] elapsed_time 00:10:26, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 23.569999, episode_sum_max_abs_reward_per_step 23.569999, mean_reward_over_100_episodes_from_training 01.53±00.59, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0020, mean_reward_over_100_episodes_from_eval 01.50±00.58
2025-12-29 06:51:57,847 | INFO | [trial_005 | seed 29] elapsed_time 00:11:17, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 28.439999, episode_sum_max_abs_reward_per_step 28.439999, mean_reward_over_100_episodes_from_training 01.59±00.61, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0020, mean_reward_over_100_episodes_from_eval 01.62±00.71
2025-12-29 06:52:49,765 | INFO | [trial_005 | seed 29] elapsed_time 00:12:09, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 29.459999, episode_sum_max_abs_reward_per_step 29.459999, mean_reward_over_100_episodes_from_training 01.67±00.65, mean_exploration_ratio_over_100_episodes_from_training 0.0256±0.0020, mean_reward_over_100_episodes_from_eval 01.70±00.73
2025-12-29 06:53:42,103 | INFO | [trial_005 | seed 29] elapsed_time 00:13:02, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 31.909999, episode_sum_max_abs_reward_per_step 31.909999, mean_reward_over_100_episodes_from_training 01.78±00.75, mean_exploration_ratio_over_100_episodes_from_training 0.0256±0.0019, mean_reward_over_100_episodes_from_eval 01.84±00.88
2025-12-29 06:54:33,571 | INFO | [trial_005 | seed 29] elapsed_time 00:13:53, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 34.569999, episode_sum_max_abs_reward_per_step 34.569999, mean_reward_over_100_episodes_from_training 01.88±00.83, mean_exploration_ratio_over_100_episodes_from_training 0.0255±0.0019, mean_reward_over_100_episodes_from_eval 01.96±00.98
2025-12-29 06:55:25,663 | INFO | [trial_005 | seed 29] elapsed_time 00:14:45, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 29.019999, episode_sum_max_abs_reward_per_step 29.019999, mean_reward_over_100_episodes_from_training 01.93±00.83, mean_exploration_ratio_over_100_episodes_from_training 0.0254±0.0019, mean_reward_over_100_episodes_from_eval 02.03±00.99
2025-12-29 06:56:16,759 | INFO | [trial_005 | seed 29] elapsed_time 00:15:36, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 34.369999, episode_sum_max_abs_reward_per_step 34.369999, mean_reward_over_100_episodes_from_training 02.05±00.95, mean_exploration_ratio_over_100_episodes_from_training 0.0254±0.0018, mean_reward_over_100_episodes_from_eval 02.12±01.03
2025-12-29 06:57:08,567 | INFO | [trial_005 | seed 29] elapsed_time 00:16:28, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 37.399999, episode_sum_max_abs_reward_per_step 37.399999, mean_reward_over_100_episodes_from_training 02.23±01.20, mean_exploration_ratio_over_100_episodes_from_training 0.0254±0.0018, mean_reward_over_100_episodes_from_eval 02.46±01.74
2025-12-29 06:57:59,938 | INFO | [trial_005 | seed 29] elapsed_time 00:17:20, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 39.379999, episode_sum_max_abs_reward_per_step 39.379999, mean_reward_over_100_episodes_from_training 02.44±01.49, mean_exploration_ratio_over_100_episodes_from_training 0.0253±0.0017, mean_reward_over_100_episodes_from_eval 02.72±02.04
2025-12-29 06:58:51,458 | INFO | [trial_005 | seed 29] elapsed_time 00:18:11, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 38.459999, episode_sum_max_abs_reward_per_step 38.459999, mean_reward_over_100_episodes_from_training 02.67±01.78, mean_exploration_ratio_over_100_episodes_from_training 0.0253±0.0017, mean_reward_over_100_episodes_from_eval 02.99±02.32
2025-12-29 06:59:43,653 | INFO | [trial_005 | seed 29] elapsed_time 00:19:03, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 02.95±02.14, mean_exploration_ratio_over_100_episodes_from_training 0.0253±0.0016, mean_reward_over_100_episodes_from_eval 03.18±02.45
2025-12-29 07:00:36,086 | INFO | [trial_005 | seed 29] elapsed_time 00:19:56, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 03.31±02.71, mean_exploration_ratio_over_100_episodes_from_training 0.0254±0.0016, mean_reward_over_100_episodes_from_eval 03.64±03.22
2025-12-29 07:01:28,331 | INFO | [trial_005 | seed 29] elapsed_time 00:20:48, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 03.73±03.33, mean_exploration_ratio_over_100_episodes_from_training 0.0255±0.0018, mean_reward_over_100_episodes_from_eval 04.16±04.02
2025-12-29 07:02:19,885 | INFO | [trial_005 | seed 29] elapsed_time 00:21:40, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 04.31±04.32, mean_exploration_ratio_over_100_episodes_from_training 0.0257±0.0021, mean_reward_over_100_episodes_from_eval 04.83±05.12
2025-12-29 07:03:12,062 | INFO | [trial_005 | seed 29] elapsed_time 00:22:32, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 04.89±05.13, mean_exploration_ratio_over_100_episodes_from_training 0.0259±0.0021, mean_reward_over_100_episodes_from_eval 05.35±05.66
2025-12-29 07:04:04,534 | INFO | [trial_005 | seed 29] elapsed_time 00:23:24, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 05.37±05.61, mean_exploration_ratio_over_100_episodes_from_training 0.0261±0.0025, mean_reward_over_100_episodes_from_eval 05.86±06.12
2025-12-29 07:04:56,921 | INFO | [trial_005 | seed 29] elapsed_time 00:24:17, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 05.84±06.02, mean_exploration_ratio_over_100_episodes_from_training 0.0264±0.0029, mean_reward_over_100_episodes_from_eval 06.39±06.62
2025-12-29 07:05:48,654 | INFO | [trial_005 | seed 29] elapsed_time 00:25:08, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 06.33±06.45, mean_exploration_ratio_over_100_episodes_from_training 0.0266±0.0029, mean_reward_over_100_episodes_from_eval 06.92±07.09
2025-12-29 07:06:41,934 | INFO | [trial_005 | seed 29] elapsed_time 00:26:02, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 06.84±06.91, mean_exploration_ratio_over_100_episodes_from_training 0.0268±0.0031, mean_reward_over_100_episodes_from_eval 07.43±07.48
2025-12-29 07:07:34,139 | INFO | [trial_005 | seed 29] elapsed_time 00:26:54, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 07.33±07.31, mean_exploration_ratio_over_100_episodes_from_training 0.0270±0.0033, mean_reward_over_100_episodes_from_eval 08.01±08.02
2025-12-29 07:08:26,006 | INFO | [trial_005 | seed 29] elapsed_time 00:27:46, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 07.89±07.84, mean_exploration_ratio_over_100_episodes_from_training 0.0273±0.0035, mean_reward_over_100_episodes_from_eval 08.66±08.67
2025-12-29 07:09:17,787 | INFO | [trial_005 | seed 29] elapsed_time 00:28:37, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 08.46±08.36, mean_exploration_ratio_over_100_episodes_from_training 0.0275±0.0038, mean_reward_over_100_episodes_from_eval 09.24±09.15
2025-12-29 07:10:10,620 | INFO | [trial_005 | seed 29] elapsed_time 00:29:30, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 08.99±08.79, mean_exploration_ratio_over_100_episodes_from_training 0.0277±0.0039, mean_reward_over_100_episodes_from_eval 09.67±09.36
2025-12-29 07:11:03,267 | INFO | [trial_005 | seed 29] elapsed_time 00:30:23, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 09.51±09.17, mean_exploration_ratio_over_100_episodes_from_training 0.0280±0.0041, mean_reward_over_100_episodes_from_eval 10.25±09.82
2025-12-29 07:11:55,421 | INFO | [trial_005 | seed 29] elapsed_time 00:31:15, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 10.08±09.66, mean_exploration_ratio_over_100_episodes_from_training 0.0282±0.0043, mean_reward_over_100_episodes_from_eval 10.83±10.27
2025-12-29 07:12:46,498 | INFO | [trial_005 | seed 29] elapsed_time 00:32:06, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 10.65±10.12, mean_exploration_ratio_over_100_episodes_from_training 0.0285±0.0046, mean_reward_over_100_episodes_from_eval 11.40±10.69
2025-12-29 07:13:38,411 | INFO | [trial_005 | seed 29] elapsed_time 00:32:58, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 11.22±10.57, mean_exploration_ratio_over_100_episodes_from_training 0.0288±0.0048, mean_reward_over_100_episodes_from_eval 11.95±11.07
2025-12-29 07:14:31,628 | INFO | [trial_005 | seed 29] elapsed_time 00:33:51, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 11.64±10.75, mean_exploration_ratio_over_100_episodes_from_training 0.0290±0.0049, mean_reward_over_100_episodes_from_eval 12.48±11.40
2025-12-29 07:15:25,350 | INFO | [trial_005 | seed 29] elapsed_time 00:34:45, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 12.11±11.01, mean_exploration_ratio_over_100_episodes_from_training 0.0292±0.0051, mean_reward_over_100_episodes_from_eval 13.08±11.87
2025-12-29 07:16:16,431 | INFO | [trial_005 | seed 29] elapsed_time 00:35:36, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 12.54±11.22, mean_exploration_ratio_over_100_episodes_from_training 0.0294±0.0052, mean_reward_over_100_episodes_from_eval 13.64±12.23
2025-12-29 07:17:08,376 | INFO | [trial_005 | seed 29] elapsed_time 00:36:28, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 12.98±11.44, mean_exploration_ratio_over_100_episodes_from_training 0.0296±0.0052, mean_reward_over_100_episodes_from_eval 14.11±12.46
2025-12-29 07:18:00,450 | INFO | [trial_005 | seed 29] elapsed_time 00:37:20, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 13.42±11.65, mean_exploration_ratio_over_100_episodes_from_training 0.0297±0.0052, mean_reward_over_100_episodes_from_eval 14.52±12.59
2025-12-29 07:18:51,851 | INFO | [trial_005 | seed 29] elapsed_time 00:38:11, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 13.88±11.91, mean_exploration_ratio_over_100_episodes_from_training 0.0299±0.0053, mean_reward_over_100_episodes_from_eval 14.83±12.62
2025-12-29 07:19:45,607 | INFO | [trial_005 | seed 29] elapsed_time 00:39:05, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 14.27±12.06, mean_exploration_ratio_over_100_episodes_from_training 0.0301±0.0054, mean_reward_over_100_episodes_from_eval 15.10±12.61
2025-12-29 07:20:37,756 | INFO | [trial_005 | seed 29] elapsed_time 00:39:57, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 14.67±12.22, mean_exploration_ratio_over_100_episodes_from_training 0.0302±0.0054, mean_reward_over_100_episodes_from_eval 15.49±12.74
2025-12-29 07:21:30,432 | INFO | [trial_005 | seed 29] elapsed_time 00:40:50, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 15.05±12.36, mean_exploration_ratio_over_100_episodes_from_training 0.0304±0.0055, mean_reward_over_100_episodes_from_eval 15.78±12.76
2025-12-29 07:22:22,238 | INFO | [trial_005 | seed 29] elapsed_time 00:41:42, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 15.40±12.47, mean_exploration_ratio_over_100_episodes_from_training 0.0305±0.0055, mean_reward_over_100_episodes_from_eval 16.06±12.77
2025-12-29 07:23:13,751 | INFO | [trial_005 | seed 29] elapsed_time 00:42:33, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 15.69±12.51, mean_exploration_ratio_over_100_episodes_from_training 0.0307±0.0055, mean_reward_over_100_episodes_from_eval 16.41±12.87
2025-12-29 07:24:05,917 | INFO | [trial_005 | seed 29] elapsed_time 00:43:26, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 16.01±12.58, mean_exploration_ratio_over_100_episodes_from_training 0.0308±0.0056, mean_reward_over_100_episodes_from_eval 16.75±12.96
2025-12-29 07:24:58,637 | INFO | [trial_005 | seed 29] elapsed_time 00:44:18, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 16.36±12.69, mean_exploration_ratio_over_100_episodes_from_training 0.0309±0.0055, mean_reward_over_100_episodes_from_eval 16.96±12.92
2025-12-29 07:25:50,930 | INFO | [trial_005 | seed 29] elapsed_time 00:45:11, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 16.66±12.75, mean_exploration_ratio_over_100_episodes_from_training 0.0310±0.0055, mean_reward_over_100_episodes_from_eval 17.20±12.91
2025-12-29 07:26:42,378 | INFO | [trial_005 | seed 29] elapsed_time 00:46:02, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 17.00±12.88, mean_exploration_ratio_over_100_episodes_from_training 0.0311±0.0056, mean_reward_over_100_episodes_from_eval 17.53±13.00
2025-12-29 07:27:34,571 | INFO | [trial_005 | seed 29] elapsed_time 00:46:54, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 17.35±13.01, mean_exploration_ratio_over_100_episodes_from_training 0.0313±0.0056, mean_reward_over_100_episodes_from_eval 17.90±13.16
2025-12-29 07:28:26,814 | INFO | [trial_005 | seed 29] elapsed_time 00:47:46, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 17.71±13.16, mean_exploration_ratio_over_100_episodes_from_training 0.0314±0.0056, mean_reward_over_100_episodes_from_eval 18.23±13.26
2025-12-29 07:29:18,095 | INFO | [trial_005 | seed 29] elapsed_time 00:48:38, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 18.02±13.23, mean_exploration_ratio_over_100_episodes_from_training 0.0315±0.0057, mean_reward_over_100_episodes_from_eval 18.52±13.32
2025-12-29 07:30:10,640 | INFO | [trial_005 | seed 29] elapsed_time 00:49:30, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.29±13.28, mean_exploration_ratio_over_100_episodes_from_training 0.0317±0.0057, mean_reward_over_100_episodes_from_eval 18.75±13.31
2025-12-29 07:31:02,741 | INFO | [trial_005 | seed 29] elapsed_time 00:50:22, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 18.51±13.27, mean_exploration_ratio_over_100_episodes_from_training 0.0317±0.0057, mean_reward_over_100_episodes_from_eval 18.96±13.29
2025-12-29 07:31:54,751 | INFO | [trial_005 | seed 29] elapsed_time 00:51:14, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 18.66±13.20, mean_exploration_ratio_over_100_episodes_from_training 0.0318±0.0057, mean_reward_over_100_episodes_from_eval 19.16±13.27
2025-12-29 07:32:46,130 | INFO | [trial_005 | seed 29] elapsed_time 00:52:06, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 18.95±13.27, mean_exploration_ratio_over_100_episodes_from_training 0.0319±0.0057, mean_reward_over_100_episodes_from_eval 19.43±13.32
2025-12-29 07:33:38,378 | INFO | [trial_005 | seed 29] elapsed_time 00:52:58, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 19.16±13.27, mean_exploration_ratio_over_100_episodes_from_training 0.0320±0.0057, mean_reward_over_100_episodes_from_eval 19.66±13.33
2025-12-29 07:34:30,721 | INFO | [trial_005 | seed 29] elapsed_time 00:53:50, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 19.36±13.26, mean_exploration_ratio_over_100_episodes_from_training 0.0321±0.0057, mean_reward_over_100_episodes_from_eval 19.77±13.25
2025-12-29 07:35:23,164 | INFO | [trial_005 | seed 29] elapsed_time 00:54:43, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 19.43±13.16, mean_exploration_ratio_over_100_episodes_from_training 0.0322±0.0057, mean_reward_over_100_episodes_from_eval 19.88±13.17
2025-12-29 07:36:14,598 | INFO | [trial_005 | seed 29] elapsed_time 00:55:34, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 19.51±13.08, mean_exploration_ratio_over_100_episodes_from_training 0.0322±0.0056, mean_reward_over_100_episodes_from_eval 19.99±13.10
2025-12-29 07:37:06,912 | INFO | [trial_005 | seed 29] elapsed_time 00:56:27, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 19.69±13.05, mean_exploration_ratio_over_100_episodes_from_training 0.0323±0.0056, mean_reward_over_100_episodes_from_eval 20.13±13.05
2025-12-29 07:37:59,540 | INFO | [trial_005 | seed 29] elapsed_time 00:57:19, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 19.84±13.01, mean_exploration_ratio_over_100_episodes_from_training 0.0324±0.0056, mean_reward_over_100_episodes_from_eval 20.23±12.97
2025-12-29 07:38:51,883 | INFO | [trial_005 | seed 29] elapsed_time 00:58:12, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 20.03±13.00, mean_exploration_ratio_over_100_episodes_from_training 0.0325±0.0056, mean_reward_over_100_episodes_from_eval 20.41±12.96
2025-12-29 07:39:44,918 | INFO | [trial_005 | seed 29] elapsed_time 00:59:05, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 20.19±12.98, mean_exploration_ratio_over_100_episodes_from_training 0.0326±0.0056, mean_reward_over_100_episodes_from_eval 20.61±12.96
2025-12-29 07:40:37,007 | INFO | [trial_005 | seed 29] elapsed_time 00:59:57, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 20.39±12.98, mean_exploration_ratio_over_100_episodes_from_training 0.0326±0.0056, mean_reward_over_100_episodes_from_eval 20.77±12.94
2025-12-29 07:41:29,951 | INFO | [trial_005 | seed 29] elapsed_time 01:00:50, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 20.54±12.95, mean_exploration_ratio_over_100_episodes_from_training 0.0326±0.0056, mean_reward_over_100_episodes_from_eval 20.94±12.92
2025-12-29 07:42:24,300 | INFO | [trial_005 | seed 29] elapsed_time 01:01:44, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 20.74±12.97, mean_exploration_ratio_over_100_episodes_from_training 0.0327±0.0056, mean_reward_over_100_episodes_from_eval 21.13±12.93
2025-12-29 07:43:17,357 | INFO | [trial_005 | seed 29] elapsed_time 01:02:37, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 20.89±12.94, mean_exploration_ratio_over_100_episodes_from_training 0.0327±0.0056, mean_reward_over_100_episodes_from_eval 21.27±12.89
2025-12-29 07:44:10,963 | INFO | [trial_005 | seed 29] elapsed_time 01:03:31, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.03±12.90, mean_exploration_ratio_over_100_episodes_from_training 0.0328±0.0055, mean_reward_over_100_episodes_from_eval 21.43±12.88
2025-12-29 07:45:13,531 | INFO | [trial_005 | seed 29] elapsed_time 01:04:33, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 21.16±12.87, mean_exploration_ratio_over_100_episodes_from_training 0.0328±0.0055, mean_reward_over_100_episodes_from_eval 21.50±12.80
2025-12-29 07:46:06,451 | INFO | [trial_005 | seed 29] elapsed_time 01:05:26, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 21.27±12.81, mean_exploration_ratio_over_100_episodes_from_training 0.0329±0.0055, mean_reward_over_100_episodes_from_eval 21.59±12.74
2025-12-29 07:46:59,949 | INFO | [trial_005 | seed 29] elapsed_time 01:06:20, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 21.42±12.80, mean_exploration_ratio_over_100_episodes_from_training 0.0329±0.0055, mean_reward_over_100_episodes_from_eval 21.81±12.80
2025-12-29 07:47:51,334 | INFO | [trial_005 | seed 29] elapsed_time 01:07:11, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 21.51±12.74, mean_exploration_ratio_over_100_episodes_from_training 0.0330±0.0054, mean_reward_over_100_episodes_from_eval 21.92±12.75
2025-12-29 07:48:47,730 | INFO | [trial_005 | seed 29] elapsed_time 01:08:07, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.62±12.69, mean_exploration_ratio_over_100_episodes_from_training 0.0330±0.0055, mean_reward_over_100_episodes_from_eval 22.07±12.74
2025-12-29 07:49:44,393 | INFO | [trial_005 | seed 29] elapsed_time 01:09:04, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 21.71±12.64, mean_exploration_ratio_over_100_episodes_from_training 0.0331±0.0055, mean_reward_over_100_episodes_from_eval 22.19±12.70
2025-12-29 07:50:42,071 | INFO | [trial_005 | seed 29] elapsed_time 01:10:02, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 21.85±12.62, mean_exploration_ratio_over_100_episodes_from_training 0.0332±0.0054, mean_reward_over_100_episodes_from_eval 22.30±12.66
2025-12-29 07:51:39,955 | INFO | [trial_005 | seed 29] elapsed_time 01:11:00, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 21.97±12.58, mean_exploration_ratio_over_100_episodes_from_training 0.0332±0.0054, mean_reward_over_100_episodes_from_eval 22.40±12.61
2025-12-29 07:52:36,273 | INFO | [trial_005 | seed 29] elapsed_time 01:11:56, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.06±12.54, mean_exploration_ratio_over_100_episodes_from_training 0.0333±0.0054, mean_reward_over_100_episodes_from_eval 22.53±12.59
2025-12-29 07:53:32,473 | INFO | [trial_005 | seed 29] elapsed_time 01:12:52, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 22.16±12.49, mean_exploration_ratio_over_100_episodes_from_training 0.0334±0.0054, mean_reward_over_100_episodes_from_eval 22.64±12.55
2025-12-29 07:54:25,239 | INFO | [trial_005 | seed 29] elapsed_time 01:13:45, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 22.30±12.49, mean_exploration_ratio_over_100_episodes_from_training 0.0334±0.0054, mean_reward_over_100_episodes_from_eval 22.81±12.57
2025-12-29 07:55:17,119 | INFO | [trial_005 | seed 29] elapsed_time 01:14:37, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 22.42±12.46, mean_exploration_ratio_over_100_episodes_from_training 0.0335±0.0055, mean_reward_over_100_episodes_from_eval 22.91±12.54
2025-12-29 07:56:09,430 | INFO | [trial_005 | seed 29] elapsed_time 01:15:29, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.53±12.43, mean_exploration_ratio_over_100_episodes_from_training 0.0335±0.0054, mean_reward_over_100_episodes_from_eval 23.03±12.51
2025-12-29 07:57:01,522 | INFO | [trial_005 | seed 29] elapsed_time 01:16:21, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 22.64±12.40, mean_exploration_ratio_over_100_episodes_from_training 0.0336±0.0054, mean_reward_over_100_episodes_from_eval 23.07±12.44
2025-12-29 07:57:53,626 | INFO | [trial_005 | seed 29] elapsed_time 01:17:13, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 22.76±12.38, mean_exploration_ratio_over_100_episodes_from_training 0.0337±0.0054, mean_reward_over_100_episodes_from_eval 23.19±12.42
2025-12-29 07:58:45,034 | INFO | [trial_005 | seed 29] elapsed_time 01:18:05, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 22.82±12.32, mean_exploration_ratio_over_100_episodes_from_training 0.0337±0.0054, mean_reward_over_100_episodes_from_eval 23.24±12.36
2025-12-29 07:59:37,642 | INFO | [trial_005 | seed 29] elapsed_time 01:18:57, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.90±12.28, mean_exploration_ratio_over_100_episodes_from_training 0.0338±0.0054, mean_reward_over_100_episodes_from_eval 23.35±12.34
2025-12-29 08:00:29,762 | INFO | [trial_005 | seed 29] elapsed_time 01:19:49, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 22.97±12.23, mean_exploration_ratio_over_100_episodes_from_training 0.0338±0.0054, mean_reward_over_100_episodes_from_eval 23.34±12.27
2025-12-29 08:01:21,710 | INFO | [trial_005 | seed 29] elapsed_time 01:20:41, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.01±12.17, mean_exploration_ratio_over_100_episodes_from_training 0.0338±0.0054, mean_reward_over_100_episodes_from_eval 23.44±12.25
2025-12-29 08:02:16,808 | INFO | [trial_005 | seed 29] elapsed_time 01:21:36, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 23.09±12.12, mean_exploration_ratio_over_100_episodes_from_training 0.0339±0.0054, mean_reward_over_100_episodes_from_eval 23.53±12.21
2025-12-29 08:03:25,440 | INFO | [trial_005 | seed 29] elapsed_time 01:22:45, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.18±12.09, mean_exploration_ratio_over_100_episodes_from_training 0.0339±0.0054, mean_reward_over_100_episodes_from_eval 23.62±12.18
2025-12-29 08:04:33,280 | INFO | [trial_005 | seed 29] elapsed_time 01:23:53, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.27±12.06, mean_exploration_ratio_over_100_episodes_from_training 0.0340±0.0054, mean_reward_over_100_episodes_from_eval 23.69±12.13
2025-12-29 08:05:32,223 | INFO | [trial_005 | seed 29] elapsed_time 01:24:52, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.34±12.02, mean_exploration_ratio_over_100_episodes_from_training 0.0340±0.0054, mean_reward_over_100_episodes_from_eval 23.75±12.08
2025-12-29 08:06:25,158 | INFO | [trial_005 | seed 29] elapsed_time 01:25:45, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 23.38±11.96, mean_exploration_ratio_over_100_episodes_from_training 0.0341±0.0053, mean_reward_over_100_episodes_from_eval 23.80±12.03
2025-12-29 08:07:18,622 | INFO | [trial_005 | seed 29] elapsed_time 01:26:38, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 23.46±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0341±0.0053, mean_reward_over_100_episodes_from_eval 23.93±12.03
2025-12-29 08:08:28,680 | INFO | [trial_005 | seed 29] elapsed_time 01:27:48, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 23.56±11.91, mean_exploration_ratio_over_100_episodes_from_training 0.0341±0.0053, mean_reward_over_100_episodes_from_eval 24.01±12.00
2025-12-29 08:09:36,225 | INFO | [trial_005 | seed 29] elapsed_time 01:28:56, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 23.63±11.87, mean_exploration_ratio_over_100_episodes_from_training 0.0342±0.0053, mean_reward_over_100_episodes_from_eval 24.05±11.95
2025-12-29 08:10:33,330 | INFO | [trial_005 | seed 29] elapsed_time 01:29:53, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 23.92±11.67, mean_exploration_ratio_over_100_episodes_from_training 0.0343±0.0053, mean_reward_over_100_episodes_from_eval 24.33±11.73
2025-12-29 08:11:30,016 | INFO | [trial_005 | seed 29] elapsed_time 01:30:50, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 24.23±11.46, mean_exploration_ratio_over_100_episodes_from_training 0.0344±0.0053, mean_reward_over_100_episodes_from_eval 24.64±11.52
2025-12-29 08:12:39,634 | INFO | [trial_005 | seed 29] elapsed_time 01:31:59, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 24.53±11.25, mean_exploration_ratio_over_100_episodes_from_training 0.0345±0.0052, mean_reward_over_100_episodes_from_eval 24.93±11.30
2025-12-29 08:13:44,130 | INFO | [trial_005 | seed 29] elapsed_time 01:33:04, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 24.84±11.02, mean_exploration_ratio_over_100_episodes_from_training 0.0346±0.0052, mean_reward_over_100_episodes_from_eval 25.28±11.08
2025-12-29 08:14:47,381 | INFO | [trial_005 | seed 29] elapsed_time 01:34:07, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 25.17±10.79, mean_exploration_ratio_over_100_episodes_from_training 0.0347±0.0051, mean_reward_over_100_episodes_from_eval 25.61±10.84
2025-12-29 08:15:39,736 | INFO | [trial_005 | seed 29] elapsed_time 01:34:59, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.48±10.54, mean_exploration_ratio_over_100_episodes_from_training 0.0348±0.0050, mean_reward_over_100_episodes_from_eval 25.95±10.58
2025-12-29 08:16:30,625 | INFO | [trial_005 | seed 29] elapsed_time 01:35:50, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.80±10.30, mean_exploration_ratio_over_100_episodes_from_training 0.0349±0.0049, mean_reward_over_100_episodes_from_eval 26.29±10.34
2025-12-29 08:17:16,853 | INFO | [trial_005 | seed 29] elapsed_time 01:36:36, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.10±10.05, mean_exploration_ratio_over_100_episodes_from_training 0.0351±0.0048, mean_reward_over_100_episodes_from_eval 26.64±10.11
2025-12-29 08:18:03,951 | INFO | [trial_005 | seed 29] elapsed_time 01:37:24, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.40±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0352±0.0047, mean_reward_over_100_episodes_from_eval 26.96±09.83
2025-12-29 08:18:54,882 | INFO | [trial_005 | seed 29] elapsed_time 01:38:15, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.73±09.49, mean_exploration_ratio_over_100_episodes_from_training 0.0353±0.0046, mean_reward_over_100_episodes_from_eval 27.29±09.54
2025-12-29 08:19:42,600 | INFO | [trial_005 | seed 29] elapsed_time 01:39:02, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.05±09.18, mean_exploration_ratio_over_100_episodes_from_training 0.0354±0.0045, mean_reward_over_100_episodes_from_eval 27.61±09.22
2025-12-29 08:20:30,032 | INFO | [trial_005 | seed 29] elapsed_time 01:39:50, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.35±08.84, mean_exploration_ratio_over_100_episodes_from_training 0.0356±0.0044, mean_reward_over_100_episodes_from_eval 27.88±08.85
2025-12-29 08:21:17,367 | INFO | [trial_005 | seed 29] elapsed_time 01:40:37, episode 0112, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 27.66±08.49, mean_exploration_ratio_over_100_episodes_from_training 0.0357±0.0042, mean_reward_over_100_episodes_from_eval 28.16±08.49
2025-12-29 08:22:04,386 | INFO | [trial_005 | seed 29] elapsed_time 01:41:24, episode 0113, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.96±08.12, mean_exploration_ratio_over_100_episodes_from_training 0.0359±0.0040, mean_reward_over_100_episodes_from_eval 28.43±08.10
2025-12-29 08:22:52,023 | INFO | [trial_005 | seed 29] elapsed_time 01:42:12, episode 0114, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 28.23±07.74, mean_exploration_ratio_over_100_episodes_from_training 0.0360±0.0039, mean_reward_over_100_episodes_from_eval 28.76±07.74
2025-12-29 08:23:55,221 | INFO | [trial_005 | seed 29] elapsed_time 01:43:15, episode 0115, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 28.51±07.33, mean_exploration_ratio_over_100_episodes_from_training 0.0361±0.0037, mean_reward_over_100_episodes_from_eval 29.02±07.33
2025-12-29 08:24:48,889 | INFO | [trial_005 | seed 29] elapsed_time 01:44:09, episode 0116, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.79±06.86, mean_exploration_ratio_over_100_episodes_from_training 0.0362±0.0035, mean_reward_over_100_episodes_from_eval 29.24±06.86
2025-12-29 08:25:36,620 | INFO | [trial_005 | seed 29] elapsed_time 01:44:56, episode 0117, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 29.08±06.41, mean_exploration_ratio_over_100_episodes_from_training 0.0364±0.0033, mean_reward_over_100_episodes_from_eval 29.56±06.39
2025-12-29 08:26:24,349 | INFO | [trial_005 | seed 29] elapsed_time 01:45:44, episode 0118, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 29.34±05.96, mean_exploration_ratio_over_100_episodes_from_training 0.0365±0.0031, mean_reward_over_100_episodes_from_eval 29.77±06.03
2025-12-29 08:27:10,712 | INFO | [trial_005 | seed 29] elapsed_time 01:46:30, episode 0119, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 29.56±05.50, mean_exploration_ratio_over_100_episodes_from_training 0.0366±0.0029, mean_reward_over_100_episodes_from_eval 29.94±05.63
2025-12-29 08:27:57,629 | INFO | [trial_005 | seed 29] Requirement met (evaluation metric): solved at episode 121 with mean_100_eval=30.15
2025-12-29 08:27:57,630 | INFO | [trial_005 | seed 29] elapsed_time 01:47:17, episode 0120, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 29.75±05.03, mean_exploration_ratio_over_100_episodes_from_training 0.0367±0.0027, mean_reward_over_100_episodes_from_eval 30.15±05.20
2025-12-29 08:27:57,630 | INFO | [trial_005 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 08:57:44,128 | INFO | [trial_005 | seed 29] Training complete.
2025-12-29 08:57:44,129 | INFO | [trial_005 | seed 29] Solved (evaluation metric) at episode 121.
2025-12-29 08:57:44,129 | INFO | [trial_005 | seed 29] Final evaluation score 28.23±1.71 in 4295.85s training, 8224.25s wall.
2025-12-29 08:57:44,130 | INFO | [trial_005 | seed 29] Closing UnityVectorEnv (worker_id=5029).
2025-12-29 08:57:44,130 | INFO | [Main] Requesting worker 5029 to close Unity env.
2025-12-29 08:57:45,559 | INFO | [Main] Worker 5029 joined. Unity env fully closed.
2025-12-29 08:57:45,563 | INFO | [trial_005 | seed 29] Final eval score: 28.23
2025-12-29 08:57:46,041 | INFO | [trial_005 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_005_seed_29.png
2025-12-29 08:57:46,043 | INFO | [trial_005 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 08:57:46,251 | INFO | [trial_005] Final scores across seeds: [28.227]
2025-12-29 08:57:46,253 | INFO | [trial_005] Avg=28.227 ± 0.000, Best seed score=28.227
2025-12-29 08:57:46,255 | INFO | [trial_006] Starting trial with hparams: {"batch_size":256,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[64,64],"lr":0.0003,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-29 08:57:46,257 | INFO | [trial_006 | seed 29] Start training with hparams: {"batch_size":256,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[64,64],"lr":0.0003,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-29 08:57:46,257 | INFO | [trial_006 | seed 29] === Starting run for seed 29 ===
2025-12-29 08:57:46,257 | INFO | [trial_006 | seed 29] Hyperparameters: {"batch_size":256,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[64,64],"lr":0.0003,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-29 08:57:46,257 | INFO | [trial_006 | seed 29] Launching UnityVectorEnv with worker_id=6029, seed=29
2025-12-29 08:57:46,257 | INFO | [Main] Spawning worker 6029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 08:57:46,294 | INFO | [Main] Worker 6029 started (pid=68152).
2025-12-29 08:57:53,223 | INFO | [trial_006 | seed 29] Environment batched agents (train): 20
2025-12-29 08:58:25,817 | INFO | [trial_006 | seed 29] Environment batched agents (eval): 20
2025-12-29 08:58:41,790 | INFO | [trial_006 | seed 29] elapsed_time 00:00:55, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 11.570000, episode_sum_max_abs_reward_per_step 11.570000, mean_reward_over_100_episodes_from_training 00.70±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0183±0.0000, mean_reward_over_100_episodes_from_eval 01.37±00.00
2025-12-29 08:59:31,990 | INFO | [trial_006 | seed 29] elapsed_time 00:01:45, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 13.960000, episode_sum_max_abs_reward_per_step 13.960000, mean_reward_over_100_episodes_from_training 00.80±00.10, mean_exploration_ratio_over_100_episodes_from_training 0.0169±0.0015, mean_reward_over_100_episodes_from_eval 01.21±00.16
2025-12-29 09:00:22,179 | INFO | [trial_006 | seed 29] elapsed_time 00:02:35, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 13.880000, episode_sum_max_abs_reward_per_step 13.880000, mean_reward_over_100_episodes_from_training 00.82±00.09, mean_exploration_ratio_over_100_episodes_from_training 0.0166±0.0013, mean_reward_over_100_episodes_from_eval 01.26±00.15
2025-12-29 09:01:13,932 | INFO | [trial_006 | seed 29] elapsed_time 00:03:27, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 19.000000, episode_sum_max_abs_reward_per_step 19.000000, mean_reward_over_100_episodes_from_training 00.92±00.19, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0012, mean_reward_over_100_episodes_from_eval 01.22±00.15
2025-12-29 09:02:11,138 | INFO | [trial_006 | seed 29] elapsed_time 00:04:24, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 14.910000, episode_sum_max_abs_reward_per_step 14.910000, mean_reward_over_100_episodes_from_training 00.93±00.17, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0014, mean_reward_over_100_episodes_from_eval 01.21±00.13
2025-12-29 09:03:02,526 | INFO | [trial_006 | seed 29] elapsed_time 00:05:16, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 19.220000, episode_sum_max_abs_reward_per_step 19.220000, mean_reward_over_100_episodes_from_training 00.99±00.21, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0013, mean_reward_over_100_episodes_from_eval 01.23±00.13
2025-12-29 09:03:52,706 | INFO | [trial_006 | seed 29] elapsed_time 00:06:06, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 16.770000, episode_sum_max_abs_reward_per_step 16.770000, mean_reward_over_100_episodes_from_training 01.00±00.19, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0014, mean_reward_over_100_episodes_from_eval 01.20±00.15
2025-12-29 09:04:43,426 | INFO | [trial_006 | seed 29] elapsed_time 00:06:57, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 12.950000, episode_sum_max_abs_reward_per_step 12.950000, mean_reward_over_100_episodes_from_training 00.98±00.19, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0015, mean_reward_over_100_episodes_from_eval 01.16±00.18
2025-12-29 09:05:35,647 | INFO | [trial_006 | seed 29] elapsed_time 00:07:49, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 23.559999, episode_sum_max_abs_reward_per_step 23.559999, mean_reward_over_100_episodes_from_training 01.07±00.31, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0015, mean_reward_over_100_episodes_from_eval 01.23±00.28
2025-12-29 09:06:27,230 | INFO | [trial_006 | seed 29] elapsed_time 00:08:40, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 24.039999, episode_sum_max_abs_reward_per_step 24.039999, mean_reward_over_100_episodes_from_training 01.14±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0015, mean_reward_over_100_episodes_from_eval 01.29±00.30
2025-12-29 09:07:25,243 | INFO | [trial_006 | seed 29] elapsed_time 00:09:38, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 26.229999, episode_sum_max_abs_reward_per_step 26.229999, mean_reward_over_100_episodes_from_training 01.23±00.46, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0015, mean_reward_over_100_episodes_from_eval 01.36±00.38
2025-12-29 09:08:26,777 | INFO | [trial_006 | seed 29] elapsed_time 00:10:40, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 26.979999, episode_sum_max_abs_reward_per_step 26.979999, mean_reward_over_100_episodes_from_training 01.32±00.52, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0014, mean_reward_over_100_episodes_from_eval 01.47±00.50
2025-12-29 09:09:21,810 | INFO | [trial_006 | seed 29] elapsed_time 00:11:35, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 29.209999, episode_sum_max_abs_reward_per_step 29.209999, mean_reward_over_100_episodes_from_training 01.42±00.61, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0014, mean_reward_over_100_episodes_from_eval 01.60±00.66
2025-12-29 09:10:25,696 | INFO | [trial_006 | seed 29] elapsed_time 00:12:39, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 31.889999, episode_sum_max_abs_reward_per_step 31.889999, mean_reward_over_100_episodes_from_training 01.53±00.71, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0013, mean_reward_over_100_episodes_from_eval 01.69±00.71
2025-12-29 09:11:22,063 | INFO | [trial_006 | seed 29] elapsed_time 00:13:35, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 33.209999, episode_sum_max_abs_reward_per_step 33.209999, mean_reward_over_100_episodes_from_training 01.66±00.83, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0013, mean_reward_over_100_episodes_from_eval 01.85±00.93
2025-12-29 09:12:15,779 | INFO | [trial_006 | seed 29] elapsed_time 00:14:29, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 32.219999, episode_sum_max_abs_reward_per_step 32.219999, mean_reward_over_100_episodes_from_training 01.78±00.93, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0013, mean_reward_over_100_episodes_from_eval 02.11±01.34
2025-12-29 09:13:13,242 | INFO | [trial_006 | seed 29] elapsed_time 00:15:26, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 37.309999, episode_sum_max_abs_reward_per_step 37.309999, mean_reward_over_100_episodes_from_training 01.96±01.16, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0013, mean_reward_over_100_episodes_from_eval 02.27±01.45
2025-12-29 09:14:20,221 | INFO | [trial_006 | seed 29] elapsed_time 00:16:33, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 36.739999, episode_sum_max_abs_reward_per_step 36.739999, mean_reward_over_100_episodes_from_training 02.15±01.39, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0012, mean_reward_over_100_episodes_from_eval 02.48±01.65
2025-12-29 09:15:24,405 | INFO | [trial_006 | seed 29] elapsed_time 00:17:38, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 38.919999, episode_sum_max_abs_reward_per_step 38.919999, mean_reward_over_100_episodes_from_training 02.38±01.67, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0012, mean_reward_over_100_episodes_from_eval 02.73±01.93
2025-12-29 09:16:26,172 | INFO | [trial_006 | seed 29] elapsed_time 00:18:39, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 38.849999, episode_sum_max_abs_reward_per_step 38.849999, mean_reward_over_100_episodes_from_training 02.64±01.98, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0012, mean_reward_over_100_episodes_from_eval 02.94±02.09
2025-12-29 09:17:23,362 | INFO | [trial_006 | seed 29] elapsed_time 00:19:37, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 38.329999, episode_sum_max_abs_reward_per_step 38.329999, mean_reward_over_100_episodes_from_training 02.85±02.15, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0011, mean_reward_over_100_episodes_from_eval 03.23±02.43
2025-12-29 09:18:18,616 | INFO | [trial_006 | seed 29] elapsed_time 00:20:32, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 39.079999, episode_sum_max_abs_reward_per_step 39.079999, mean_reward_over_100_episodes_from_training 03.09±02.37, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0011, mean_reward_over_100_episodes_from_eval 03.41±02.50
2025-12-29 09:19:13,327 | INFO | [trial_006 | seed 29] elapsed_time 00:21:27, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 38.979999, episode_sum_max_abs_reward_per_step 38.979999, mean_reward_over_100_episodes_from_training 03.28±02.48, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0011, mean_reward_over_100_episodes_from_eval 03.66±02.72
2025-12-29 09:20:18,510 | INFO | [trial_006 | seed 29] elapsed_time 00:22:32, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.369999, episode_sum_max_abs_reward_per_step 39.369999, mean_reward_over_100_episodes_from_training 03.58±02.81, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0011, mean_reward_over_100_episodes_from_eval 03.92±02.94
2025-12-29 09:21:23,982 | INFO | [trial_006 | seed 29] elapsed_time 00:23:37, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.429999, episode_sum_max_abs_reward_per_step 39.429999, mean_reward_over_100_episodes_from_training 03.79±02.93, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0011, mean_reward_over_100_episodes_from_eval 03.99±02.90
2025-12-29 09:22:21,046 | INFO | [trial_006 | seed 29] elapsed_time 00:24:34, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.109999, episode_sum_max_abs_reward_per_step 39.109999, mean_reward_over_100_episodes_from_training 03.94±02.98, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 04.18±03.00
2025-12-29 09:23:19,238 | INFO | [trial_006 | seed 29] elapsed_time 00:25:32, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 04.15±03.11, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 04.36±03.09
2025-12-29 09:24:14,397 | INFO | [trial_006 | seed 29] elapsed_time 00:26:28, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 04.31±03.16, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 04.50±03.11
2025-12-29 09:25:08,685 | INFO | [trial_006 | seed 29] elapsed_time 00:27:22, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 04.48±03.23, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 04.59±03.09
2025-12-29 09:26:03,038 | INFO | [trial_006 | seed 29] elapsed_time 00:28:16, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.369999, episode_sum_max_abs_reward_per_step 39.369999, mean_reward_over_100_episodes_from_training 04.62±03.28, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 04.75±03.16
2025-12-29 09:26:57,509 | INFO | [trial_006 | seed 29] elapsed_time 00:29:11, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.329999, episode_sum_max_abs_reward_per_step 39.329999, mean_reward_over_100_episodes_from_training 04.81±03.39, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 05.01±03.43
2025-12-29 09:27:50,199 | INFO | [trial_006 | seed 29] elapsed_time 00:30:03, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 05.01±03.52, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 05.19±03.51
2025-12-29 09:28:44,697 | INFO | [trial_006 | seed 29] elapsed_time 00:30:58, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 05.23±03.67, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 05.40±03.66
2025-12-29 09:29:38,814 | INFO | [trial_006 | seed 29] elapsed_time 00:31:52, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 05.46±03.86, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 05.61±03.81
2025-12-29 09:30:48,947 | INFO | [trial_006 | seed 29] elapsed_time 00:33:02, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 05.70±04.04, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 05.81±03.92
2025-12-29 09:31:42,316 | INFO | [trial_006 | seed 29] elapsed_time 00:33:56, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 05.89±04.14, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 06.03±04.09
2025-12-29 09:32:36,314 | INFO | [trial_006 | seed 29] elapsed_time 00:34:50, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 06.09±04.26, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 06.20±04.16
2025-12-29 09:33:32,719 | INFO | [trial_006 | seed 29] elapsed_time 00:35:46, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 06.26±04.33, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 06.47±04.42
2025-12-29 09:34:32,207 | INFO | [trial_006 | seed 29] elapsed_time 00:36:45, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 06.49±04.50, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 06.81±04.84
2025-12-29 09:35:30,631 | INFO | [trial_006 | seed 29] elapsed_time 00:37:44, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 06.77±04.78, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 07.11±05.13
2025-12-29 09:36:25,253 | INFO | [trial_006 | seed 29] elapsed_time 00:38:38, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 07.06±05.07, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0010, mean_reward_over_100_episodes_from_eval 07.41±05.41
2025-12-29 09:37:18,668 | INFO | [trial_006 | seed 29] elapsed_time 00:39:32, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.469999, episode_sum_max_abs_reward_per_step 39.469999, mean_reward_over_100_episodes_from_training 07.37±05.39, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 07.79±05.88
2025-12-29 09:38:24,756 | INFO | [trial_006 | seed 29] elapsed_time 00:40:38, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 07.82±06.07, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 08.32±06.74
2025-12-29 09:39:21,683 | INFO | [trial_006 | seed 29] elapsed_time 00:41:35, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 08.24±06.61, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0010, mean_reward_over_100_episodes_from_eval 08.64±06.99
2025-12-29 09:40:21,835 | INFO | [trial_006 | seed 29] elapsed_time 00:42:35, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 08.69±07.16, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0011, mean_reward_over_100_episodes_from_eval 09.20±07.87
2025-12-29 09:41:28,193 | INFO | [trial_006 | seed 29] elapsed_time 00:43:41, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 09.21±07.92, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0011, mean_reward_over_100_episodes_from_eval 09.74±08.57
2025-12-29 09:42:26,039 | INFO | [trial_006 | seed 29] elapsed_time 00:44:39, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 09.73±08.58, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0011, mean_reward_over_100_episodes_from_eval 10.15±08.92
2025-12-29 09:43:24,645 | INFO | [trial_006 | seed 29] elapsed_time 00:45:38, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 10.25±09.20, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0012, mean_reward_over_100_episodes_from_eval 10.68±09.53
2025-12-29 09:44:19,354 | INFO | [trial_006 | seed 29] elapsed_time 00:46:33, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 10.74±09.74, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0012, mean_reward_over_100_episodes_from_eval 11.22±10.17
2025-12-29 09:45:16,476 | INFO | [trial_006 | seed 29] elapsed_time 00:47:30, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 11.26±10.29, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0013, mean_reward_over_100_episodes_from_eval 11.71±10.63
2025-12-29 09:46:13,024 | INFO | [trial_006 | seed 29] elapsed_time 00:48:26, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 11.76±10.80, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0014, mean_reward_over_100_episodes_from_eval 12.19±11.07
2025-12-29 09:47:11,779 | INFO | [trial_006 | seed 29] elapsed_time 00:49:25, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 12.22±11.18, mean_exploration_ratio_over_100_episodes_from_training 0.0150±0.0015, mean_reward_over_100_episodes_from_eval 12.56±11.27
2025-12-29 09:48:08,317 | INFO | [trial_006 | seed 29] elapsed_time 00:50:22, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 12.58±11.38, mean_exploration_ratio_over_100_episodes_from_training 0.0151±0.0015, mean_reward_over_100_episodes_from_eval 12.93±11.47
2025-12-29 09:49:04,330 | INFO | [trial_006 | seed 29] elapsed_time 00:51:18, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 12.98±11.64, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0016, mean_reward_over_100_episodes_from_eval 13.33±11.74
2025-12-29 09:50:01,275 | INFO | [trial_006 | seed 29] elapsed_time 00:52:15, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 13.40±11.93, mean_exploration_ratio_over_100_episodes_from_training 0.0152±0.0017, mean_reward_over_100_episodes_from_eval 13.61±11.81
2025-12-29 09:50:57,973 | INFO | [trial_006 | seed 29] elapsed_time 00:53:11, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 13.76±12.13, mean_exploration_ratio_over_100_episodes_from_training 0.0153±0.0018, mean_reward_over_100_episodes_from_eval 13.92±11.93
2025-12-29 09:51:51,900 | INFO | [trial_006 | seed 29] elapsed_time 00:54:05, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 14.10±12.28, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0019, mean_reward_over_100_episodes_from_eval 14.23±12.05
2025-12-29 09:52:46,691 | INFO | [trial_006 | seed 29] elapsed_time 00:55:00, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 14.41±12.40, mean_exploration_ratio_over_100_episodes_from_training 0.0154±0.0019, mean_reward_over_100_episodes_from_eval 14.53±12.16
2025-12-29 09:53:44,221 | INFO | [trial_006 | seed 29] elapsed_time 00:55:57, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 14.71±12.51, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0019, mean_reward_over_100_episodes_from_eval 14.89±12.37
2025-12-29 09:54:38,630 | INFO | [trial_006 | seed 29] elapsed_time 00:56:52, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 15.01±12.61, mean_exploration_ratio_over_100_episodes_from_training 0.0155±0.0020, mean_reward_over_100_episodes_from_eval 15.08±12.35
2025-12-29 09:55:33,546 | INFO | [trial_006 | seed 29] elapsed_time 00:57:47, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 15.27±12.67, mean_exploration_ratio_over_100_episodes_from_training 0.0156±0.0020, mean_reward_over_100_episodes_from_eval 15.42±12.51
2025-12-29 09:56:27,133 | INFO | [trial_006 | seed 29] elapsed_time 00:58:40, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 15.57±12.79, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0020, mean_reward_over_100_episodes_from_eval 15.77±12.71
2025-12-29 09:57:20,465 | INFO | [trial_006 | seed 29] elapsed_time 00:59:34, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 15.87±12.90, mean_exploration_ratio_over_100_episodes_from_training 0.0157±0.0021, mean_reward_over_100_episodes_from_eval 16.03±12.78
2025-12-29 09:58:12,580 | INFO | [trial_006 | seed 29] elapsed_time 01:00:26, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 16.11±12.94, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0021, mean_reward_over_100_episodes_from_eval 16.27±12.82
2025-12-29 09:59:05,638 | INFO | [trial_006 | seed 29] elapsed_time 01:01:19, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 16.38±13.02, mean_exploration_ratio_over_100_episodes_from_training 0.0158±0.0021, mean_reward_over_100_episodes_from_eval 16.53±12.89
2025-12-29 09:59:58,071 | INFO | [trial_006 | seed 29] elapsed_time 01:02:11, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 16.66±13.12, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0021, mean_reward_over_100_episodes_from_eval 16.82±13.01
2025-12-29 10:00:50,303 | INFO | [trial_006 | seed 29] elapsed_time 01:03:04, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 16.93±13.20, mean_exploration_ratio_over_100_episodes_from_training 0.0159±0.0022, mean_reward_over_100_episodes_from_eval 17.02±13.01
2025-12-29 10:01:42,492 | INFO | [trial_006 | seed 29] elapsed_time 01:03:56, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 17.15±13.23, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0022, mean_reward_over_100_episodes_from_eval 17.27±13.08
2025-12-29 10:02:36,208 | INFO | [trial_006 | seed 29] elapsed_time 01:04:49, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 17.42±13.32, mean_exploration_ratio_over_100_episodes_from_training 0.0160±0.0022, mean_reward_over_100_episodes_from_eval 17.46±13.08
2025-12-29 10:03:29,570 | INFO | [trial_006 | seed 29] elapsed_time 01:05:43, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 17.62±13.33, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0022, mean_reward_over_100_episodes_from_eval 17.62±13.06
2025-12-29 10:04:20,432 | INFO | [trial_006 | seed 29] elapsed_time 01:06:34, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 17.78±13.30, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0022, mean_reward_over_100_episodes_from_eval 17.74±13.00
2025-12-29 10:05:13,039 | INFO | [trial_006 | seed 29] elapsed_time 01:07:26, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 17.98±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0161±0.0022, mean_reward_over_100_episodes_from_eval 17.96±13.04
2025-12-29 10:06:05,632 | INFO | [trial_006 | seed 29] elapsed_time 01:08:19, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 18.14±13.29, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0022, mean_reward_over_100_episodes_from_eval 18.12±13.02
2025-12-29 10:06:57,952 | INFO | [trial_006 | seed 29] elapsed_time 01:09:11, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.439999, episode_sum_max_abs_reward_per_step 39.439999, mean_reward_over_100_episodes_from_training 18.31±13.29, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0022, mean_reward_over_100_episodes_from_eval 18.33±13.06
2025-12-29 10:07:51,083 | INFO | [trial_006 | seed 29] elapsed_time 01:10:04, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 18.54±13.34, mean_exploration_ratio_over_100_episodes_from_training 0.0162±0.0022, mean_reward_over_100_episodes_from_eval 18.56±13.12
2025-12-29 10:08:46,946 | INFO | [trial_006 | seed 29] elapsed_time 01:11:00, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 18.78±13.42, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0022, mean_reward_over_100_episodes_from_eval 18.80±13.20
2025-12-29 10:09:40,278 | INFO | [trial_006 | seed 29] elapsed_time 01:11:54, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 18.99±13.45, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0022, mean_reward_over_100_episodes_from_eval 18.95±13.17
2025-12-29 10:10:35,269 | INFO | [trial_006 | seed 29] elapsed_time 01:12:49, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 19.19±13.48, mean_exploration_ratio_over_100_episodes_from_training 0.0163±0.0022, mean_reward_over_100_episodes_from_eval 19.11±13.17
2025-12-29 10:11:31,850 | INFO | [trial_006 | seed 29] elapsed_time 01:13:45, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 19.38±13.50, mean_exploration_ratio_over_100_episodes_from_training 0.0164±0.0023, mean_reward_over_100_episodes_from_eval 19.30±13.18
2025-12-29 10:12:33,175 | INFO | [trial_006 | seed 29] elapsed_time 01:14:46, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 19.56±13.51, mean_exploration_ratio_over_100_episodes_from_training 0.0164±0.0023, mean_reward_over_100_episodes_from_eval 19.48±13.21
2025-12-29 10:13:25,641 | INFO | [trial_006 | seed 29] elapsed_time 01:15:39, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 19.71±13.49, mean_exploration_ratio_over_100_episodes_from_training 0.0164±0.0023, mean_reward_over_100_episodes_from_eval 19.67±13.23
2025-12-29 10:14:17,376 | INFO | [trial_006 | seed 29] elapsed_time 01:16:31, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 19.85±13.47, mean_exploration_ratio_over_100_episodes_from_training 0.0165±0.0023, mean_reward_over_100_episodes_from_eval 19.77±13.18
2025-12-29 10:15:10,218 | INFO | [trial_006 | seed 29] elapsed_time 01:17:23, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 19.94±13.41, mean_exploration_ratio_over_100_episodes_from_training 0.0165±0.0023, mean_reward_over_100_episodes_from_eval 19.91±13.16
2025-12-29 10:16:04,939 | INFO | [trial_006 | seed 29] elapsed_time 01:18:18, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 20.04±13.36, mean_exploration_ratio_over_100_episodes_from_training 0.0165±0.0023, mean_reward_over_100_episodes_from_eval 20.09±13.19
2025-12-29 10:16:58,769 | INFO | [trial_006 | seed 29] elapsed_time 01:19:12, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 20.21±13.37, mean_exploration_ratio_over_100_episodes_from_training 0.0166±0.0023, mean_reward_over_100_episodes_from_eval 20.24±13.18
2025-12-29 10:17:50,541 | INFO | [trial_006 | seed 29] elapsed_time 01:20:04, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.35±13.36, mean_exploration_ratio_over_100_episodes_from_training 0.0166±0.0023, mean_reward_over_100_episodes_from_eval 20.37±13.16
2025-12-29 10:18:42,688 | INFO | [trial_006 | seed 29] elapsed_time 01:20:56, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 20.45±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0166±0.0023, mean_reward_over_100_episodes_from_eval 20.45±13.10
2025-12-29 10:19:35,094 | INFO | [trial_006 | seed 29] elapsed_time 01:21:48, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 20.60±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0167±0.0023, mean_reward_over_100_episodes_from_eval 20.60±13.11
2025-12-29 10:20:27,422 | INFO | [trial_006 | seed 29] elapsed_time 01:22:41, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 20.74±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0167±0.0024, mean_reward_over_100_episodes_from_eval 20.72±13.08
2025-12-29 10:21:18,860 | INFO | [trial_006 | seed 29] elapsed_time 01:23:32, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 20.90±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0167±0.0024, mean_reward_over_100_episodes_from_eval 20.88±13.10
2025-12-29 10:22:10,856 | INFO | [trial_006 | seed 29] elapsed_time 01:24:24, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 21.06±13.32, mean_exploration_ratio_over_100_episodes_from_training 0.0168±0.0024, mean_reward_over_100_episodes_from_eval 21.00±13.07
2025-12-29 10:23:04,040 | INFO | [trial_006 | seed 29] elapsed_time 01:25:17, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 21.18±13.30, mean_exploration_ratio_over_100_episodes_from_training 0.0168±0.0024, mean_reward_over_100_episodes_from_eval 21.09±13.03
2025-12-29 10:23:55,738 | INFO | [trial_006 | seed 29] elapsed_time 01:26:09, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.29±13.27, mean_exploration_ratio_over_100_episodes_from_training 0.0168±0.0024, mean_reward_over_100_episodes_from_eval 21.24±13.04
2025-12-29 10:24:47,769 | INFO | [trial_006 | seed 29] elapsed_time 01:27:01, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 21.41±13.25, mean_exploration_ratio_over_100_episodes_from_training 0.0169±0.0024, mean_reward_over_100_episodes_from_eval 21.37±13.03
2025-12-29 10:25:40,432 | INFO | [trial_006 | seed 29] elapsed_time 01:27:54, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 21.49±13.21, mean_exploration_ratio_over_100_episodes_from_training 0.0169±0.0024, mean_reward_over_100_episodes_from_eval 21.39±12.97
2025-12-29 10:26:33,487 | INFO | [trial_006 | seed 29] elapsed_time 01:28:47, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 21.56±13.16, mean_exploration_ratio_over_100_episodes_from_training 0.0169±0.0024, mean_reward_over_100_episodes_from_eval 21.52±12.96
2025-12-29 10:27:25,669 | INFO | [trial_006 | seed 29] elapsed_time 01:29:39, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 21.66±13.13, mean_exploration_ratio_over_100_episodes_from_training 0.0169±0.0024, mean_reward_over_100_episodes_from_eval 21.56±12.90
2025-12-29 10:28:18,011 | INFO | [trial_006 | seed 29] elapsed_time 01:30:31, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.68±13.06, mean_exploration_ratio_over_100_episodes_from_training 0.0170±0.0024, mean_reward_over_100_episodes_from_eval 21.58±12.83
2025-12-29 10:29:10,342 | INFO | [trial_006 | seed 29] elapsed_time 01:31:24, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 21.72±13.00, mean_exploration_ratio_over_100_episodes_from_training 0.0170±0.0024, mean_reward_over_100_episodes_from_eval 21.66±12.79
2025-12-29 10:30:03,402 | INFO | [trial_006 | seed 29] elapsed_time 01:32:17, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.439999, episode_sum_max_abs_reward_per_step 39.439999, mean_reward_over_100_episodes_from_training 21.81±12.97, mean_exploration_ratio_over_100_episodes_from_training 0.0170±0.0024, mean_reward_over_100_episodes_from_eval 21.78±12.78
2025-12-29 10:30:56,231 | INFO | [trial_006 | seed 29] elapsed_time 01:33:09, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.409999, episode_sum_max_abs_reward_per_step 39.409999, mean_reward_over_100_episodes_from_training 22.13±12.84, mean_exploration_ratio_over_100_episodes_from_training 0.0170±0.0024, mean_reward_over_100_episodes_from_eval 22.04±12.63
2025-12-29 10:31:49,175 | INFO | [trial_006 | seed 29] elapsed_time 01:34:02, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 22.43±12.69, mean_exploration_ratio_over_100_episodes_from_training 0.0170±0.0024, mean_reward_over_100_episodes_from_eval 22.38±12.51
2025-12-29 10:32:41,940 | INFO | [trial_006 | seed 29] elapsed_time 01:34:55, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 22.72±12.52, mean_exploration_ratio_over_100_episodes_from_training 0.0171±0.0024, mean_reward_over_100_episodes_from_eval 22.71±12.39
2025-12-29 10:33:36,400 | INFO | [trial_006 | seed 29] elapsed_time 01:35:50, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 23.02±12.36, mean_exploration_ratio_over_100_episodes_from_training 0.0171±0.0024, mean_reward_over_100_episodes_from_eval 23.04±12.25
2025-12-29 10:34:29,405 | INFO | [trial_006 | seed 29] elapsed_time 01:36:43, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.30±12.18, mean_exploration_ratio_over_100_episodes_from_training 0.0171±0.0024, mean_reward_over_100_episodes_from_eval 23.39±12.12
2025-12-29 10:35:22,171 | INFO | [trial_006 | seed 29] elapsed_time 01:37:35, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 23.61±12.00, mean_exploration_ratio_over_100_episodes_from_training 0.0172±0.0024, mean_reward_over_100_episodes_from_eval 23.70±11.95
2025-12-29 10:36:15,549 | INFO | [trial_006 | seed 29] elapsed_time 01:38:29, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 23.87±11.79, mean_exploration_ratio_over_100_episodes_from_training 0.0172±0.0023, mean_reward_over_100_episodes_from_eval 23.95±11.73
2025-12-29 10:37:07,625 | INFO | [trial_006 | seed 29] elapsed_time 01:39:21, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 24.16±11.58, mean_exploration_ratio_over_100_episodes_from_training 0.0173±0.0023, mean_reward_over_100_episodes_from_eval 24.20±11.50
2025-12-29 10:38:03,342 | INFO | [trial_006 | seed 29] elapsed_time 01:40:17, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.43±11.37, mean_exploration_ratio_over_100_episodes_from_training 0.0173±0.0023, mean_reward_over_100_episodes_from_eval 24.45±11.28
2025-12-29 10:38:57,127 | INFO | [trial_006 | seed 29] elapsed_time 01:41:10, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 24.69±11.14, mean_exploration_ratio_over_100_episodes_from_training 0.0174±0.0022, mean_reward_over_100_episodes_from_eval 24.66±11.05
2025-12-29 10:39:50,767 | INFO | [trial_006 | seed 29] elapsed_time 01:42:04, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 24.91±10.91, mean_exploration_ratio_over_100_episodes_from_training 0.0174±0.0022, mean_reward_over_100_episodes_from_eval 24.86±10.82
2025-12-29 10:40:43,742 | INFO | [trial_006 | seed 29] elapsed_time 01:42:57, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 25.11±10.67, mean_exploration_ratio_over_100_episodes_from_training 0.0174±0.0022, mean_reward_over_100_episodes_from_eval 25.13±10.59
2025-12-29 10:41:38,073 | INFO | [trial_006 | seed 29] elapsed_time 01:43:51, episode 0112, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 25.35±10.43, mean_exploration_ratio_over_100_episodes_from_training 0.0175±0.0022, mean_reward_over_100_episodes_from_eval 25.36±10.36
2025-12-29 10:42:31,303 | INFO | [trial_006 | seed 29] elapsed_time 01:44:45, episode 0113, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 25.63±10.20, mean_exploration_ratio_over_100_episodes_from_training 0.0175±0.0022, mean_reward_over_100_episodes_from_eval 25.64±10.13
2025-12-29 10:43:25,252 | INFO | [trial_006 | seed 29] elapsed_time 01:45:38, episode 0114, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 25.90±09.96, mean_exploration_ratio_over_100_episodes_from_training 0.0176±0.0021, mean_reward_over_100_episodes_from_eval 25.91±09.91
2025-12-29 10:44:16,806 | INFO | [trial_006 | seed 29] elapsed_time 01:46:30, episode 0115, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 26.13±09.71, mean_exploration_ratio_over_100_episodes_from_training 0.0177±0.0021, mean_reward_over_100_episodes_from_eval 26.11±09.70
2025-12-29 10:45:09,317 | INFO | [trial_006 | seed 29] elapsed_time 01:47:23, episode 0116, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 26.37±09.47, mean_exploration_ratio_over_100_episodes_from_training 0.0177±0.0021, mean_reward_over_100_episodes_from_eval 26.32±09.47
2025-12-29 10:46:04,939 | INFO | [trial_006 | seed 29] elapsed_time 01:48:18, episode 0117, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 26.57±09.24, mean_exploration_ratio_over_100_episodes_from_training 0.0178±0.0021, mean_reward_over_100_episodes_from_eval 26.53±09.24
2025-12-29 10:47:00,999 | INFO | [trial_006 | seed 29] elapsed_time 01:49:14, episode 0118, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 26.78±09.02, mean_exploration_ratio_over_100_episodes_from_training 0.0178±0.0020, mean_reward_over_100_episodes_from_eval 26.71±09.04
2025-12-29 10:47:55,553 | INFO | [trial_006 | seed 29] elapsed_time 01:50:09, episode 0119, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 27.01±08.81, mean_exploration_ratio_over_100_episodes_from_training 0.0179±0.0020, mean_reward_over_100_episodes_from_eval 26.88±08.82
2025-12-29 10:48:49,880 | INFO | [trial_006 | seed 29] elapsed_time 01:51:03, episode 0120, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 27.21±08.58, mean_exploration_ratio_over_100_episodes_from_training 0.0179±0.0020, mean_reward_over_100_episodes_from_eval 27.12±08.66
2025-12-29 10:49:45,111 | INFO | [trial_006 | seed 29] elapsed_time 01:51:58, episode 0121, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 27.40±08.37, mean_exploration_ratio_over_100_episodes_from_training 0.0180±0.0020, mean_reward_over_100_episodes_from_eval 27.32±08.42
2025-12-29 10:50:41,160 | INFO | [trial_006 | seed 29] elapsed_time 01:52:54, episode 0122, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 27.62±08.13, mean_exploration_ratio_over_100_episodes_from_training 0.0180±0.0019, mean_reward_over_100_episodes_from_eval 27.51±08.22
2025-12-29 10:51:36,434 | INFO | [trial_006 | seed 29] elapsed_time 01:53:50, episode 0123, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 27.79±07.94, mean_exploration_ratio_over_100_episodes_from_training 0.0181±0.0019, mean_reward_over_100_episodes_from_eval 27.65±08.04
2025-12-29 10:52:29,895 | INFO | [trial_006 | seed 29] elapsed_time 01:54:43, episode 0124, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 27.96±07.71, mean_exploration_ratio_over_100_episodes_from_training 0.0181±0.0019, mean_reward_over_100_episodes_from_eval 27.83±07.74
2025-12-29 10:53:23,379 | INFO | [trial_006 | seed 29] elapsed_time 01:55:37, episode 0125, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 28.12±07.45, mean_exploration_ratio_over_100_episodes_from_training 0.0182±0.0018, mean_reward_over_100_episodes_from_eval 27.99±07.51
2025-12-29 10:54:15,578 | INFO | [trial_006 | seed 29] elapsed_time 01:56:29, episode 0126, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 28.33±07.21, mean_exploration_ratio_over_100_episodes_from_training 0.0182±0.0018, mean_reward_over_100_episodes_from_eval 28.22±07.27
2025-12-29 10:55:08,517 | INFO | [trial_006 | seed 29] elapsed_time 01:57:22, episode 0127, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 28.56±06.94, mean_exploration_ratio_over_100_episodes_from_training 0.0183±0.0018, mean_reward_over_100_episodes_from_eval 28.41±06.99
2025-12-29 10:56:01,024 | INFO | [trial_006 | seed 29] elapsed_time 01:58:14, episode 0128, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 28.76±06.67, mean_exploration_ratio_over_100_episodes_from_training 0.0183±0.0017, mean_reward_over_100_episodes_from_eval 28.61±06.65
2025-12-29 10:56:52,872 | INFO | [trial_006 | seed 29] elapsed_time 01:59:06, episode 0129, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.93±06.37, mean_exploration_ratio_over_100_episodes_from_training 0.0184±0.0017, mean_reward_over_100_episodes_from_eval 28.77±06.37
2025-12-29 10:57:45,315 | INFO | [trial_006 | seed 29] elapsed_time 01:59:59, episode 0130, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 29.16±06.10, mean_exploration_ratio_over_100_episodes_from_training 0.0184±0.0016, mean_reward_over_100_episodes_from_eval 28.90±06.18
2025-12-29 10:58:37,777 | INFO | [trial_006 | seed 29] elapsed_time 02:00:51, episode 0131, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.30±05.85, mean_exploration_ratio_over_100_episodes_from_training 0.0185±0.0015, mean_reward_over_100_episodes_from_eval 29.08±05.90
2025-12-29 10:59:30,099 | INFO | [trial_006 | seed 29] elapsed_time 02:01:43, episode 0132, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 29.45±05.59, mean_exploration_ratio_over_100_episodes_from_training 0.0185±0.0015, mean_reward_over_100_episodes_from_eval 29.21±05.66
2025-12-29 11:00:21,467 | INFO | [trial_006 | seed 29] elapsed_time 02:02:35, episode 0133, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 29.60±05.35, mean_exploration_ratio_over_100_episodes_from_training 0.0186±0.0014, mean_reward_over_100_episodes_from_eval 29.33±05.44
2025-12-29 11:01:15,150 | INFO | [trial_006 | seed 29] elapsed_time 02:03:28, episode 0134, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 29.77±05.11, mean_exploration_ratio_over_100_episodes_from_training 0.0186±0.0014, mean_reward_over_100_episodes_from_eval 29.54±05.18
2025-12-29 11:02:10,355 | INFO | [trial_006 | seed 29] elapsed_time 02:04:24, episode 0135, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 29.95±04.80, mean_exploration_ratio_over_100_episodes_from_training 0.0187±0.0012, mean_reward_over_100_episodes_from_eval 29.68±04.95
2025-12-29 11:03:03,463 | INFO | [trial_006 | seed 29] elapsed_time 02:05:17, episode 0136, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 30.13±04.50, mean_exploration_ratio_over_100_episodes_from_training 0.0187±0.0012, mean_reward_over_100_episodes_from_eval 29.89±04.64
2025-12-29 11:03:55,765 | INFO | [trial_006 | seed 29] Requirement met (evaluation metric): solved at episode 138 with mean_100_eval=30.09
2025-12-29 11:03:55,767 | INFO | [trial_006 | seed 29] elapsed_time 02:06:09, episode 0137, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 30.36±04.17, mean_exploration_ratio_over_100_episodes_from_training 0.0187±0.0011, mean_reward_over_100_episodes_from_eval 30.09±04.48
2025-12-29 11:03:55,767 | INFO | [trial_006 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 11:32:17,652 | INFO | [trial_006 | seed 29] Training complete.
2025-12-29 11:32:17,653 | INFO | [trial_006 | seed 29] Solved (evaluation metric) at episode 138.
2025-12-29 11:32:17,653 | INFO | [trial_006 | seed 29] Final evaluation score 36.36±0.98 in 5097.98s training, 9271.40s wall.
2025-12-29 11:32:17,653 | INFO | [trial_006 | seed 29] Closing UnityVectorEnv (worker_id=6029).
2025-12-29 11:32:17,653 | INFO | [Main] Requesting worker 6029 to close Unity env.
2025-12-29 11:32:19,237 | INFO | [Main] Worker 6029 joined. Unity env fully closed.
2025-12-29 11:32:19,237 | INFO | [trial_006 | seed 29] Final eval score: 36.36
2025-12-29 11:32:19,648 | INFO | [trial_006 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_006_seed_29.png
2025-12-29 11:32:19,649 | INFO | [trial_006 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 11:32:19,865 | INFO | [trial_006] Final scores across seeds: [36.359]
2025-12-29 11:32:19,866 | INFO | [trial_006] Avg=36.359 ± 0.000, Best seed score=36.359
2025-12-29 11:32:19,868 | INFO | [trial_007] Starting trial with hparams: {"batch_size":64,"buffer_size":100000,"exploration_noise_ratio":0.2,"hidden_dims":[64,64],"lr":0.0003,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-29 11:32:19,870 | INFO | [trial_007 | seed 29] Start training with hparams: {"batch_size":64,"buffer_size":100000,"exploration_noise_ratio":0.2,"hidden_dims":[64,64],"lr":0.0003,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-29 11:32:19,871 | INFO | [trial_007 | seed 29] === Starting run for seed 29 ===
2025-12-29 11:32:19,872 | INFO | [trial_007 | seed 29] Hyperparameters: {"batch_size":64,"buffer_size":100000,"exploration_noise_ratio":0.2,"hidden_dims":[64,64],"lr":0.0003,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":10,"tau":0.01}
2025-12-29 11:32:19,875 | INFO | [trial_007 | seed 29] Launching UnityVectorEnv with worker_id=7029, seed=29
2025-12-29 11:32:19,875 | INFO | [Main] Spawning worker 7029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 11:32:19,902 | INFO | [Main] Worker 7029 started (pid=76404).
2025-12-29 11:32:31,073 | INFO | [trial_007 | seed 29] Environment batched agents (train): 20
2025-12-29 11:33:03,077 | INFO | [trial_007 | seed 29] Environment batched agents (eval): 20
2025-12-29 11:33:19,665 | INFO | [trial_007 | seed 29] elapsed_time 00:00:59, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 15.180000, episode_sum_max_abs_reward_per_step 15.180000, mean_reward_over_100_episodes_from_training 00.98±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0629±0.0000, mean_reward_over_100_episodes_from_eval 00.76±00.00
2025-12-29 11:34:08,340 | INFO | [trial_007 | seed 29] elapsed_time 00:01:48, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 10.160000, episode_sum_max_abs_reward_per_step 10.160000, mean_reward_over_100_episodes_from_training 00.77±00.20, mean_exploration_ratio_over_100_episodes_from_training 0.0577±0.0052, mean_reward_over_100_episodes_from_eval 00.48±00.28
2025-12-29 11:34:57,538 | INFO | [trial_007 | seed 29] elapsed_time 00:02:37, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 11.590000, episode_sum_max_abs_reward_per_step 11.590000, mean_reward_over_100_episodes_from_training 00.75±00.17, mean_exploration_ratio_over_100_episodes_from_training 0.0568±0.0044, mean_reward_over_100_episodes_from_eval 00.84±00.55
2025-12-29 11:35:46,717 | INFO | [trial_007 | seed 29] elapsed_time 00:03:26, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 22.250000, episode_sum_max_abs_reward_per_step 22.250000, mean_reward_over_100_episodes_from_training 01.00±00.46, mean_exploration_ratio_over_100_episodes_from_training 0.0560±0.0041, mean_reward_over_100_episodes_from_eval 00.69±00.54
2025-12-29 11:36:36,795 | INFO | [trial_007 | seed 29] elapsed_time 00:04:16, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 01.420000, episode_sum_max_abs_reward_per_step 01.420000, mean_reward_over_100_episodes_from_training 00.82±00.55, mean_exploration_ratio_over_100_episodes_from_training 0.0541±0.0053, mean_reward_over_100_episodes_from_eval 00.59±00.53
2025-12-29 11:37:27,751 | INFO | [trial_007 | seed 29] elapsed_time 00:05:07, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 00.440000, episode_sum_max_abs_reward_per_step 00.440000, mean_reward_over_100_episodes_from_training 00.69±00.58, mean_exploration_ratio_over_100_episodes_from_training 0.0525±0.0059, mean_reward_over_100_episodes_from_eval 00.50±00.51
2025-12-29 11:38:17,094 | INFO | [trial_007 | seed 29] elapsed_time 00:05:57, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 01.260000, episode_sum_max_abs_reward_per_step 01.260000, mean_reward_over_100_episodes_from_training 00.60±00.58, mean_exploration_ratio_over_100_episodes_from_training 0.0512±0.0064, mean_reward_over_100_episodes_from_eval 00.45±00.49
2025-12-29 11:39:07,027 | INFO | [trial_007 | seed 29] elapsed_time 00:06:47, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 01.690000, episode_sum_max_abs_reward_per_step 01.690000, mean_reward_over_100_episodes_from_training 00.54±00.57, mean_exploration_ratio_over_100_episodes_from_training 0.0502±0.0066, mean_reward_over_100_episodes_from_eval 00.41±00.47
2025-12-29 11:39:57,321 | INFO | [trial_007 | seed 29] elapsed_time 00:07:37, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 01.210000, episode_sum_max_abs_reward_per_step 01.210000, mean_reward_over_100_episodes_from_training 00.49±00.56, mean_exploration_ratio_over_100_episodes_from_training 0.0491±0.0069, mean_reward_over_100_episodes_from_eval 00.39±00.45
2025-12-29 11:40:47,164 | INFO | [trial_007 | seed 29] elapsed_time 00:08:27, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 05.000000, episode_sum_max_abs_reward_per_step 05.000000, mean_reward_over_100_episodes_from_training 00.46±00.53, mean_exploration_ratio_over_100_episodes_from_training 0.0486±0.0067, mean_reward_over_100_episodes_from_eval 00.38±00.43
2025-12-29 11:41:37,904 | INFO | [trial_007 | seed 29] elapsed_time 00:09:18, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 09.660000, episode_sum_max_abs_reward_per_step 09.660000, mean_reward_over_100_episodes_from_training 00.47±00.51, mean_exploration_ratio_over_100_episodes_from_training 0.0482±0.0065, mean_reward_over_100_episodes_from_eval 00.39±00.41
2025-12-29 11:42:27,970 | INFO | [trial_007 | seed 29] elapsed_time 00:10:08, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 11.280000, episode_sum_max_abs_reward_per_step 11.280000, mean_reward_over_100_episodes_from_training 00.49±00.49, mean_exploration_ratio_over_100_episodes_from_training 0.0479±0.0063, mean_reward_over_100_episodes_from_eval 00.41±00.40
2025-12-29 11:43:17,710 | INFO | [trial_007 | seed 29] elapsed_time 00:10:57, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 11.880000, episode_sum_max_abs_reward_per_step 11.880000, mean_reward_over_100_episodes_from_training 00.50±00.47, mean_exploration_ratio_over_100_episodes_from_training 0.0478±0.0061, mean_reward_over_100_episodes_from_eval 00.44±00.40
2025-12-29 11:44:08,153 | INFO | [trial_007 | seed 29] elapsed_time 00:11:48, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 16.010000, episode_sum_max_abs_reward_per_step 16.010000, mean_reward_over_100_episodes_from_training 00.54±00.48, mean_exploration_ratio_over_100_episodes_from_training 0.0477±0.0059, mean_reward_over_100_episodes_from_eval 00.51±00.45
2025-12-29 11:44:59,181 | INFO | [trial_007 | seed 29] elapsed_time 00:12:39, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 13.150000, episode_sum_max_abs_reward_per_step 13.150000, mean_reward_over_100_episodes_from_training 00.56±00.47, mean_exploration_ratio_over_100_episodes_from_training 0.0478±0.0057, mean_reward_over_100_episodes_from_eval 00.53±00.44
2025-12-29 11:45:49,374 | INFO | [trial_007 | seed 29] elapsed_time 00:13:29, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 15.610000, episode_sum_max_abs_reward_per_step 15.610000, mean_reward_over_100_episodes_from_training 00.59±00.47, mean_exploration_ratio_over_100_episodes_from_training 0.0477±0.0055, mean_reward_over_100_episodes_from_eval 00.58±00.46
2025-12-29 11:46:41,840 | INFO | [trial_007 | seed 29] elapsed_time 00:14:21, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 22.769999, episode_sum_max_abs_reward_per_step 22.769999, mean_reward_over_100_episodes_from_training 00.66±00.53, mean_exploration_ratio_over_100_episodes_from_training 0.0477±0.0053, mean_reward_over_100_episodes_from_eval 00.67±00.58
2025-12-29 11:47:34,748 | INFO | [trial_007 | seed 29] elapsed_time 00:15:14, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 24.409999, episode_sum_max_abs_reward_per_step 24.409999, mean_reward_over_100_episodes_from_training 00.73±00.59, mean_exploration_ratio_over_100_episodes_from_training 0.0477±0.0052, mean_reward_over_100_episodes_from_eval 00.77±00.69
2025-12-29 11:48:28,314 | INFO | [trial_007 | seed 29] elapsed_time 00:16:08, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 25.889999, episode_sum_max_abs_reward_per_step 25.889999, mean_reward_over_100_episodes_from_training 00.79±00.63, mean_exploration_ratio_over_100_episodes_from_training 0.0476±0.0051, mean_reward_over_100_episodes_from_eval 00.85±00.76
2025-12-29 11:49:20,255 | INFO | [trial_007 | seed 29] elapsed_time 00:17:00, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 26.889999, episode_sum_max_abs_reward_per_step 26.889999, mean_reward_over_100_episodes_from_training 00.85±00.66, mean_exploration_ratio_over_100_episodes_from_training 0.0476±0.0049, mean_reward_over_100_episodes_from_eval 00.91±00.78
2025-12-29 11:50:15,654 | INFO | [trial_007 | seed 29] elapsed_time 00:17:55, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 29.479999, episode_sum_max_abs_reward_per_step 29.479999, mean_reward_over_100_episodes_from_training 00.94±00.77, mean_exploration_ratio_over_100_episodes_from_training 0.0478±0.0049, mean_reward_over_100_episodes_from_eval 01.12±01.21
2025-12-29 11:51:09,141 | INFO | [trial_007 | seed 29] elapsed_time 00:18:49, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 34.589999, episode_sum_max_abs_reward_per_step 34.589999, mean_reward_over_100_episodes_from_training 01.07±00.95, mean_exploration_ratio_over_100_episodes_from_training 0.0478±0.0048, mean_reward_over_100_episodes_from_eval 01.19±01.23
2025-12-29 11:52:02,176 | INFO | [trial_007 | seed 29] elapsed_time 00:19:42, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 31.139999, episode_sum_max_abs_reward_per_step 31.139999, mean_reward_over_100_episodes_from_training 01.16±01.03, mean_exploration_ratio_over_100_episodes_from_training 0.0479±0.0047, mean_reward_over_100_episodes_from_eval 01.28±01.27
2025-12-29 11:52:55,851 | INFO | [trial_007 | seed 29] elapsed_time 00:20:35, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 35.269999, episode_sum_max_abs_reward_per_step 35.269999, mean_reward_over_100_episodes_from_training 01.30±01.22, mean_exploration_ratio_over_100_episodes_from_training 0.0480±0.0046, mean_reward_over_100_episodes_from_eval 01.38±01.34
2025-12-29 11:53:47,785 | INFO | [trial_007 | seed 29] elapsed_time 00:21:27, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 34.259999, episode_sum_max_abs_reward_per_step 34.259999, mean_reward_over_100_episodes_from_training 01.42±01.33, mean_exploration_ratio_over_100_episodes_from_training 0.0481±0.0045, mean_reward_over_100_episodes_from_eval 01.52±01.47
2025-12-29 11:54:37,680 | INFO | [trial_007 | seed 29] elapsed_time 00:22:17, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 36.499999, episode_sum_max_abs_reward_per_step 36.499999, mean_reward_over_100_episodes_from_training 01.56±01.48, mean_exploration_ratio_over_100_episodes_from_training 0.0481±0.0044, mean_reward_over_100_episodes_from_eval 01.62±01.52
2025-12-29 11:55:28,262 | INFO | [trial_007 | seed 29] elapsed_time 00:23:08, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 01.77±01.79, mean_exploration_ratio_over_100_episodes_from_training 0.0483±0.0044, mean_reward_over_100_episodes_from_eval 01.80±01.76
2025-12-29 11:56:18,556 | INFO | [trial_007 | seed 29] elapsed_time 00:23:58, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 37.419999, episode_sum_max_abs_reward_per_step 37.419999, mean_reward_over_100_episodes_from_training 01.91±01.91, mean_exploration_ratio_over_100_episodes_from_training 0.0485±0.0044, mean_reward_over_100_episodes_from_eval 01.99±01.99
2025-12-29 11:57:08,499 | INFO | [trial_007 | seed 29] elapsed_time 00:24:48, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.069999, episode_sum_max_abs_reward_per_step 39.069999, mean_reward_over_100_episodes_from_training 02.13±02.20, mean_exploration_ratio_over_100_episodes_from_training 0.0488±0.0048, mean_reward_over_100_episodes_from_eval 02.27±02.46
2025-12-29 11:57:58,701 | INFO | [trial_007 | seed 29] elapsed_time 00:25:38, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 38.719999, episode_sum_max_abs_reward_per_step 38.719999, mean_reward_over_100_episodes_from_training 02.35±02.47, mean_exploration_ratio_over_100_episodes_from_training 0.0490±0.0048, mean_reward_over_100_episodes_from_eval 02.51±02.75
2025-12-29 11:58:48,038 | INFO | [trial_007 | seed 29] elapsed_time 00:26:28, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 02.63±02.88, mean_exploration_ratio_over_100_episodes_from_training 0.0493±0.0050, mean_reward_over_100_episodes_from_eval 02.94±03.56
2025-12-29 11:59:38,780 | INFO | [trial_007 | seed 29] elapsed_time 00:27:18, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 02.93±03.29, mean_exploration_ratio_over_100_episodes_from_training 0.0496±0.0052, mean_reward_over_100_episodes_from_eval 03.24±03.89
2025-12-29 12:00:29,084 | INFO | [trial_007 | seed 29] elapsed_time 00:28:09, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 03.15±03.46, mean_exploration_ratio_over_100_episodes_from_training 0.0500±0.0055, mean_reward_over_100_episodes_from_eval 03.51±04.13
2025-12-29 12:01:19,190 | INFO | [trial_007 | seed 29] elapsed_time 00:28:59, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 03.37±03.65, mean_exploration_ratio_over_100_episodes_from_training 0.0503±0.0058, mean_reward_over_100_episodes_from_eval 03.75±04.28
2025-12-29 12:02:09,265 | INFO | [trial_007 | seed 29] elapsed_time 00:29:49, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 03.62±03.87, mean_exploration_ratio_over_100_episodes_from_training 0.0505±0.0059, mean_reward_over_100_episodes_from_eval 03.86±04.28
2025-12-29 12:03:00,641 | INFO | [trial_007 | seed 29] elapsed_time 00:30:40, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 03.90±04.17, mean_exploration_ratio_over_100_episodes_from_training 0.0507±0.0059, mean_reward_over_100_episodes_from_eval 04.21±04.69
2025-12-29 12:03:50,773 | INFO | [trial_007 | seed 29] elapsed_time 00:31:30, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 04.16±04.38, mean_exploration_ratio_over_100_episodes_from_training 0.0509±0.0060, mean_reward_over_100_episodes_from_eval 04.53±05.00
2025-12-29 12:04:40,933 | INFO | [trial_007 | seed 29] elapsed_time 00:32:21, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 04.42±04.61, mean_exploration_ratio_over_100_episodes_from_training 0.0514±0.0064, mean_reward_over_100_episodes_from_eval 04.84±05.28
2025-12-29 12:05:32,532 | INFO | [trial_007 | seed 29] elapsed_time 00:33:12, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.409999, episode_sum_max_abs_reward_per_step 39.409999, mean_reward_over_100_episodes_from_training 04.75±04.99, mean_exploration_ratio_over_100_episodes_from_training 0.0516±0.0066, mean_reward_over_100_episodes_from_eval 05.18±05.64
2025-12-29 12:06:22,864 | INFO | [trial_007 | seed 29] elapsed_time 00:34:02, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 05.06±05.30, mean_exploration_ratio_over_100_episodes_from_training 0.0521±0.0070, mean_reward_over_100_episodes_from_eval 05.42±05.75
2025-12-29 12:07:13,399 | INFO | [trial_007 | seed 29] elapsed_time 00:34:53, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 05.35±05.55, mean_exploration_ratio_over_100_episodes_from_training 0.0525±0.0074, mean_reward_over_100_episodes_from_eval 05.65±05.87
2025-12-29 12:08:03,841 | INFO | [trial_007 | seed 29] elapsed_time 00:35:43, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 05.65±05.79, mean_exploration_ratio_over_100_episodes_from_training 0.0527±0.0075, mean_reward_over_100_episodes_from_eval 05.94±06.08
2025-12-29 12:08:53,715 | INFO | [trial_007 | seed 29] elapsed_time 00:36:33, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 05.96±06.08, mean_exploration_ratio_over_100_episodes_from_training 0.0531±0.0078, mean_reward_over_100_episodes_from_eval 06.13±06.14
2025-12-29 12:09:45,178 | INFO | [trial_007 | seed 29] elapsed_time 00:37:25, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 06.25±06.29, mean_exploration_ratio_over_100_episodes_from_training 0.0535±0.0082, mean_reward_over_100_episodes_from_eval 06.30±06.17
2025-12-29 12:10:35,742 | INFO | [trial_007 | seed 29] elapsed_time 00:38:15, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 06.48±06.42, mean_exploration_ratio_over_100_episodes_from_training 0.0539±0.0085, mean_reward_over_100_episodes_from_eval 06.61±06.44
2025-12-29 12:11:26,393 | INFO | [trial_007 | seed 29] elapsed_time 00:39:06, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 06.72±06.55, mean_exploration_ratio_over_100_episodes_from_training 0.0541±0.0085, mean_reward_over_100_episodes_from_eval 06.85±06.57
2025-12-29 12:12:15,804 | INFO | [trial_007 | seed 29] elapsed_time 00:39:55, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 06.97±06.70, mean_exploration_ratio_over_100_episodes_from_training 0.0544±0.0086, mean_reward_over_100_episodes_from_eval 07.16±06.82
2025-12-29 12:13:09,056 | INFO | [trial_007 | seed 29] elapsed_time 00:40:49, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 07.20±06.81, mean_exploration_ratio_over_100_episodes_from_training 0.0547±0.0087, mean_reward_over_100_episodes_from_eval 07.36±06.90
2025-12-29 12:13:59,493 | INFO | [trial_007 | seed 29] elapsed_time 00:41:39, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 07.45±06.96, mean_exploration_ratio_over_100_episodes_from_training 0.0549±0.0088, mean_reward_over_100_episodes_from_eval 07.62±07.06
2025-12-29 12:14:49,113 | INFO | [trial_007 | seed 29] elapsed_time 00:42:29, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 07.71±07.12, mean_exploration_ratio_over_100_episodes_from_training 0.0551±0.0088, mean_reward_over_100_episodes_from_eval 07.81±07.12
2025-12-29 12:15:40,295 | INFO | [trial_007 | seed 29] elapsed_time 00:43:20, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 07.91±07.20, mean_exploration_ratio_over_100_episodes_from_training 0.0554±0.0089, mean_reward_over_100_episodes_from_eval 07.93±07.10
2025-12-29 12:16:31,279 | INFO | [trial_007 | seed 29] elapsed_time 00:44:11, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 08.13±07.29, mean_exploration_ratio_over_100_episodes_from_training 0.0556±0.0090, mean_reward_over_100_episodes_from_eval 08.17±07.23
2025-12-29 12:17:22,371 | INFO | [trial_007 | seed 29] elapsed_time 00:45:02, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 08.44±07.57, mean_exploration_ratio_over_100_episodes_from_training 0.0559±0.0092, mean_reward_over_100_episodes_from_eval 08.43±07.41
2025-12-29 12:18:12,806 | INFO | [trial_007 | seed 29] elapsed_time 00:45:52, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 08.67±07.68, mean_exploration_ratio_over_100_episodes_from_training 0.0562±0.0093, mean_reward_over_100_episodes_from_eval 08.67±07.54
2025-12-29 12:19:03,942 | INFO | [trial_007 | seed 29] elapsed_time 00:46:44, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 08.87±07.75, mean_exploration_ratio_over_100_episodes_from_training 0.0564±0.0094, mean_reward_over_100_episodes_from_eval 08.80±07.53
2025-12-29 12:19:53,972 | INFO | [trial_007 | seed 29] elapsed_time 00:47:34, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 09.10±07.87, mean_exploration_ratio_over_100_episodes_from_training 0.0567±0.0096, mean_reward_over_100_episodes_from_eval 08.99±07.60
2025-12-29 12:20:45,020 | INFO | [trial_007 | seed 29] elapsed_time 00:48:25, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 09.27±07.91, mean_exploration_ratio_over_100_episodes_from_training 0.0570±0.0097, mean_reward_over_100_episodes_from_eval 09.18±07.67
2025-12-29 12:21:35,636 | INFO | [trial_007 | seed 29] elapsed_time 00:49:15, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 09.48±07.99, mean_exploration_ratio_over_100_episodes_from_training 0.0571±0.0097, mean_reward_over_100_episodes_from_eval 09.41±07.79
2025-12-29 12:22:25,592 | INFO | [trial_007 | seed 29] elapsed_time 00:50:05, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 09.62±08.00, mean_exploration_ratio_over_100_episodes_from_training 0.0573±0.0097, mean_reward_over_100_episodes_from_eval 09.58±07.84
2025-12-29 12:23:15,615 | INFO | [trial_007 | seed 29] elapsed_time 00:50:55, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 09.89±08.19, mean_exploration_ratio_over_100_episodes_from_training 0.0576±0.0099, mean_reward_over_100_episodes_from_eval 09.76±07.89
2025-12-29 12:24:06,538 | INFO | [trial_007 | seed 29] elapsed_time 00:51:46, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 10.13±08.34, mean_exploration_ratio_over_100_episodes_from_training 0.0579±0.0101, mean_reward_over_100_episodes_from_eval 09.99±08.04
2025-12-29 12:24:57,292 | INFO | [trial_007 | seed 29] elapsed_time 00:52:37, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 10.34±08.43, mean_exploration_ratio_over_100_episodes_from_training 0.0582±0.0102, mean_reward_over_100_episodes_from_eval 10.28±08.29
2025-12-29 12:25:47,367 | INFO | [trial_007 | seed 29] elapsed_time 00:53:27, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 10.60±08.61, mean_exploration_ratio_over_100_episodes_from_training 0.0584±0.0102, mean_reward_over_100_episodes_from_eval 10.59±08.57
2025-12-29 12:26:38,884 | INFO | [trial_007 | seed 29] elapsed_time 00:54:19, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 10.76±08.64, mean_exploration_ratio_over_100_episodes_from_training 0.0586±0.0103, mean_reward_over_100_episodes_from_eval 10.80±08.66
2025-12-29 12:27:29,011 | INFO | [trial_007 | seed 29] elapsed_time 00:55:09, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 10.99±08.77, mean_exploration_ratio_over_100_episodes_from_training 0.0589±0.0105, mean_reward_over_100_episodes_from_eval 10.99±08.73
2025-12-29 12:28:18,642 | INFO | [trial_007 | seed 29] elapsed_time 00:55:58, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 11.17±08.82, mean_exploration_ratio_over_100_episodes_from_training 0.0590±0.0104, mean_reward_over_100_episodes_from_eval 11.14±08.74
2025-12-29 12:29:09,387 | INFO | [trial_007 | seed 29] elapsed_time 00:56:49, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 11.39±08.93, mean_exploration_ratio_over_100_episodes_from_training 0.0592±0.0105, mean_reward_over_100_episodes_from_eval 11.35±08.84
2025-12-29 12:30:00,422 | INFO | [trial_007 | seed 29] elapsed_time 00:57:40, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 11.61±09.05, mean_exploration_ratio_over_100_episodes_from_training 0.0594±0.0106, mean_reward_over_100_episodes_from_eval 11.41±08.79
2025-12-29 12:30:50,500 | INFO | [trial_007 | seed 29] elapsed_time 00:58:30, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 11.85±09.20, mean_exploration_ratio_over_100_episodes_from_training 0.0596±0.0106, mean_reward_over_100_episodes_from_eval 11.64±08.93
2025-12-29 12:31:40,964 | INFO | [trial_007 | seed 29] elapsed_time 00:59:21, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 12.10±09.36, mean_exploration_ratio_over_100_episodes_from_training 0.0598±0.0106, mean_reward_over_100_episodes_from_eval 11.89±09.10
2025-12-29 12:32:32,121 | INFO | [trial_007 | seed 29] elapsed_time 01:00:12, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 12.31±09.46, mean_exploration_ratio_over_100_episodes_from_training 0.0600±0.0106, mean_reward_over_100_episodes_from_eval 12.18±09.37
2025-12-29 12:33:23,243 | INFO | [trial_007 | seed 29] elapsed_time 01:01:03, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 12.52±09.56, mean_exploration_ratio_over_100_episodes_from_training 0.0602±0.0107, mean_reward_over_100_episodes_from_eval 12.45±09.58
2025-12-29 12:34:13,390 | INFO | [trial_007 | seed 29] elapsed_time 01:01:53, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 12.76±09.71, mean_exploration_ratio_over_100_episodes_from_training 0.0604±0.0108, mean_reward_over_100_episodes_from_eval 12.58±09.58
2025-12-29 12:35:03,936 | INFO | [trial_007 | seed 29] elapsed_time 01:02:44, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 12.98±09.83, mean_exploration_ratio_over_100_episodes_from_training 0.0604±0.0108, mean_reward_over_100_episodes_from_eval 12.78±09.66
2025-12-29 12:35:55,286 | INFO | [trial_007 | seed 29] elapsed_time 01:03:35, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 13.16±09.88, mean_exploration_ratio_over_100_episodes_from_training 0.0606±0.0109, mean_reward_over_100_episodes_from_eval 12.98±09.75
2025-12-29 12:36:45,945 | INFO | [trial_007 | seed 29] elapsed_time 01:04:26, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 13.35±09.96, mean_exploration_ratio_over_100_episodes_from_training 0.0608±0.0109, mean_reward_over_100_episodes_from_eval 13.20±09.87
2025-12-29 12:37:36,952 | INFO | [trial_007 | seed 29] elapsed_time 01:05:17, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 13.54±10.03, mean_exploration_ratio_over_100_episodes_from_training 0.0610±0.0109, mean_reward_over_100_episodes_from_eval 13.36±09.91
2025-12-29 12:38:26,971 | INFO | [trial_007 | seed 29] elapsed_time 01:06:07, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 13.76±10.16, mean_exploration_ratio_over_100_episodes_from_training 0.0611±0.0109, mean_reward_over_100_episodes_from_eval 13.62±10.09
2025-12-29 12:39:16,584 | INFO | [trial_007 | seed 29] elapsed_time 01:06:56, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 13.98±10.28, mean_exploration_ratio_over_100_episodes_from_training 0.0613±0.0110, mean_reward_over_100_episodes_from_eval 13.87±10.29
2025-12-29 12:40:07,894 | INFO | [trial_007 | seed 29] elapsed_time 01:07:48, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 14.22±10.42, mean_exploration_ratio_over_100_episodes_from_training 0.0614±0.0110, mean_reward_over_100_episodes_from_eval 14.12±10.45
2025-12-29 12:41:00,129 | INFO | [trial_007 | seed 29] elapsed_time 01:08:40, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 14.45±10.56, mean_exploration_ratio_over_100_episodes_from_training 0.0616±0.0110, mean_reward_over_100_episodes_from_eval 14.33±10.55
2025-12-29 12:41:50,039 | INFO | [trial_007 | seed 29] elapsed_time 01:09:30, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 14.63±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0618±0.0110, mean_reward_over_100_episodes_from_eval 14.54±10.67
2025-12-29 12:42:40,491 | INFO | [trial_007 | seed 29] elapsed_time 01:10:20, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 14.81±10.68, mean_exploration_ratio_over_100_episodes_from_training 0.0620±0.0111, mean_reward_over_100_episodes_from_eval 14.79±10.83
2025-12-29 12:43:31,299 | INFO | [trial_007 | seed 29] elapsed_time 01:11:11, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 15.01±10.77, mean_exploration_ratio_over_100_episodes_from_training 0.0621±0.0111, mean_reward_over_100_episodes_from_eval 14.98±10.91
2025-12-29 12:44:24,706 | INFO | [trial_007 | seed 29] elapsed_time 01:12:04, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 15.18±10.83, mean_exploration_ratio_over_100_episodes_from_training 0.0623±0.0111, mean_reward_over_100_episodes_from_eval 15.12±10.92
2025-12-29 12:45:15,994 | INFO | [trial_007 | seed 29] elapsed_time 01:12:56, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.479999, episode_sum_max_abs_reward_per_step 39.479999, mean_reward_over_100_episodes_from_training 15.30±10.82, mean_exploration_ratio_over_100_episodes_from_training 0.0624±0.0111, mean_reward_over_100_episodes_from_eval 15.19±10.87
2025-12-29 12:46:06,700 | INFO | [trial_007 | seed 29] elapsed_time 01:13:46, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 15.45±10.84, mean_exploration_ratio_over_100_episodes_from_training 0.0626±0.0112, mean_reward_over_100_episodes_from_eval 15.34±10.91
2025-12-29 12:46:58,405 | INFO | [trial_007 | seed 29] elapsed_time 01:14:38, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 15.60±10.88, mean_exploration_ratio_over_100_episodes_from_training 0.0627±0.0112, mean_reward_over_100_episodes_from_eval 15.53±10.99
2025-12-29 12:47:51,232 | INFO | [trial_007 | seed 29] elapsed_time 01:15:31, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 15.72±10.88, mean_exploration_ratio_over_100_episodes_from_training 0.0628±0.0112, mean_reward_over_100_episodes_from_eval 15.53±10.92
2025-12-29 12:48:43,469 | INFO | [trial_007 | seed 29] elapsed_time 01:16:23, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 15.89±10.92, mean_exploration_ratio_over_100_episodes_from_training 0.0630±0.0112, mean_reward_over_100_episodes_from_eval 15.73±11.02
2025-12-29 12:49:38,371 | INFO | [trial_007 | seed 29] elapsed_time 01:17:18, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 16.06±10.99, mean_exploration_ratio_over_100_episodes_from_training 0.0631±0.0112, mean_reward_over_100_episodes_from_eval 15.95±11.16
2025-12-29 12:50:31,805 | INFO | [trial_007 | seed 29] elapsed_time 01:18:11, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 16.24±11.05, mean_exploration_ratio_over_100_episodes_from_training 0.0633±0.0113, mean_reward_over_100_episodes_from_eval 16.16±11.27
2025-12-29 12:51:24,194 | INFO | [trial_007 | seed 29] elapsed_time 01:19:04, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 16.37±11.07, mean_exploration_ratio_over_100_episodes_from_training 0.0634±0.0113, mean_reward_over_100_episodes_from_eval 16.35±11.35
2025-12-29 12:52:17,244 | INFO | [trial_007 | seed 29] elapsed_time 01:19:57, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 16.51±11.09, mean_exploration_ratio_over_100_episodes_from_training 0.0635±0.0113, mean_reward_over_100_episodes_from_eval 16.49±11.37
2025-12-29 12:53:14,688 | INFO | [trial_007 | seed 29] elapsed_time 01:20:54, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 16.60±11.07, mean_exploration_ratio_over_100_episodes_from_training 0.0636±0.0113, mean_reward_over_100_episodes_from_eval 16.55±11.33
2025-12-29 12:54:08,325 | INFO | [trial_007 | seed 29] elapsed_time 01:21:48, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 16.74±11.09, mean_exploration_ratio_over_100_episodes_from_training 0.0637±0.0113, mean_reward_over_100_episodes_from_eval 16.74±11.42
2025-12-29 12:54:58,615 | INFO | [trial_007 | seed 29] elapsed_time 01:22:38, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 16.94±11.22, mean_exploration_ratio_over_100_episodes_from_training 0.0639±0.0113, mean_reward_over_100_episodes_from_eval 16.93±11.52
2025-12-29 12:55:48,837 | INFO | [trial_007 | seed 29] elapsed_time 01:23:28, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 17.13±11.31, mean_exploration_ratio_over_100_episodes_from_training 0.0640±0.0113, mean_reward_over_100_episodes_from_eval 17.13±11.63
2025-12-29 12:56:39,593 | INFO | [trial_007 | seed 29] elapsed_time 01:24:19, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 17.29±11.37, mean_exploration_ratio_over_100_episodes_from_training 0.0641±0.0113, mean_reward_over_100_episodes_from_eval 17.32±11.71
2025-12-29 12:57:30,207 | INFO | [trial_007 | seed 29] elapsed_time 01:25:10, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 17.47±11.45, mean_exploration_ratio_over_100_episodes_from_training 0.0642±0.0113, mean_reward_over_100_episodes_from_eval 17.44±11.72
2025-12-29 12:58:21,411 | INFO | [trial_007 | seed 29] elapsed_time 01:26:01, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 17.80±11.45, mean_exploration_ratio_over_100_episodes_from_training 0.0644±0.0114, mean_reward_over_100_episodes_from_eval 17.70±11.64
2025-12-29 12:59:11,810 | INFO | [trial_007 | seed 29] elapsed_time 01:26:51, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 18.13±11.42, mean_exploration_ratio_over_100_episodes_from_training 0.0646±0.0114, mean_reward_over_100_episodes_from_eval 18.02±11.59
2025-12-29 13:00:02,593 | INFO | [trial_007 | seed 29] elapsed_time 01:27:42, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 18.45±11.38, mean_exploration_ratio_over_100_episodes_from_training 0.0648±0.0114, mean_reward_over_100_episodes_from_eval 18.29±11.52
2025-12-29 13:00:53,703 | INFO | [trial_007 | seed 29] elapsed_time 01:28:33, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.71±11.29, mean_exploration_ratio_over_100_episodes_from_training 0.0650±0.0114, mean_reward_over_100_episodes_from_eval 18.63±11.48
2025-12-29 13:01:44,359 | INFO | [trial_007 | seed 29] elapsed_time 01:29:24, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 19.02±11.20, mean_exploration_ratio_over_100_episodes_from_training 0.0653±0.0112, mean_reward_over_100_episodes_from_eval 18.92±11.38
2025-12-29 13:02:45,943 | INFO | [trial_007 | seed 29] elapsed_time 01:30:26, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 19.35±11.11, mean_exploration_ratio_over_100_episodes_from_training 0.0656±0.0111, mean_reward_over_100_episodes_from_eval 19.25±11.30
2025-12-29 13:03:51,140 | INFO | [trial_007 | seed 29] elapsed_time 01:31:31, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 19.71±11.07, mean_exploration_ratio_over_100_episodes_from_training 0.0659±0.0109, mean_reward_over_100_episodes_from_eval 19.59±11.23
2025-12-29 13:04:54,797 | INFO | [trial_007 | seed 29] elapsed_time 01:32:34, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 20.04±10.97, mean_exploration_ratio_over_100_episodes_from_training 0.0662±0.0107, mean_reward_over_100_episodes_from_eval 19.86±11.08
2025-12-29 13:05:47,568 | INFO | [trial_007 | seed 29] elapsed_time 01:33:27, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 20.34±10.83, mean_exploration_ratio_over_100_episodes_from_training 0.0666±0.0104, mean_reward_over_100_episodes_from_eval 20.22±11.02
2025-12-29 13:06:38,660 | INFO | [trial_007 | seed 29] elapsed_time 01:34:18, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 20.69±10.74, mean_exploration_ratio_over_100_episodes_from_training 0.0669±0.0102, mean_reward_over_100_episodes_from_eval 20.57±10.95
2025-12-29 13:07:30,619 | INFO | [trial_007 | seed 29] elapsed_time 01:35:10, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 21.00±10.60, mean_exploration_ratio_over_100_episodes_from_training 0.0671±0.0100, mean_reward_over_100_episodes_from_eval 20.90±10.82
2025-12-29 13:08:21,011 | INFO | [trial_007 | seed 29] elapsed_time 01:36:01, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 21.32±10.47, mean_exploration_ratio_over_100_episodes_from_training 0.0675±0.0097, mean_reward_over_100_episodes_from_eval 21.13±10.64
2025-12-29 13:09:12,556 | INFO | [trial_007 | seed 29] elapsed_time 01:36:52, episode 0112, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 21.67±10.36, mean_exploration_ratio_over_100_episodes_from_training 0.0678±0.0095, mean_reward_over_100_episodes_from_eval 21.50±10.56
2025-12-29 13:10:08,595 | INFO | [trial_007 | seed 29] elapsed_time 01:37:48, episode 0113, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 22.03±10.26, mean_exploration_ratio_over_100_episodes_from_training 0.0681±0.0094, mean_reward_over_100_episodes_from_eval 21.85±10.47
2025-12-29 13:11:00,747 | INFO | [trial_007 | seed 29] elapsed_time 01:38:40, episode 0114, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 22.35±10.09, mean_exploration_ratio_over_100_episodes_from_training 0.0684±0.0092, mean_reward_over_100_episodes_from_eval 22.14±10.29
2025-12-29 13:11:49,762 | INFO | [trial_007 | seed 29] elapsed_time 01:39:29, episode 0115, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 22.69±09.94, mean_exploration_ratio_over_100_episodes_from_training 0.0687±0.0089, mean_reward_over_100_episodes_from_eval 22.47±10.14
2025-12-29 13:12:41,461 | INFO | [trial_007 | seed 29] elapsed_time 01:40:21, episode 0116, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 23.03±09.79, mean_exploration_ratio_over_100_episodes_from_training 0.0690±0.0087, mean_reward_over_100_episodes_from_eval 22.78±09.98
2025-12-29 13:13:34,996 | INFO | [trial_007 | seed 29] elapsed_time 01:41:15, episode 0117, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 23.36±09.64, mean_exploration_ratio_over_100_episodes_from_training 0.0693±0.0085, mean_reward_over_100_episodes_from_eval 23.09±09.82
2025-12-29 13:14:25,142 | INFO | [trial_007 | seed 29] elapsed_time 01:42:05, episode 0118, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 23.65±09.42, mean_exploration_ratio_over_100_episodes_from_training 0.0696±0.0083, mean_reward_over_100_episodes_from_eval 23.40±09.65
2025-12-29 13:15:16,763 | INFO | [trial_007 | seed 29] elapsed_time 01:42:56, episode 0119, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 23.98±09.23, mean_exploration_ratio_over_100_episodes_from_training 0.0699±0.0080, mean_reward_over_100_episodes_from_eval 23.69±09.44
2025-12-29 13:16:09,472 | INFO | [trial_007 | seed 29] elapsed_time 01:43:49, episode 0120, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 24.29±09.03, mean_exploration_ratio_over_100_episodes_from_training 0.0702±0.0078, mean_reward_over_100_episodes_from_eval 24.00±09.34
2025-12-29 13:17:00,960 | INFO | [trial_007 | seed 29] elapsed_time 01:44:41, episode 0121, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 24.61±08.86, mean_exploration_ratio_over_100_episodes_from_training 0.0705±0.0076, mean_reward_over_100_episodes_from_eval 24.24±09.10
2025-12-29 13:17:51,583 | INFO | [trial_007 | seed 29] elapsed_time 01:45:31, episode 0122, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 24.90±08.63, mean_exploration_ratio_over_100_episodes_from_training 0.0707±0.0073, mean_reward_over_100_episodes_from_eval 24.54±08.89
2025-12-29 13:18:42,524 | INFO | [trial_007 | seed 29] elapsed_time 01:46:22, episode 0123, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 25.11±08.38, mean_exploration_ratio_over_100_episodes_from_training 0.0710±0.0070, mean_reward_over_100_episodes_from_eval 24.72±08.65
2025-12-29 13:19:33,141 | INFO | [trial_007 | seed 29] elapsed_time 01:47:13, episode 0124, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 25.32±08.12, mean_exploration_ratio_over_100_episodes_from_training 0.0712±0.0067, mean_reward_over_100_episodes_from_eval 24.99±08.45
2025-12-29 13:20:22,936 | INFO | [trial_007 | seed 29] elapsed_time 01:48:03, episode 0125, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 25.62±07.92, mean_exploration_ratio_over_100_episodes_from_training 0.0715±0.0063, mean_reward_over_100_episodes_from_eval 25.21±08.19
2025-12-29 13:21:14,311 | INFO | [trial_007 | seed 29] elapsed_time 01:48:54, episode 0126, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 25.86±07.71, mean_exploration_ratio_over_100_episodes_from_training 0.0718±0.0061, mean_reward_over_100_episodes_from_eval 25.50±08.03
2025-12-29 13:22:04,494 | INFO | [trial_007 | seed 29] elapsed_time 01:49:44, episode 0127, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 26.10±07.45, mean_exploration_ratio_over_100_episodes_from_training 0.0720±0.0058, mean_reward_over_100_episodes_from_eval 25.80±07.89
2025-12-29 13:22:54,489 | INFO | [trial_007 | seed 29] elapsed_time 01:50:34, episode 0128, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 26.38±07.30, mean_exploration_ratio_over_100_episodes_from_training 0.0722±0.0057, mean_reward_over_100_episodes_from_eval 26.06±07.80
2025-12-29 13:23:45,166 | INFO | [trial_007 | seed 29] elapsed_time 01:51:25, episode 0129, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 26.63±07.12, mean_exploration_ratio_over_100_episodes_from_training 0.0724±0.0054, mean_reward_over_100_episodes_from_eval 26.31±07.67
2025-12-29 13:24:35,886 | INFO | [trial_007 | seed 29] elapsed_time 01:52:16, episode 0130, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.85±06.98, mean_exploration_ratio_over_100_episodes_from_training 0.0727±0.0053, mean_reward_over_100_episodes_from_eval 26.51±07.65
2025-12-29 13:25:26,085 | INFO | [trial_007 | seed 29] elapsed_time 01:53:06, episode 0131, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.04±06.83, mean_exploration_ratio_over_100_episodes_from_training 0.0729±0.0051, mean_reward_over_100_episodes_from_eval 26.64±07.52
2025-12-29 13:26:16,026 | INFO | [trial_007 | seed 29] elapsed_time 01:53:56, episode 0132, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.18±06.62, mean_exploration_ratio_over_100_episodes_from_training 0.0728±0.0051, mean_reward_over_100_episodes_from_eval 26.76±07.39
2025-12-29 13:27:07,487 | INFO | [trial_007 | seed 29] elapsed_time 01:54:47, episode 0133, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 27.39±06.43, mean_exploration_ratio_over_100_episodes_from_training 0.0730±0.0050, mean_reward_over_100_episodes_from_eval 26.96±07.23
2025-12-29 13:27:57,241 | INFO | [trial_007 | seed 29] elapsed_time 01:55:37, episode 0134, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.57±06.24, mean_exploration_ratio_over_100_episodes_from_training 0.0732±0.0048, mean_reward_over_100_episodes_from_eval 27.25±07.04
2025-12-29 13:28:49,178 | INFO | [trial_007 | seed 29] elapsed_time 01:56:29, episode 0135, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 27.79±06.14, mean_exploration_ratio_over_100_episodes_from_training 0.0733±0.0045, mean_reward_over_100_episodes_from_eval 27.39±06.96
2025-12-29 13:29:40,231 | INFO | [trial_007 | seed 29] elapsed_time 01:57:20, episode 0136, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 28.02±06.03, mean_exploration_ratio_over_100_episodes_from_training 0.0735±0.0043, mean_reward_over_100_episodes_from_eval 27.61±06.93
2025-12-29 13:30:31,676 | INFO | [trial_007 | seed 29] elapsed_time 01:58:11, episode 0137, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 28.25±05.93, mean_exploration_ratio_over_100_episodes_from_training 0.0736±0.0043, mean_reward_over_100_episodes_from_eval 27.80±06.88
2025-12-29 13:31:22,065 | INFO | [trial_007 | seed 29] elapsed_time 01:59:02, episode 0138, episode_env_steps 1001, episode_sum_max_reward_per_step 39.499999, episode_sum_max_abs_reward_per_step 39.499999, mean_reward_over_100_episodes_from_training 28.41±05.84, mean_exploration_ratio_over_100_episodes_from_training 0.0738±0.0041, mean_reward_over_100_episodes_from_eval 27.93±06.83
2025-12-29 13:32:12,516 | INFO | [trial_007 | seed 29] elapsed_time 01:59:52, episode 0139, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 28.58±05.77, mean_exploration_ratio_over_100_episodes_from_training 0.0738±0.0041, mean_reward_over_100_episodes_from_eval 28.14±06.73
2025-12-29 13:33:05,972 | INFO | [trial_007 | seed 29] elapsed_time 02:00:46, episode 0140, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.74±05.66, mean_exploration_ratio_over_100_episodes_from_training 0.0739±0.0040, mean_reward_over_100_episodes_from_eval 28.28±06.60
2025-12-29 13:33:56,247 | INFO | [trial_007 | seed 29] elapsed_time 02:01:36, episode 0141, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 28.82±05.56, mean_exploration_ratio_over_100_episodes_from_training 0.0740±0.0039, mean_reward_over_100_episodes_from_eval 28.45±06.55
2025-12-29 13:34:46,450 | INFO | [trial_007 | seed 29] elapsed_time 02:02:26, episode 0142, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 28.97±05.50, mean_exploration_ratio_over_100_episodes_from_training 0.0741±0.0039, mean_reward_over_100_episodes_from_eval 28.62±06.40
2025-12-29 13:35:38,259 | INFO | [trial_007 | seed 29] elapsed_time 02:03:18, episode 0143, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 29.12±05.41, mean_exploration_ratio_over_100_episodes_from_training 0.0742±0.0039, mean_reward_over_100_episodes_from_eval 28.74±06.22
2025-12-29 13:36:28,937 | INFO | [trial_007 | seed 29] elapsed_time 02:04:09, episode 0144, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.27±05.28, mean_exploration_ratio_over_100_episodes_from_training 0.0743±0.0039, mean_reward_over_100_episodes_from_eval 28.88±06.19
2025-12-29 13:37:19,197 | INFO | [trial_007 | seed 29] elapsed_time 02:04:59, episode 0145, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 29.37±05.15, mean_exploration_ratio_over_100_episodes_from_training 0.0744±0.0038, mean_reward_over_100_episodes_from_eval 28.94±06.11
2025-12-29 13:38:09,496 | INFO | [trial_007 | seed 29] elapsed_time 02:05:49, episode 0146, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.43±05.06, mean_exploration_ratio_over_100_episodes_from_training 0.0745±0.0037, mean_reward_over_100_episodes_from_eval 28.95±06.10
2025-12-29 13:39:00,500 | INFO | [trial_007 | seed 29] elapsed_time 02:06:40, episode 0147, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 29.51±04.94, mean_exploration_ratio_over_100_episodes_from_training 0.0746±0.0036, mean_reward_over_100_episodes_from_eval 28.88±06.26
2025-12-29 13:39:50,457 | INFO | [trial_007 | seed 29] elapsed_time 02:07:30, episode 0148, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 29.63±04.84, mean_exploration_ratio_over_100_episodes_from_training 0.0747±0.0035, mean_reward_over_100_episodes_from_eval 29.04±06.25
2025-12-29 13:40:40,735 | INFO | [trial_007 | seed 29] elapsed_time 02:08:20, episode 0149, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 29.77±04.77, mean_exploration_ratio_over_100_episodes_from_training 0.0748±0.0035, mean_reward_over_100_episodes_from_eval 29.22±06.16
2025-12-29 13:41:32,288 | INFO | [trial_007 | seed 29] elapsed_time 02:09:12, episode 0150, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 29.93±04.64, mean_exploration_ratio_over_100_episodes_from_training 0.0749±0.0034, mean_reward_over_100_episodes_from_eval 29.44±05.99
2025-12-29 13:42:21,816 | INFO | [trial_007 | seed 29] elapsed_time 02:10:01, episode 0151, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 30.08±04.53, mean_exploration_ratio_over_100_episodes_from_training 0.0750±0.0034, mean_reward_over_100_episodes_from_eval 29.58±05.94
2025-12-29 13:43:13,328 | INFO | [trial_007 | seed 29] elapsed_time 02:10:53, episode 0152, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 30.14±04.50, mean_exploration_ratio_over_100_episodes_from_training 0.0750±0.0033, mean_reward_over_100_episodes_from_eval 29.64±05.90
2025-12-29 13:44:04,835 | INFO | [trial_007 | seed 29] elapsed_time 02:11:44, episode 0153, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.24±04.40, mean_exploration_ratio_over_100_episodes_from_training 0.0751±0.0033, mean_reward_over_100_episodes_from_eval 29.72±05.83
2025-12-29 13:44:54,982 | INFO | [trial_007 | seed 29] elapsed_time 02:12:35, episode 0154, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.33±04.27, mean_exploration_ratio_over_100_episodes_from_training 0.0752±0.0033, mean_reward_over_100_episodes_from_eval 29.89±05.67
2025-12-29 13:45:46,150 | INFO | [trial_007 | seed 29] elapsed_time 02:13:26, episode 0155, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.39±04.19, mean_exploration_ratio_over_100_episodes_from_training 0.0752±0.0033, mean_reward_over_100_episodes_from_eval 29.97±05.57
2025-12-29 13:46:39,152 | INFO | [trial_007 | seed 29] Requirement met (evaluation metric): solved at episode 157 with mean_100_eval=30.10
2025-12-29 13:46:39,158 | INFO | [trial_007 | seed 29] elapsed_time 02:14:19, episode 0156, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 30.51±04.03, mean_exploration_ratio_over_100_episodes_from_training 0.0753±0.0033, mean_reward_over_100_episodes_from_eval 30.10±05.49
2025-12-29 13:46:39,159 | INFO | [trial_007 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 14:15:29,349 | INFO | [trial_007 | seed 29] Training complete.
2025-12-29 14:15:29,350 | INFO | [trial_007 | seed 29] Solved (evaluation metric) at episode 157.
2025-12-29 14:15:29,350 | INFO | [trial_007 | seed 29] Final evaluation score 31.50±1.33 in 5332.13s training, 9789.48s wall.
2025-12-29 14:15:29,350 | INFO | [trial_007 | seed 29] Closing UnityVectorEnv (worker_id=7029).
2025-12-29 14:15:29,350 | INFO | [Main] Requesting worker 7029 to close Unity env.
2025-12-29 14:15:31,050 | INFO | [Main] Worker 7029 joined. Unity env fully closed.
2025-12-29 14:15:31,050 | INFO | [trial_007 | seed 29] Final eval score: 31.50
2025-12-29 14:15:31,566 | INFO | [trial_007 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_007_seed_29.png
2025-12-29 14:15:31,568 | INFO | [trial_007 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 14:15:31,799 | INFO | [trial_007] Final scores across seeds: [31.503]
2025-12-29 14:15:31,799 | INFO | [trial_007] Avg=31.503 ± 0.000, Best seed score=31.503
2025-12-29 14:15:31,799 | INFO | [trial_008] Starting trial with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.2,"hidden_dims":[64,64],"lr":0.0001,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 14:15:31,799 | INFO | [trial_008 | seed 29] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.2,"hidden_dims":[64,64],"lr":0.0001,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 14:15:31,799 | INFO | [trial_008 | seed 29] === Starting run for seed 29 ===
2025-12-29 14:15:31,799 | INFO | [trial_008 | seed 29] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.2,"hidden_dims":[64,64],"lr":0.0001,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 14:15:31,799 | INFO | [trial_008 | seed 29] Launching UnityVectorEnv with worker_id=8029, seed=29
2025-12-29 14:15:31,799 | INFO | [Main] Spawning worker 8029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 14:15:31,837 | INFO | [Main] Worker 8029 started (pid=73568).
2025-12-29 14:15:39,007 | INFO | [trial_008 | seed 29] Environment batched agents (train): 20
2025-12-29 14:16:11,292 | INFO | [trial_008 | seed 29] Environment batched agents (eval): 20
2025-12-29 14:16:28,669 | INFO | [trial_008 | seed 29] elapsed_time 00:00:56, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 13.740000, episode_sum_max_abs_reward_per_step 13.740000, mean_reward_over_100_episodes_from_training 00.92±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0733±0.0000, mean_reward_over_100_episodes_from_eval 00.99±00.00
2025-12-29 14:17:20,869 | INFO | [trial_008 | seed 29] elapsed_time 00:01:49, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 13.630000, episode_sum_max_abs_reward_per_step 13.630000, mean_reward_over_100_episodes_from_training 00.88±00.03, mean_exploration_ratio_over_100_episodes_from_training 0.0681±0.0052, mean_reward_over_100_episodes_from_eval 00.83±00.16
2025-12-29 14:18:14,982 | INFO | [trial_008 | seed 29] elapsed_time 00:02:43, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 17.720000, episode_sum_max_abs_reward_per_step 17.720000, mean_reward_over_100_episodes_from_training 01.02±00.19, mean_exploration_ratio_over_100_episodes_from_training 0.0653±0.0057, mean_reward_over_100_episodes_from_eval 01.20±00.54
2025-12-29 14:19:09,554 | INFO | [trial_008 | seed 29] elapsed_time 00:03:37, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 24.499999, episode_sum_max_abs_reward_per_step 24.499999, mean_reward_over_100_episodes_from_training 01.24±00.42, mean_exploration_ratio_over_100_episodes_from_training 0.0639±0.0056, mean_reward_over_100_episodes_from_eval 01.25±00.47
2025-12-29 14:20:04,206 | INFO | [trial_008 | seed 29] elapsed_time 00:04:32, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 16.430000, episode_sum_max_abs_reward_per_step 16.430000, mean_reward_over_100_episodes_from_training 01.20±00.39, mean_exploration_ratio_over_100_episodes_from_training 0.0631±0.0052, mean_reward_over_100_episodes_from_eval 01.29±00.43
2025-12-29 14:21:00,201 | INFO | [trial_008 | seed 29] elapsed_time 00:05:28, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 17.360000, episode_sum_max_abs_reward_per_step 17.360000, mean_reward_over_100_episodes_from_training 01.19±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0619±0.0054, mean_reward_over_100_episodes_from_eval 01.17±00.48
2025-12-29 14:21:53,830 | INFO | [trial_008 | seed 29] elapsed_time 00:06:22, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 13.300000, episode_sum_max_abs_reward_per_step 13.300000, mean_reward_over_100_episodes_from_training 01.14±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0609±0.0056, mean_reward_over_100_episodes_from_eval 01.09±00.48
2025-12-29 14:22:48,245 | INFO | [trial_008 | seed 29] elapsed_time 00:07:16, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 11.790000, episode_sum_max_abs_reward_per_step 11.790000, mean_reward_over_100_episodes_from_training 01.09±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0599±0.0059, mean_reward_over_100_episodes_from_eval 01.10±00.44
2025-12-29 14:23:43,029 | INFO | [trial_008 | seed 29] elapsed_time 00:08:11, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 13.490000, episode_sum_max_abs_reward_per_step 13.490000, mean_reward_over_100_episodes_from_training 01.07±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0592±0.0059, mean_reward_over_100_episodes_from_eval 01.07±00.43
2025-12-29 14:24:38,337 | INFO | [trial_008 | seed 29] elapsed_time 00:09:06, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 11.940000, episode_sum_max_abs_reward_per_step 11.940000, mean_reward_over_100_episodes_from_training 01.03±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0589±0.0057, mean_reward_over_100_episodes_from_eval 01.05±00.41
2025-12-29 14:25:33,683 | INFO | [trial_008 | seed 29] elapsed_time 00:10:01, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 20.470000, episode_sum_max_abs_reward_per_step 20.470000, mean_reward_over_100_episodes_from_training 01.07±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0588±0.0054, mean_reward_over_100_episodes_from_eval 01.05±00.39
2025-12-29 14:26:29,487 | INFO | [trial_008 | seed 29] elapsed_time 00:10:57, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 20.930000, episode_sum_max_abs_reward_per_step 20.930000, mean_reward_over_100_episodes_from_training 01.11±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0580±0.0059, mean_reward_over_100_episodes_from_eval 01.09±00.40
2025-12-29 14:27:25,070 | INFO | [trial_008 | seed 29] elapsed_time 00:11:53, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 19.960000, episode_sum_max_abs_reward_per_step 19.960000, mean_reward_over_100_episodes_from_training 01.12±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0576±0.0058, mean_reward_over_100_episodes_from_eval 01.12±00.40
2025-12-29 14:28:20,974 | INFO | [trial_008 | seed 29] elapsed_time 00:12:49, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 24.839999, episode_sum_max_abs_reward_per_step 24.839999, mean_reward_over_100_episodes_from_training 01.18±00.39, mean_exploration_ratio_over_100_episodes_from_training 0.0574±0.0056, mean_reward_over_100_episodes_from_eval 01.17±00.42
2025-12-29 14:29:16,334 | INFO | [trial_008 | seed 29] elapsed_time 00:13:44, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 27.359999, episode_sum_max_abs_reward_per_step 27.359999, mean_reward_over_100_episodes_from_training 01.26±00.49, mean_exploration_ratio_over_100_episodes_from_training 0.0570±0.0056, mean_reward_over_100_episodes_from_eval 01.24±00.47
2025-12-29 14:30:11,580 | INFO | [trial_008 | seed 29] elapsed_time 00:14:39, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 26.169999, episode_sum_max_abs_reward_per_step 26.169999, mean_reward_over_100_episodes_from_training 01.32±00.52, mean_exploration_ratio_over_100_episodes_from_training 0.0567±0.0055, mean_reward_over_100_episodes_from_eval 01.31±00.54
2025-12-29 14:31:06,668 | INFO | [trial_008 | seed 29] elapsed_time 00:15:34, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 30.989999, episode_sum_max_abs_reward_per_step 30.989999, mean_reward_over_100_episodes_from_training 01.41±00.62, mean_exploration_ratio_over_100_episodes_from_training 0.0565±0.0055, mean_reward_over_100_episodes_from_eval 01.41±00.66
2025-12-29 14:32:01,888 | INFO | [trial_008 | seed 29] elapsed_time 00:16:30, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 30.759999, episode_sum_max_abs_reward_per_step 30.759999, mean_reward_over_100_episodes_from_training 01.48±00.68, mean_exploration_ratio_over_100_episodes_from_training 0.0563±0.0054, mean_reward_over_100_episodes_from_eval 01.49±00.71
2025-12-29 14:32:56,537 | INFO | [trial_008 | seed 29] elapsed_time 00:17:24, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 31.619999, episode_sum_max_abs_reward_per_step 31.619999, mean_reward_over_100_episodes_from_training 01.56±00.75, mean_exploration_ratio_over_100_episodes_from_training 0.0561±0.0053, mean_reward_over_100_episodes_from_eval 01.58±00.79
2025-12-29 14:33:53,846 | INFO | [trial_008 | seed 29] elapsed_time 00:18:22, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 33.659999, episode_sum_max_abs_reward_per_step 33.659999, mean_reward_over_100_episodes_from_training 01.65±00.83, mean_exploration_ratio_over_100_episodes_from_training 0.0560±0.0052, mean_reward_over_100_episodes_from_eval 01.71±00.97
2025-12-29 14:34:48,884 | INFO | [trial_008 | seed 29] elapsed_time 00:19:17, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 33.339999, episode_sum_max_abs_reward_per_step 33.339999, mean_reward_over_100_episodes_from_training 01.73±00.88, mean_exploration_ratio_over_100_episodes_from_training 0.0559±0.0051, mean_reward_over_100_episodes_from_eval 01.85±01.13
2025-12-29 14:35:45,840 | INFO | [trial_008 | seed 29] elapsed_time 00:20:14, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 34.639999, episode_sum_max_abs_reward_per_step 34.639999, mean_reward_over_100_episodes_from_training 01.83±00.98, mean_exploration_ratio_over_100_episodes_from_training 0.0558±0.0050, mean_reward_over_100_episodes_from_eval 01.99±01.28
2025-12-29 14:36:41,477 | INFO | [trial_008 | seed 29] elapsed_time 00:21:09, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 34.859999, episode_sum_max_abs_reward_per_step 34.859999, mean_reward_over_100_episodes_from_training 01.92±01.04, mean_exploration_ratio_over_100_episodes_from_training 0.0557±0.0049, mean_reward_over_100_episodes_from_eval 02.08±01.32
2025-12-29 14:37:36,201 | INFO | [trial_008 | seed 29] elapsed_time 00:22:04, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 37.279999, episode_sum_max_abs_reward_per_step 37.279999, mean_reward_over_100_episodes_from_training 02.07±01.24, mean_exploration_ratio_over_100_episodes_from_training 0.0556±0.0048, mean_reward_over_100_episodes_from_eval 02.23±01.48
2025-12-29 14:38:30,761 | INFO | [trial_008 | seed 29] elapsed_time 00:22:58, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.159999, episode_sum_max_abs_reward_per_step 39.159999, mean_reward_over_100_episodes_from_training 02.24±01.48, mean_exploration_ratio_over_100_episodes_from_training 0.0556±0.0047, mean_reward_over_100_episodes_from_eval 02.41±01.70
2025-12-29 14:39:25,175 | INFO | [trial_008 | seed 29] elapsed_time 00:23:53, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 38.929999, episode_sum_max_abs_reward_per_step 38.929999, mean_reward_over_100_episodes_from_training 02.40±01.64, mean_exploration_ratio_over_100_episodes_from_training 0.0555±0.0047, mean_reward_over_100_episodes_from_eval 02.61±01.93
2025-12-29 14:40:20,381 | INFO | [trial_008 | seed 29] elapsed_time 00:24:48, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 38.589999, episode_sum_max_abs_reward_per_step 38.589999, mean_reward_over_100_episodes_from_training 02.55±01.80, mean_exploration_ratio_over_100_episodes_from_training 0.0554±0.0046, mean_reward_over_100_episodes_from_eval 02.84±02.24
2025-12-29 14:41:15,982 | INFO | [trial_008 | seed 29] elapsed_time 00:25:44, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 38.459999, episode_sum_max_abs_reward_per_step 38.459999, mean_reward_over_100_episodes_from_training 02.72±01.97, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0045, mean_reward_over_100_episodes_from_eval 03.04±02.42
2025-12-29 14:42:10,592 | INFO | [trial_008 | seed 29] elapsed_time 00:26:38, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 38.729999, episode_sum_max_abs_reward_per_step 38.729999, mean_reward_over_100_episodes_from_training 02.88±02.11, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0044, mean_reward_over_100_episodes_from_eval 03.23±02.58
2025-12-29 14:43:05,122 | INFO | [trial_008 | seed 29] elapsed_time 00:27:33, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.079999, episode_sum_max_abs_reward_per_step 39.079999, mean_reward_over_100_episodes_from_training 03.07±02.33, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0044, mean_reward_over_100_episodes_from_eval 03.45±02.80
2025-12-29 14:44:00,016 | INFO | [trial_008 | seed 29] elapsed_time 00:28:28, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.409999, episode_sum_max_abs_reward_per_step 39.409999, mean_reward_over_100_episodes_from_training 03.31±02.63, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0043, mean_reward_over_100_episodes_from_eval 03.68±03.03
2025-12-29 14:44:54,146 | INFO | [trial_008 | seed 29] elapsed_time 00:29:22, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 03.53±02.87, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0042, mean_reward_over_100_episodes_from_eval 03.88±03.18
2025-12-29 14:45:48,845 | INFO | [trial_008 | seed 29] elapsed_time 00:30:17, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.169999, episode_sum_max_abs_reward_per_step 39.169999, mean_reward_over_100_episodes_from_training 03.71±03.00, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0042, mean_reward_over_100_episodes_from_eval 04.03±03.26
2025-12-29 14:46:44,124 | INFO | [trial_008 | seed 29] elapsed_time 00:31:12, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.359999, episode_sum_max_abs_reward_per_step 39.359999, mean_reward_over_100_episodes_from_training 03.89±03.13, mean_exploration_ratio_over_100_episodes_from_training 0.0552±0.0041, mean_reward_over_100_episodes_from_eval 04.19±03.34
2025-12-29 14:47:39,138 | INFO | [trial_008 | seed 29] elapsed_time 00:32:07, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.529999, episode_sum_max_abs_reward_per_step 39.529999, mean_reward_over_100_episodes_from_training 04.05±03.22, mean_exploration_ratio_over_100_episodes_from_training 0.0551±0.0041, mean_reward_over_100_episodes_from_eval 04.35±03.41
2025-12-29 14:48:34,696 | INFO | [trial_008 | seed 29] elapsed_time 00:33:02, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.329999, episode_sum_max_abs_reward_per_step 39.329999, mean_reward_over_100_episodes_from_training 04.22±03.33, mean_exploration_ratio_over_100_episodes_from_training 0.0551±0.0041, mean_reward_over_100_episodes_from_eval 04.47±03.44
2025-12-29 14:49:31,438 | INFO | [trial_008 | seed 29] elapsed_time 00:33:59, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.369999, episode_sum_max_abs_reward_per_step 39.369999, mean_reward_over_100_episodes_from_training 04.37±03.40, mean_exploration_ratio_over_100_episodes_from_training 0.0551±0.0040, mean_reward_over_100_episodes_from_eval 04.62±03.51
2025-12-29 14:50:27,077 | INFO | [trial_008 | seed 29] elapsed_time 00:34:55, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.449999, episode_sum_max_abs_reward_per_step 39.449999, mean_reward_over_100_episodes_from_training 04.53±03.51, mean_exploration_ratio_over_100_episodes_from_training 0.0551±0.0040, mean_reward_over_100_episodes_from_eval 04.77±03.59
2025-12-29 14:51:25,686 | INFO | [trial_008 | seed 29] elapsed_time 00:35:53, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.229999, episode_sum_max_abs_reward_per_step 39.229999, mean_reward_over_100_episodes_from_training 04.66±03.54, mean_exploration_ratio_over_100_episodes_from_training 0.0551±0.0039, mean_reward_over_100_episodes_from_eval 04.95±03.70
2025-12-29 14:52:23,542 | INFO | [trial_008 | seed 29] elapsed_time 00:36:51, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 04.80±03.61, mean_exploration_ratio_over_100_episodes_from_training 0.0552±0.0039, mean_reward_over_100_episodes_from_eval 05.09±03.75
2025-12-29 14:53:23,492 | INFO | [trial_008 | seed 29] elapsed_time 00:37:51, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.439999, episode_sum_max_abs_reward_per_step 39.439999, mean_reward_over_100_episodes_from_training 04.93±03.66, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0039, mean_reward_over_100_episodes_from_eval 05.27±03.89
2025-12-29 14:54:21,093 | INFO | [trial_008 | seed 29] elapsed_time 00:38:49, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 05.11±03.80, mean_exploration_ratio_over_100_episodes_from_training 0.0553±0.0039, mean_reward_over_100_episodes_from_eval 05.45±04.00
2025-12-29 14:55:19,053 | INFO | [trial_008 | seed 29] elapsed_time 00:39:47, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.439999, episode_sum_max_abs_reward_per_step 39.439999, mean_reward_over_100_episodes_from_training 05.25±03.87, mean_exploration_ratio_over_100_episodes_from_training 0.0554±0.0038, mean_reward_over_100_episodes_from_eval 05.61±04.09
2025-12-29 14:56:17,132 | INFO | [trial_008 | seed 29] elapsed_time 00:40:45, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 05.44±04.02, mean_exploration_ratio_over_100_episodes_from_training 0.0555±0.0039, mean_reward_over_100_episodes_from_eval 05.77±04.18
2025-12-29 14:57:11,810 | INFO | [trial_008 | seed 29] elapsed_time 00:41:40, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 05.66±04.24, mean_exploration_ratio_over_100_episodes_from_training 0.0556±0.0039, mean_reward_over_100_episodes_from_eval 05.96±04.33
2025-12-29 14:58:07,234 | INFO | [trial_008 | seed 29] elapsed_time 00:42:35, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 05.90±04.48, mean_exploration_ratio_over_100_episodes_from_training 0.0556±0.0039, mean_reward_over_100_episodes_from_eval 06.27±04.76
2025-12-29 14:59:02,195 | INFO | [trial_008 | seed 29] elapsed_time 00:43:30, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 06.30±05.20, mean_exploration_ratio_over_100_episodes_from_training 0.0558±0.0040, mean_reward_over_100_episodes_from_eval 06.69±05.50
2025-12-29 14:59:56,466 | INFO | [trial_008 | seed 29] elapsed_time 00:44:24, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 06.70±05.84, mean_exploration_ratio_over_100_episodes_from_training 0.0561±0.0044, mean_reward_over_100_episodes_from_eval 07.25±06.64
2025-12-29 15:00:51,420 | INFO | [trial_008 | seed 29] elapsed_time 00:45:19, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 07.20±06.71, mean_exploration_ratio_over_100_episodes_from_training 0.0562±0.0045, mean_reward_over_100_episodes_from_eval 07.68±07.22
2025-12-29 15:01:47,301 | INFO | [trial_008 | seed 29] elapsed_time 00:46:15, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 07.69±07.48, mean_exploration_ratio_over_100_episodes_from_training 0.0565±0.0048, mean_reward_over_100_episodes_from_eval 08.14±07.85
2025-12-29 15:02:42,648 | INFO | [trial_008 | seed 29] elapsed_time 00:47:10, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 08.20±08.24, mean_exploration_ratio_over_100_episodes_from_training 0.0567±0.0050, mean_reward_over_100_episodes_from_eval 08.63±08.49
2025-12-29 15:03:38,978 | INFO | [trial_008 | seed 29] elapsed_time 00:48:07, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 08.64±08.76, mean_exploration_ratio_over_100_episodes_from_training 0.0569±0.0051, mean_reward_over_100_episodes_from_eval 09.07±08.98
2025-12-29 15:04:33,773 | INFO | [trial_008 | seed 29] elapsed_time 00:49:01, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 09.13±09.36, mean_exploration_ratio_over_100_episodes_from_training 0.0571±0.0053, mean_reward_over_100_episodes_from_eval 09.45±09.31
2025-12-29 15:05:28,908 | INFO | [trial_008 | seed 29] elapsed_time 00:49:57, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 09.58±09.84, mean_exploration_ratio_over_100_episodes_from_training 0.0573±0.0054, mean_reward_over_100_episodes_from_eval 09.81±09.60
2025-12-29 15:06:23,422 | INFO | [trial_008 | seed 29] elapsed_time 00:50:51, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 10.03±10.29, mean_exploration_ratio_over_100_episodes_from_training 0.0575±0.0057, mean_reward_over_100_episodes_from_eval 10.07±09.70
2025-12-29 15:07:18,902 | INFO | [trial_008 | seed 29] elapsed_time 00:51:47, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 10.43±10.61, mean_exploration_ratio_over_100_episodes_from_training 0.0578±0.0059, mean_reward_over_100_episodes_from_eval 10.51±10.15
2025-12-29 15:08:13,547 | INFO | [trial_008 | seed 29] elapsed_time 00:52:41, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 10.81±10.91, mean_exploration_ratio_over_100_episodes_from_training 0.0581±0.0062, mean_reward_over_100_episodes_from_eval 10.82±10.31
2025-12-29 15:09:08,404 | INFO | [trial_008 | seed 29] elapsed_time 00:53:36, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 11.09±11.02, mean_exploration_ratio_over_100_episodes_from_training 0.0582±0.0062, mean_reward_over_100_episodes_from_eval 11.05±10.38
2025-12-29 15:10:03,885 | INFO | [trial_008 | seed 29] elapsed_time 00:54:32, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 11.42±11.20, mean_exploration_ratio_over_100_episodes_from_training 0.0584±0.0063, mean_reward_over_100_episodes_from_eval 11.34±10.52
2025-12-29 15:10:59,287 | INFO | [trial_008 | seed 29] elapsed_time 00:55:27, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 11.73±11.37, mean_exploration_ratio_over_100_episodes_from_training 0.0586±0.0066, mean_reward_over_100_episodes_from_eval 11.61±10.64
2025-12-29 15:11:59,483 | INFO | [trial_008 | seed 29] elapsed_time 00:56:27, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 12.01±11.47, mean_exploration_ratio_over_100_episodes_from_training 0.0588±0.0067, mean_reward_over_100_episodes_from_eval 11.85±10.72
2025-12-29 15:12:55,116 | INFO | [trial_008 | seed 29] elapsed_time 00:57:23, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.489999, episode_sum_max_abs_reward_per_step 39.489999, mean_reward_over_100_episodes_from_training 12.28±11.58, mean_exploration_ratio_over_100_episodes_from_training 0.0591±0.0069, mean_reward_over_100_episodes_from_eval 12.19±10.95
2025-12-29 15:13:52,159 | INFO | [trial_008 | seed 29] elapsed_time 00:58:20, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 12.69±11.92, mean_exploration_ratio_over_100_episodes_from_training 0.0593±0.0071, mean_reward_over_100_episodes_from_eval 12.57±11.27
2025-12-29 15:14:47,585 | INFO | [trial_008 | seed 29] elapsed_time 00:59:15, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 13.08±12.23, mean_exploration_ratio_over_100_episodes_from_training 0.0595±0.0072, mean_reward_over_100_episodes_from_eval 12.97±11.63
2025-12-29 15:15:43,285 | INFO | [trial_008 | seed 29] elapsed_time 01:00:11, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.379999, episode_sum_max_abs_reward_per_step 39.379999, mean_reward_over_100_episodes_from_training 13.45±12.49, mean_exploration_ratio_over_100_episodes_from_training 0.0597±0.0074, mean_reward_over_100_episodes_from_eval 13.31±11.86
2025-12-29 15:16:39,909 | INFO | [trial_008 | seed 29] elapsed_time 01:01:08, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 13.76±12.65, mean_exploration_ratio_over_100_episodes_from_training 0.0599±0.0075, mean_reward_over_100_episodes_from_eval 13.63±12.04
2025-12-29 15:17:35,478 | INFO | [trial_008 | seed 29] elapsed_time 01:02:03, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 14.11±12.87, mean_exploration_ratio_over_100_episodes_from_training 0.0601±0.0075, mean_reward_over_100_episodes_from_eval 13.94±12.20
2025-12-29 15:18:31,645 | INFO | [trial_008 | seed 29] elapsed_time 01:02:59, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 14.44±13.07, mean_exploration_ratio_over_100_episodes_from_training 0.0603±0.0076, mean_reward_over_100_episodes_from_eval 14.30±12.47
2025-12-29 15:19:26,323 | INFO | [trial_008 | seed 29] elapsed_time 01:03:54, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 14.78±13.27, mean_exploration_ratio_over_100_episodes_from_training 0.0604±0.0077, mean_reward_over_100_episodes_from_eval 14.62±12.66
2025-12-29 15:20:21,886 | INFO | [trial_008 | seed 29] elapsed_time 01:04:50, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 15.09±13.42, mean_exploration_ratio_over_100_episodes_from_training 0.0605±0.0077, mean_reward_over_100_episodes_from_eval 14.94±12.85
2025-12-29 15:21:17,209 | INFO | [trial_008 | seed 29] elapsed_time 01:05:45, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 15.40±13.58, mean_exploration_ratio_over_100_episodes_from_training 0.0607±0.0078, mean_reward_over_100_episodes_from_eval 15.26±13.04
2025-12-29 15:22:13,019 | INFO | [trial_008 | seed 29] elapsed_time 01:06:41, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 15.70±13.71, mean_exploration_ratio_over_100_episodes_from_training 0.0609±0.0078, mean_reward_over_100_episodes_from_eval 15.56±13.19
2025-12-29 15:23:08,447 | INFO | [trial_008 | seed 29] elapsed_time 01:07:36, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 15.99±13.84, mean_exploration_ratio_over_100_episodes_from_training 0.0610±0.0079, mean_reward_over_100_episodes_from_eval 15.81±13.28
2025-12-29 15:24:03,816 | INFO | [trial_008 | seed 29] elapsed_time 01:08:32, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 16.27±13.95, mean_exploration_ratio_over_100_episodes_from_training 0.0612±0.0079, mean_reward_over_100_episodes_from_eval 16.10±13.41
2025-12-29 15:25:00,836 | INFO | [trial_008 | seed 29] elapsed_time 01:09:29, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 16.55±14.07, mean_exploration_ratio_over_100_episodes_from_training 0.0613±0.0080, mean_reward_over_100_episodes_from_eval 16.35±13.50
2025-12-29 15:25:56,094 | INFO | [trial_008 | seed 29] elapsed_time 01:10:24, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 16.81±14.16, mean_exploration_ratio_over_100_episodes_from_training 0.0615±0.0081, mean_reward_over_100_episodes_from_eval 16.61±13.59
2025-12-29 15:26:52,047 | INFO | [trial_008 | seed 29] elapsed_time 01:11:20, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 17.07±14.25, mean_exploration_ratio_over_100_episodes_from_training 0.0617±0.0081, mean_reward_over_100_episodes_from_eval 16.86±13.68
2025-12-29 15:27:46,680 | INFO | [trial_008 | seed 29] elapsed_time 01:12:14, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 17.32±14.32, mean_exploration_ratio_over_100_episodes_from_training 0.0618±0.0082, mean_reward_over_100_episodes_from_eval 17.09±13.75
2025-12-29 15:28:42,416 | INFO | [trial_008 | seed 29] elapsed_time 01:13:10, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 17.55±14.38, mean_exploration_ratio_over_100_episodes_from_training 0.0619±0.0082, mean_reward_over_100_episodes_from_eval 17.31±13.80
2025-12-29 15:29:37,669 | INFO | [trial_008 | seed 29] elapsed_time 01:14:05, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 17.74±14.38, mean_exploration_ratio_over_100_episodes_from_training 0.0620±0.0082, mean_reward_over_100_episodes_from_eval 17.44±13.76
2025-12-29 15:30:32,274 | INFO | [trial_008 | seed 29] elapsed_time 01:15:00, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 17.91±14.38, mean_exploration_ratio_over_100_episodes_from_training 0.0622±0.0083, mean_reward_over_100_episodes_from_eval 17.67±13.82
2025-12-29 15:31:26,813 | INFO | [trial_008 | seed 29] elapsed_time 01:15:55, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 18.15±14.46, mean_exploration_ratio_over_100_episodes_from_training 0.0623±0.0083, mean_reward_over_100_episodes_from_eval 17.90±13.89
2025-12-29 15:32:21,706 | INFO | [trial_008 | seed 29] elapsed_time 01:16:49, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 18.38±14.52, mean_exploration_ratio_over_100_episodes_from_training 0.0625±0.0084, mean_reward_over_100_episodes_from_eval 18.15±13.99
2025-12-29 15:33:19,024 | INFO | [trial_008 | seed 29] elapsed_time 01:17:47, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 18.60±14.56, mean_exploration_ratio_over_100_episodes_from_training 0.0626±0.0085, mean_reward_over_100_episodes_from_eval 18.38±14.06
2025-12-29 15:34:14,694 | INFO | [trial_008 | seed 29] elapsed_time 01:18:42, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 18.79±14.58, mean_exploration_ratio_over_100_episodes_from_training 0.0628±0.0085, mean_reward_over_100_episodes_from_eval 18.52±14.04
2025-12-29 15:35:10,335 | INFO | [trial_008 | seed 29] elapsed_time 01:19:38, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 18.98±14.61, mean_exploration_ratio_over_100_episodes_from_training 0.0629±0.0086, mean_reward_over_100_episodes_from_eval 18.72±14.08
2025-12-29 15:36:05,797 | INFO | [trial_008 | seed 29] elapsed_time 01:20:33, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 19.19±14.65, mean_exploration_ratio_over_100_episodes_from_training 0.0631±0.0086, mean_reward_over_100_episodes_from_eval 18.93±14.13
2025-12-29 15:37:01,729 | INFO | [trial_008 | seed 29] elapsed_time 01:21:29, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 19.40±14.69, mean_exploration_ratio_over_100_episodes_from_training 0.0632±0.0087, mean_reward_over_100_episodes_from_eval 19.13±14.17
2025-12-29 15:37:56,208 | INFO | [trial_008 | seed 29] elapsed_time 01:22:24, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 19.58±14.71, mean_exploration_ratio_over_100_episodes_from_training 0.0634±0.0088, mean_reward_over_100_episodes_from_eval 19.33±14.22
2025-12-29 15:38:50,819 | INFO | [trial_008 | seed 29] elapsed_time 01:23:19, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 19.78±14.75, mean_exploration_ratio_over_100_episodes_from_training 0.0635±0.0088, mean_reward_over_100_episodes_from_eval 19.53±14.27
2025-12-29 15:39:46,849 | INFO | [trial_008 | seed 29] elapsed_time 01:24:15, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 19.95±14.75, mean_exploration_ratio_over_100_episodes_from_training 0.0636±0.0088, mean_reward_over_100_episodes_from_eval 19.72±14.30
2025-12-29 15:40:41,989 | INFO | [trial_008 | seed 29] elapsed_time 01:25:10, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.10±14.75, mean_exploration_ratio_over_100_episodes_from_training 0.0637±0.0088, mean_reward_over_100_episodes_from_eval 19.92±14.36
2025-12-29 15:41:38,033 | INFO | [trial_008 | seed 29] elapsed_time 01:26:06, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 20.28±14.77, mean_exploration_ratio_over_100_episodes_from_training 0.0638±0.0089, mean_reward_over_100_episodes_from_eval 20.10±14.38
2025-12-29 15:42:35,205 | INFO | [trial_008 | seed 29] elapsed_time 01:27:03, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 20.46±14.79, mean_exploration_ratio_over_100_episodes_from_training 0.0639±0.0089, mean_reward_over_100_episodes_from_eval 20.28±14.41
2025-12-29 15:43:30,651 | INFO | [trial_008 | seed 29] elapsed_time 01:27:58, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 20.60±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0641±0.0089, mean_reward_over_100_episodes_from_eval 20.46±14.44
2025-12-29 15:44:25,621 | INFO | [trial_008 | seed 29] elapsed_time 01:28:53, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 20.76±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0641±0.0089, mean_reward_over_100_episodes_from_eval 20.63±14.45
2025-12-29 15:45:20,932 | INFO | [trial_008 | seed 29] elapsed_time 01:29:49, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.92±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0643±0.0090, mean_reward_over_100_episodes_from_eval 20.81±14.49
2025-12-29 15:46:16,036 | INFO | [trial_008 | seed 29] elapsed_time 01:30:44, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 21.06±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0644±0.0090, mean_reward_over_100_episodes_from_eval 20.95±14.48
2025-12-29 15:47:11,503 | INFO | [trial_008 | seed 29] elapsed_time 01:31:39, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.379999, episode_sum_max_abs_reward_per_step 39.379999, mean_reward_over_100_episodes_from_training 21.20±14.77, mean_exploration_ratio_over_100_episodes_from_training 0.0644±0.0089, mean_reward_over_100_episodes_from_eval 21.03±14.43
2025-12-29 15:48:06,573 | INFO | [trial_008 | seed 29] elapsed_time 01:32:34, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 21.34±14.76, mean_exploration_ratio_over_100_episodes_from_training 0.0645±0.0089, mean_reward_over_100_episodes_from_eval 21.19±14.44
2025-12-29 15:49:02,159 | INFO | [trial_008 | seed 29] elapsed_time 01:33:30, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 21.71±14.71, mean_exploration_ratio_over_100_episodes_from_training 0.0645±0.0089, mean_reward_over_100_episodes_from_eval 21.56±14.39
2025-12-29 15:49:56,673 | INFO | [trial_008 | seed 29] elapsed_time 01:34:24, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 22.08±14.64, mean_exploration_ratio_over_100_episodes_from_training 0.0646±0.0089, mean_reward_over_100_episodes_from_eval 21.91±14.32
2025-12-29 15:50:54,842 | INFO | [trial_008 | seed 29] elapsed_time 01:35:23, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.509999, episode_sum_max_abs_reward_per_step 39.509999, mean_reward_over_100_episodes_from_training 22.44±14.57, mean_exploration_ratio_over_100_episodes_from_training 0.0647±0.0090, mean_reward_over_100_episodes_from_eval 22.26±14.24
2025-12-29 15:51:50,932 | INFO | [trial_008 | seed 29] elapsed_time 01:36:19, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 22.79±14.49, mean_exploration_ratio_over_100_episodes_from_training 0.0649±0.0090, mean_reward_over_100_episodes_from_eval 22.59±14.14
2025-12-29 15:52:50,888 | INFO | [trial_008 | seed 29] elapsed_time 01:37:19, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 23.13±14.37, mean_exploration_ratio_over_100_episodes_from_training 0.0650±0.0090, mean_reward_over_100_episodes_from_eval 22.93±14.04
2025-12-29 15:53:51,461 | INFO | [trial_008 | seed 29] elapsed_time 01:38:19, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.46±14.24, mean_exploration_ratio_over_100_episodes_from_training 0.0652±0.0090, mean_reward_over_100_episodes_from_eval 23.30±13.93
2025-12-29 15:54:49,249 | INFO | [trial_008 | seed 29] elapsed_time 01:39:17, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 23.83±14.13, mean_exploration_ratio_over_100_episodes_from_training 0.0653±0.0090, mean_reward_over_100_episodes_from_eval 23.65±13.79
2025-12-29 15:55:47,467 | INFO | [trial_008 | seed 29] elapsed_time 01:40:15, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 24.19±14.00, mean_exploration_ratio_over_100_episodes_from_training 0.0655±0.0089, mean_reward_over_100_episodes_from_eval 24.01±13.67
2025-12-29 15:56:45,134 | INFO | [trial_008 | seed 29] elapsed_time 01:41:13, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 24.55±13.85, mean_exploration_ratio_over_100_episodes_from_training 0.0657±0.0089, mean_reward_over_100_episodes_from_eval 24.37±13.53
2025-12-29 15:57:52,925 | INFO | [trial_008 | seed 29] elapsed_time 01:42:21, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 24.91±13.70, mean_exploration_ratio_over_100_episodes_from_training 0.0659±0.0089, mean_reward_over_100_episodes_from_eval 24.73±13.38
2025-12-29 15:58:58,405 | INFO | [trial_008 | seed 29] elapsed_time 01:43:26, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 25.25±13.53, mean_exploration_ratio_over_100_episodes_from_training 0.0661±0.0089, mean_reward_over_100_episodes_from_eval 25.08±13.21
2025-12-29 15:59:55,421 | INFO | [trial_008 | seed 29] elapsed_time 01:44:23, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 25.59±13.35, mean_exploration_ratio_over_100_episodes_from_training 0.0663±0.0087, mean_reward_over_100_episodes_from_eval 25.40±13.02
2025-12-29 16:00:52,690 | INFO | [trial_008 | seed 29] elapsed_time 01:45:20, episode 0112, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.93±13.17, mean_exploration_ratio_over_100_episodes_from_training 0.0666±0.0087, mean_reward_over_100_episodes_from_eval 25.75±12.84
2025-12-29 16:01:54,040 | INFO | [trial_008 | seed 29] elapsed_time 01:46:22, episode 0113, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 26.27±12.98, mean_exploration_ratio_over_100_episodes_from_training 0.0668±0.0086, mean_reward_over_100_episodes_from_eval 26.10±12.66
2025-12-29 16:02:51,320 | INFO | [trial_008 | seed 29] elapsed_time 01:47:19, episode 0114, episode_env_steps 1001, episode_sum_max_reward_per_step 39.459999, episode_sum_max_abs_reward_per_step 39.459999, mean_reward_over_100_episodes_from_training 26.60±12.79, mean_exploration_ratio_over_100_episodes_from_training 0.0670±0.0085, mean_reward_over_100_episodes_from_eval 26.44±12.47
2025-12-29 16:03:56,715 | INFO | [trial_008 | seed 29] elapsed_time 01:48:24, episode 0115, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 26.93±12.57, mean_exploration_ratio_over_100_episodes_from_training 0.0672±0.0084, mean_reward_over_100_episodes_from_eval 26.72±12.24
2025-12-29 16:05:02,813 | INFO | [trial_008 | seed 29] elapsed_time 01:49:31, episode 0116, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 27.26±12.37, mean_exploration_ratio_over_100_episodes_from_training 0.0674±0.0083, mean_reward_over_100_episodes_from_eval 27.05±12.04
2025-12-29 16:05:59,037 | INFO | [trial_008 | seed 29] elapsed_time 01:50:27, episode 0117, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.59±12.15, mean_exploration_ratio_over_100_episodes_from_training 0.0676±0.0082, mean_reward_over_100_episodes_from_eval 27.37±11.81
2025-12-29 16:06:55,662 | INFO | [trial_008 | seed 29] elapsed_time 01:51:23, episode 0118, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 27.86±11.90, mean_exploration_ratio_over_100_episodes_from_training 0.0678±0.0081, mean_reward_over_100_episodes_from_eval 27.70±11.59
2025-12-29 16:07:51,378 | INFO | [trial_008 | seed 29] elapsed_time 01:52:19, episode 0119, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 28.17±11.66, mean_exploration_ratio_over_100_episodes_from_training 0.0680±0.0080, mean_reward_over_100_episodes_from_eval 27.98±11.36
2025-12-29 16:08:46,636 | INFO | [trial_008 | seed 29] elapsed_time 01:53:14, episode 0120, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 28.46±11.40, mean_exploration_ratio_over_100_episodes_from_training 0.0682±0.0079, mean_reward_over_100_episodes_from_eval 28.27±11.13
2025-12-29 16:09:43,578 | INFO | [trial_008 | seed 29] elapsed_time 01:54:11, episode 0121, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 28.78±11.15, mean_exploration_ratio_over_100_episodes_from_training 0.0685±0.0078, mean_reward_over_100_episodes_from_eval 28.54±10.88
2025-12-29 16:10:38,941 | INFO | [trial_008 | seed 29] elapsed_time 01:55:07, episode 0122, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 29.06±10.86, mean_exploration_ratio_over_100_episodes_from_training 0.0686±0.0077, mean_reward_over_100_episodes_from_eval 28.85±10.62
2025-12-29 16:11:34,453 | INFO | [trial_008 | seed 29] elapsed_time 01:56:02, episode 0123, episode_env_steps 1001, episode_sum_max_reward_per_step 39.569999, episode_sum_max_abs_reward_per_step 39.569999, mean_reward_over_100_episodes_from_training 29.35±10.62, mean_exploration_ratio_over_100_episodes_from_training 0.0688±0.0076, mean_reward_over_100_episodes_from_eval 29.10±10.36
2025-12-29 16:12:32,403 | INFO | [trial_008 | seed 29] elapsed_time 01:57:00, episode 0124, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 29.61±10.37, mean_exploration_ratio_over_100_episodes_from_training 0.0689±0.0074, mean_reward_over_100_episodes_from_eval 29.38±10.13
2025-12-29 16:13:29,842 | INFO | [trial_008 | seed 29] elapsed_time 01:57:58, episode 0125, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 29.88±10.10, mean_exploration_ratio_over_100_episodes_from_training 0.0692±0.0072, mean_reward_over_100_episodes_from_eval 29.63±09.90
2025-12-29 16:14:26,699 | INFO | [trial_008 | seed 29] elapsed_time 01:58:54, episode 0126, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 30.17±09.84, mean_exploration_ratio_over_100_episodes_from_training 0.0694±0.0071, mean_reward_over_100_episodes_from_eval 29.92±09.71
2025-12-29 16:15:22,279 | INFO | [trial_008 | seed 29] Requirement met (evaluation metric): solved at episode 128 with mean_100_eval=30.20
2025-12-29 16:15:22,282 | INFO | [trial_008 | seed 29] elapsed_time 01:59:50, episode 0127, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 30.47±09.59, mean_exploration_ratio_over_100_episodes_from_training 0.0696±0.0069, mean_reward_over_100_episodes_from_eval 30.20±09.48
2025-12-29 16:15:22,282 | INFO | [trial_008 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 16:46:19,622 | INFO | [trial_008 | seed 29] Training complete.
2025-12-29 16:46:19,624 | INFO | [trial_008 | seed 29] Solved (evaluation metric) at episode 128.
2025-12-29 16:46:19,625 | INFO | [trial_008 | seed 29] Final evaluation score 35.86±0.94 in 4991.86s training, 9047.82s wall.
2025-12-29 16:46:19,625 | INFO | [trial_008 | seed 29] Closing UnityVectorEnv (worker_id=8029).
2025-12-29 16:46:19,625 | INFO | [Main] Requesting worker 8029 to close Unity env.
2025-12-29 16:46:20,483 | INFO | [Main] Worker 8029 joined. Unity env fully closed.
2025-12-29 16:46:20,496 | INFO | [trial_008 | seed 29] Final eval score: 35.86
2025-12-29 16:46:20,801 | INFO | [trial_008 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_008_seed_29.png
2025-12-29 16:46:20,801 | INFO | [trial_008 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 16:46:21,085 | INFO | [trial_008] Final scores across seeds: [35.856]
2025-12-29 16:46:21,085 | INFO | [trial_008] Avg=35.856 ± 0.000, Best seed score=35.856
2025-12-29 16:46:21,087 | INFO | [trial_009] Starting trial with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":2,"tau":0.001}
2025-12-29 16:46:21,089 | INFO | [trial_009 | seed 29] Start training with hparams: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":2,"tau":0.001}
2025-12-29 16:46:21,090 | INFO | [trial_009 | seed 29] === Starting run for seed 29 ===
2025-12-29 16:46:21,090 | INFO | [trial_009 | seed 29] Hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":2,"tau":0.001}
2025-12-29 16:46:21,091 | INFO | [trial_009 | seed 29] Launching UnityVectorEnv with worker_id=9029, seed=29
2025-12-29 16:46:21,092 | INFO | [Main] Spawning worker 9029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 16:46:21,107 | INFO | [Main] Worker 9029 started (pid=46792).
2025-12-29 16:46:24,851 | INFO | [trial_009 | seed 29] Environment batched agents (train): 20
2025-12-29 16:47:00,133 | INFO | [trial_009 | seed 29] Environment batched agents (eval): 20
2025-12-29 16:47:19,449 | INFO | [trial_009 | seed 29] elapsed_time 00:00:58, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 15.290000, episode_sum_max_abs_reward_per_step 15.290000, mean_reward_over_100_episodes_from_training 00.93±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0000, mean_reward_over_100_episodes_from_eval 00.93±00.00
2025-12-29 16:48:16,469 | INFO | [trial_009 | seed 29] elapsed_time 00:01:55, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 16.070000, episode_sum_max_abs_reward_per_step 16.070000, mean_reward_over_100_episodes_from_training 00.98±00.05, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0011, mean_reward_over_100_episodes_from_eval 01.03±00.10
2025-12-29 16:49:22,671 | INFO | [trial_009 | seed 29] elapsed_time 00:03:01, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 18.000000, episode_sum_max_abs_reward_per_step 18.000000, mean_reward_over_100_episodes_from_training 01.04±00.09, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0009, mean_reward_over_100_episodes_from_eval 01.25±00.33
2025-12-29 16:50:27,218 | INFO | [trial_009 | seed 29] elapsed_time 00:04:06, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 18.440000, episode_sum_max_abs_reward_per_step 18.440000, mean_reward_over_100_episodes_from_training 01.06±00.09, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0008, mean_reward_over_100_episodes_from_eval 01.33±00.31
2025-12-29 16:51:27,076 | INFO | [trial_009 | seed 29] elapsed_time 00:05:05, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 16.390000, episode_sum_max_abs_reward_per_step 16.390000, mean_reward_over_100_episodes_from_training 01.07±00.08, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0007, mean_reward_over_100_episodes_from_eval 01.30±00.28
2025-12-29 16:52:47,748 | INFO | [trial_009 | seed 29] elapsed_time 00:06:26, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 18.480000, episode_sum_max_abs_reward_per_step 18.480000, mean_reward_over_100_episodes_from_training 01.12±00.14, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0007, mean_reward_over_100_episodes_from_eval 01.40±00.35
2025-12-29 16:53:45,875 | INFO | [trial_009 | seed 29] elapsed_time 00:07:24, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 16.400000, episode_sum_max_abs_reward_per_step 16.400000, mean_reward_over_100_episodes_from_training 01.10±00.14, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0007, mean_reward_over_100_episodes_from_eval 01.38±00.32
2025-12-29 16:54:45,764 | INFO | [trial_009 | seed 29] elapsed_time 00:08:24, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 21.070000, episode_sum_max_abs_reward_per_step 21.070000, mean_reward_over_100_episodes_from_training 01.13±00.15, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0007, mean_reward_over_100_episodes_from_eval 01.34±00.32
2025-12-29 16:55:41,549 | INFO | [trial_009 | seed 29] elapsed_time 00:09:20, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 23.369999, episode_sum_max_abs_reward_per_step 23.369999, mean_reward_over_100_episodes_from_training 01.20±00.24, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0007, mean_reward_over_100_episodes_from_eval 01.32±00.30
2025-12-29 16:57:14,043 | INFO | [trial_009 | seed 29] elapsed_time 00:10:52, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 26.369999, episode_sum_max_abs_reward_per_step 26.369999, mean_reward_over_100_episodes_from_training 01.29±00.34, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0007, mean_reward_over_100_episodes_from_eval 01.34±00.29
2025-12-29 16:58:25,097 | INFO | [trial_009 | seed 29] elapsed_time 00:12:04, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 24.319999, episode_sum_max_abs_reward_per_step 24.319999, mean_reward_over_100_episodes_from_training 01.32±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0007, mean_reward_over_100_episodes_from_eval 01.41±00.36
2025-12-29 16:59:26,416 | INFO | [trial_009 | seed 29] elapsed_time 00:13:05, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 22.589999, episode_sum_max_abs_reward_per_step 22.589999, mean_reward_over_100_episodes_from_training 01.37±00.36, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0007, mean_reward_over_100_episodes_from_eval 01.51±00.46
2025-12-29 17:00:23,728 | INFO | [trial_009 | seed 29] elapsed_time 00:14:02, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 24.609999, episode_sum_max_abs_reward_per_step 24.609999, mean_reward_over_100_episodes_from_training 01.42±00.39, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0007, mean_reward_over_100_episodes_from_eval 01.62±00.59
2025-12-29 17:01:21,594 | INFO | [trial_009 | seed 29] elapsed_time 00:15:00, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 30.549999, episode_sum_max_abs_reward_per_step 30.549999, mean_reward_over_100_episodes_from_training 01.53±00.54, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0007, mean_reward_over_100_episodes_from_eval 01.68±00.61
2025-12-29 17:02:20,179 | INFO | [trial_009 | seed 29] elapsed_time 00:15:59, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 26.239999, episode_sum_max_abs_reward_per_step 26.239999, mean_reward_over_100_episodes_from_training 01.56±00.53, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0007, mean_reward_over_100_episodes_from_eval 01.74±00.63
2025-12-29 17:03:21,065 | INFO | [trial_009 | seed 29] elapsed_time 00:16:59, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 22.909999, episode_sum_max_abs_reward_per_step 22.909999, mean_reward_over_100_episodes_from_training 01.56±00.52, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0007, mean_reward_over_100_episodes_from_eval 01.78±00.63
2025-12-29 17:04:17,731 | INFO | [trial_009 | seed 29] elapsed_time 00:17:56, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 29.659999, episode_sum_max_abs_reward_per_step 29.659999, mean_reward_over_100_episodes_from_training 01.61±00.54, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 01.89±00.76
2025-12-29 17:05:15,698 | INFO | [trial_009 | seed 29] elapsed_time 00:18:54, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 33.639999, episode_sum_max_abs_reward_per_step 33.639999, mean_reward_over_100_episodes_from_training 01.71±00.65, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 02.02±00.91
2025-12-29 17:06:13,203 | INFO | [trial_009 | seed 29] elapsed_time 00:19:52, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 36.269999, episode_sum_max_abs_reward_per_step 36.269999, mean_reward_over_100_episodes_from_training 01.84±00.86, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 02.16±01.05
2025-12-29 17:07:11,549 | INFO | [trial_009 | seed 29] elapsed_time 00:20:50, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 38.679999, episode_sum_max_abs_reward_per_step 38.679999, mean_reward_over_100_episodes_from_training 02.08±01.33, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 02.30±01.20
2025-12-29 17:08:10,713 | INFO | [trial_009 | seed 29] elapsed_time 00:21:49, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 36.399999, episode_sum_max_abs_reward_per_step 36.399999, mean_reward_over_100_episodes_from_training 02.21±01.42, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 02.44±01.33
2025-12-29 17:09:07,758 | INFO | [trial_009 | seed 29] elapsed_time 00:22:46, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 37.129999, episode_sum_max_abs_reward_per_step 37.129999, mean_reward_over_100_episodes_from_training 02.39±01.62, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0007, mean_reward_over_100_episodes_from_eval 02.70±01.78
2025-12-29 17:10:06,077 | INFO | [trial_009 | seed 29] elapsed_time 00:23:44, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 02.68±02.08, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0007, mean_reward_over_100_episodes_from_eval 03.14±02.68
2025-12-29 17:11:04,138 | INFO | [trial_009 | seed 29] elapsed_time 00:24:43, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 03.15±03.04, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0007, mean_reward_over_100_episodes_from_eval 03.60±03.44
2025-12-29 17:11:59,972 | INFO | [trial_009 | seed 29] elapsed_time 00:25:38, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 03.63±03.81, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0007, mean_reward_over_100_episodes_from_eval 04.07±04.08
2025-12-29 17:12:56,014 | INFO | [trial_009 | seed 29] elapsed_time 00:26:34, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 04.10±04.41, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0007, mean_reward_over_100_episodes_from_eval 04.56±04.68
2025-12-29 17:13:53,800 | INFO | [trial_009 | seed 29] elapsed_time 00:27:32, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 04.59±05.00, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 05.14±05.46
2025-12-29 17:14:51,304 | INFO | [trial_009 | seed 29] elapsed_time 00:28:30, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 05.06±05.47, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 05.60±05.87
2025-12-29 17:15:47,836 | INFO | [trial_009 | seed 29] elapsed_time 00:29:26, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 05.53±05.94, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 06.07±06.28
2025-12-29 17:16:44,726 | INFO | [trial_009 | seed 29] elapsed_time 00:30:23, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.559999, episode_sum_max_abs_reward_per_step 39.559999, mean_reward_over_100_episodes_from_training 06.03±06.43, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0008, mean_reward_over_100_episodes_from_eval 06.59±06.79
2025-12-29 17:17:41,162 | INFO | [trial_009 | seed 29] elapsed_time 00:31:20, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 06.60±07.04, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0009, mean_reward_over_100_episodes_from_eval 07.12±07.28
2025-12-29 17:18:36,800 | INFO | [trial_009 | seed 29] elapsed_time 00:32:15, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 07.16±07.61, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 07.73±07.94
2025-12-29 17:19:34,116 | INFO | [trial_009 | seed 29] elapsed_time 00:33:13, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 07.69±08.07, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0009, mean_reward_over_100_episodes_from_eval 08.28±08.41
2025-12-29 17:20:30,712 | INFO | [trial_009 | seed 29] elapsed_time 00:34:09, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 08.29±08.66, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0010, mean_reward_over_100_episodes_from_eval 08.86±08.93
2025-12-29 17:21:27,180 | INFO | [trial_009 | seed 29] elapsed_time 00:35:06, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 08.83±09.10, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0010, mean_reward_over_100_episodes_from_eval 09.44±09.43
2025-12-29 17:22:24,388 | INFO | [trial_009 | seed 29] elapsed_time 00:36:03, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 09.35±09.49, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0012, mean_reward_over_100_episodes_from_eval 09.94±09.75
2025-12-29 17:23:24,234 | INFO | [trial_009 | seed 29] elapsed_time 00:37:03, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 09.87±09.85, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0013, mean_reward_over_100_episodes_from_eval 10.45±10.10
2025-12-29 17:24:21,019 | INFO | [trial_009 | seed 29] elapsed_time 00:37:59, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 10.39±10.23, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0013, mean_reward_over_100_episodes_from_eval 10.99±10.49
2025-12-29 17:25:18,514 | INFO | [trial_009 | seed 29] elapsed_time 00:38:57, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 10.81±10.43, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0012, mean_reward_over_100_episodes_from_eval 11.50±10.82
2025-12-29 17:26:16,032 | INFO | [trial_009 | seed 29] elapsed_time 00:39:54, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 11.31±10.75, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 12.02±11.18
2025-12-29 17:27:12,812 | INFO | [trial_009 | seed 29] elapsed_time 00:40:51, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 11.83±11.12, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 12.54±11.50
2025-12-29 17:28:07,921 | INFO | [trial_009 | seed 29] elapsed_time 00:41:46, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 12.37±11.52, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 13.06±11.86
2025-12-29 17:29:05,034 | INFO | [trial_009 | seed 29] elapsed_time 00:42:43, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 12.90±11.89, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 13.60±12.22
2025-12-29 17:30:02,361 | INFO | [trial_009 | seed 29] elapsed_time 00:43:41, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 13.45±12.30, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 14.17±12.64
2025-12-29 17:30:58,724 | INFO | [trial_009 | seed 29] elapsed_time 00:44:37, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 14.00±12.69, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 14.73±13.04
2025-12-29 17:31:55,081 | INFO | [trial_009 | seed 29] elapsed_time 00:45:33, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 14.52±13.04, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 15.22±13.32
2025-12-29 17:32:46,398 | INFO | [trial_009 | seed 29] elapsed_time 00:46:25, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 15.01±13.31, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 15.71±13.58
2025-12-29 17:33:37,432 | INFO | [trial_009 | seed 29] elapsed_time 00:47:16, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 15.48±13.57, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0012, mean_reward_over_100_episodes_from_eval 16.18±13.82
2025-12-29 17:34:25,973 | INFO | [trial_009 | seed 29] elapsed_time 00:48:04, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 15.93±13.78, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 16.62±14.02
2025-12-29 17:35:13,258 | INFO | [trial_009 | seed 29] elapsed_time 00:48:52, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 16.38±14.01, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 17.07±14.24
2025-12-29 17:35:58,751 | INFO | [trial_009 | seed 29] elapsed_time 00:49:37, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 16.82±14.21, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 17.49±14.41
2025-12-29 17:36:45,084 | INFO | [trial_009 | seed 29] elapsed_time 00:50:23, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.539999, episode_sum_max_abs_reward_per_step 39.539999, mean_reward_over_100_episodes_from_training 17.23±14.38, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 17.89±14.55
2025-12-29 17:37:30,858 | INFO | [trial_009 | seed 29] elapsed_time 00:51:09, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 17.64±14.54, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 18.30±14.70
2025-12-29 17:38:18,586 | INFO | [trial_009 | seed 29] elapsed_time 00:51:57, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.02±14.67, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 18.67±14.82
2025-12-29 17:39:05,111 | INFO | [trial_009 | seed 29] elapsed_time 00:52:44, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 18.38±14.78, mean_exploration_ratio_over_100_episodes_from_training 0.0149±0.0011, mean_reward_over_100_episodes_from_eval 19.04±14.92
2025-12-29 17:39:51,964 | INFO | [trial_009 | seed 29] elapsed_time 00:53:30, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 18.74±14.88, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0011, mean_reward_over_100_episodes_from_eval 19.39±15.02
2025-12-29 17:40:39,077 | INFO | [trial_009 | seed 29] elapsed_time 00:54:17, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 19.08±14.97, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0011, mean_reward_over_100_episodes_from_eval 19.73±15.11
2025-12-29 17:41:26,005 | INFO | [trial_009 | seed 29] elapsed_time 00:55:04, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 19.40±15.03, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0011, mean_reward_over_100_episodes_from_eval 20.05±15.17
2025-12-29 17:42:11,317 | INFO | [trial_009 | seed 29] elapsed_time 00:55:50, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 19.70±15.08, mean_exploration_ratio_over_100_episodes_from_training 0.0148±0.0011, mean_reward_over_100_episodes_from_eval 20.30±15.16
2025-12-29 17:42:57,438 | INFO | [trial_009 | seed 29] elapsed_time 00:56:36, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 19.99±15.12, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0011, mean_reward_over_100_episodes_from_eval 20.59±15.20
2025-12-29 17:43:43,871 | INFO | [trial_009 | seed 29] elapsed_time 00:57:22, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 20.27±15.15, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0011, mean_reward_over_100_episodes_from_eval 20.86±15.22
2025-12-29 17:44:30,624 | INFO | [trial_009 | seed 29] elapsed_time 00:58:09, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 20.55±15.19, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0012, mean_reward_over_100_episodes_from_eval 21.13±15.24
2025-12-29 17:45:19,502 | INFO | [trial_009 | seed 29] elapsed_time 00:58:58, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 20.83±15.22, mean_exploration_ratio_over_100_episodes_from_training 0.0147±0.0012, mean_reward_over_100_episodes_from_eval 21.41±15.27
2025-12-29 17:46:07,288 | INFO | [trial_009 | seed 29] elapsed_time 00:59:46, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.08±15.24, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0012, mean_reward_over_100_episodes_from_eval 21.67±15.30
2025-12-29 17:46:53,802 | INFO | [trial_009 | seed 29] elapsed_time 01:00:32, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 21.34±15.26, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0012, mean_reward_over_100_episodes_from_eval 21.91±15.30
2025-12-29 17:47:39,642 | INFO | [trial_009 | seed 29] elapsed_time 01:01:18, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 21.58±15.26, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0012, mean_reward_over_100_episodes_from_eval 22.14±15.30
2025-12-29 17:48:25,427 | INFO | [trial_009 | seed 29] elapsed_time 01:02:04, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.82±15.27, mean_exploration_ratio_over_100_episodes_from_training 0.0146±0.0012, mean_reward_over_100_episodes_from_eval 22.38±15.31
2025-12-29 17:49:10,773 | INFO | [trial_009 | seed 29] elapsed_time 01:02:49, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 22.05±15.29, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0012, mean_reward_over_100_episodes_from_eval 22.60±15.31
2025-12-29 17:49:56,539 | INFO | [trial_009 | seed 29] elapsed_time 01:03:35, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 22.26±15.27, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0012, mean_reward_over_100_episodes_from_eval 22.83±15.31
2025-12-29 17:50:41,902 | INFO | [trial_009 | seed 29] elapsed_time 01:04:20, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 22.47±15.26, mean_exploration_ratio_over_100_episodes_from_training 0.0145±0.0013, mean_reward_over_100_episodes_from_eval 23.06±15.31
2025-12-29 17:51:27,243 | INFO | [trial_009 | seed 29] elapsed_time 01:05:06, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 22.67±15.24, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0013, mean_reward_over_100_episodes_from_eval 23.25±15.29
2025-12-29 17:52:12,800 | INFO | [trial_009 | seed 29] elapsed_time 01:05:51, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 22.86±15.22, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0013, mean_reward_over_100_episodes_from_eval 23.46±15.28
2025-12-29 17:52:59,678 | INFO | [trial_009 | seed 29] elapsed_time 01:06:38, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 23.05±15.20, mean_exploration_ratio_over_100_episodes_from_training 0.0144±0.0014, mean_reward_over_100_episodes_from_eval 23.65±15.26
2025-12-29 17:53:45,721 | INFO | [trial_009 | seed 29] elapsed_time 01:07:24, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 23.24±15.19, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0014, mean_reward_over_100_episodes_from_eval 23.80±15.22
2025-12-29 17:54:30,310 | INFO | [trial_009 | seed 29] elapsed_time 01:08:09, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 23.43±15.18, mean_exploration_ratio_over_100_episodes_from_training 0.0143±0.0014, mean_reward_over_100_episodes_from_eval 23.99±15.20
2025-12-29 17:55:16,035 | INFO | [trial_009 | seed 29] elapsed_time 01:08:54, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 23.62±15.17, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0015, mean_reward_over_100_episodes_from_eval 24.17±15.18
2025-12-29 17:56:00,708 | INFO | [trial_009 | seed 29] elapsed_time 01:09:39, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 23.79±15.14, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0015, mean_reward_over_100_episodes_from_eval 24.29±15.12
2025-12-29 17:56:46,306 | INFO | [trial_009 | seed 29] elapsed_time 01:10:25, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.549999, episode_sum_max_abs_reward_per_step 39.549999, mean_reward_over_100_episodes_from_training 23.95±15.10, mean_exploration_ratio_over_100_episodes_from_training 0.0142±0.0015, mean_reward_over_100_episodes_from_eval 24.45±15.09
2025-12-29 17:57:33,392 | INFO | [trial_009 | seed 29] elapsed_time 01:11:12, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 24.09±15.06, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0015, mean_reward_over_100_episodes_from_eval 24.58±15.04
2025-12-29 17:58:18,892 | INFO | [trial_009 | seed 29] elapsed_time 01:11:57, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.25±15.03, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0016, mean_reward_over_100_episodes_from_eval 24.74±15.01
2025-12-29 17:59:03,755 | INFO | [trial_009 | seed 29] elapsed_time 01:12:42, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.40±15.00, mean_exploration_ratio_over_100_episodes_from_training 0.0141±0.0016, mean_reward_over_100_episodes_from_eval 24.90±14.99
2025-12-29 17:59:48,870 | INFO | [trial_009 | seed 29] elapsed_time 01:13:27, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.55±14.97, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0016, mean_reward_over_100_episodes_from_eval 25.06±14.96
2025-12-29 18:00:34,185 | INFO | [trial_009 | seed 29] elapsed_time 01:14:13, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 24.69±14.93, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0016, mean_reward_over_100_episodes_from_eval 25.18±14.91
2025-12-29 18:01:19,214 | INFO | [trial_009 | seed 29] elapsed_time 01:14:58, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 24.84±14.91, mean_exploration_ratio_over_100_episodes_from_training 0.0140±0.0016, mean_reward_over_100_episodes_from_eval 25.34±14.89
2025-12-29 18:02:05,167 | INFO | [trial_009 | seed 29] elapsed_time 01:15:44, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 24.97±14.87, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0016, mean_reward_over_100_episodes_from_eval 25.48±14.86
2025-12-29 18:02:50,455 | INFO | [trial_009 | seed 29] elapsed_time 01:16:29, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 25.13±14.86, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0017, mean_reward_over_100_episodes_from_eval 25.63±14.84
2025-12-29 18:03:36,222 | INFO | [trial_009 | seed 29] elapsed_time 01:17:15, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.28±14.83, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0017, mean_reward_over_100_episodes_from_eval 25.77±14.81
2025-12-29 18:04:20,729 | INFO | [trial_009 | seed 29] elapsed_time 01:17:59, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 25.41±14.80, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0017, mean_reward_over_100_episodes_from_eval 25.90±14.77
2025-12-29 18:05:06,143 | INFO | [trial_009 | seed 29] elapsed_time 01:18:45, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 25.51±14.74, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0017, mean_reward_over_100_episodes_from_eval 26.02±14.73
2025-12-29 18:05:50,893 | INFO | [trial_009 | seed 29] elapsed_time 01:19:29, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 25.62±14.70, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0017, mean_reward_over_100_episodes_from_eval 26.13±14.69
2025-12-29 18:06:36,578 | INFO | [trial_009 | seed 29] elapsed_time 01:20:15, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 25.74±14.66, mean_exploration_ratio_over_100_episodes_from_training 0.0138±0.0017, mean_reward_over_100_episodes_from_eval 26.27±14.67
2025-12-29 18:07:21,236 | INFO | [trial_009 | seed 29] elapsed_time 01:21:00, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 25.85±14.62, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 26.40±14.64
2025-12-29 18:08:07,016 | INFO | [trial_009 | seed 29] elapsed_time 01:21:45, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 25.97±14.59, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0017, mean_reward_over_100_episodes_from_eval 26.51±14.60
2025-12-29 18:08:51,476 | INFO | [trial_009 | seed 29] elapsed_time 01:22:30, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 26.08±14.54, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0018, mean_reward_over_100_episodes_from_eval 26.60±14.55
2025-12-29 18:09:37,348 | INFO | [trial_009 | seed 29] elapsed_time 01:23:16, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.17±14.50, mean_exploration_ratio_over_100_episodes_from_training 0.0137±0.0018, mean_reward_over_100_episodes_from_eval 26.69±14.50
2025-12-29 18:10:22,436 | INFO | [trial_009 | seed 29] elapsed_time 01:24:01, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.28±14.46, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0018, mean_reward_over_100_episodes_from_eval 26.78±14.45
2025-12-29 18:11:08,597 | INFO | [trial_009 | seed 29] elapsed_time 01:24:47, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 26.37±14.41, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0018, mean_reward_over_100_episodes_from_eval 26.88±14.41
2025-12-29 18:11:53,355 | INFO | [trial_009 | seed 29] elapsed_time 01:25:32, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 26.46±14.36, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0018, mean_reward_over_100_episodes_from_eval 26.99±14.38
2025-12-29 18:12:39,806 | INFO | [trial_009 | seed 29] elapsed_time 01:26:18, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.56±14.33, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 27.10±14.35
2025-12-29 18:13:26,218 | INFO | [trial_009 | seed 29] elapsed_time 01:27:05, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 26.66±14.29, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 27.21±14.31
2025-12-29 18:14:12,137 | INFO | [trial_009 | seed 29] elapsed_time 01:27:51, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 27.03±14.10, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 27.57±14.10
2025-12-29 18:14:59,063 | INFO | [trial_009 | seed 29] elapsed_time 01:28:37, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 27.39±13.89, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 27.92±13.87
2025-12-29 18:15:44,903 | INFO | [trial_009 | seed 29] elapsed_time 01:29:23, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 27.74±13.66, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0018, mean_reward_over_100_episodes_from_eval 28.28±13.65
2025-12-29 18:16:30,285 | INFO | [trial_009 | seed 29] elapsed_time 01:30:09, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 28.09±13.42, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 28.63±13.41
2025-12-29 18:17:15,511 | INFO | [trial_009 | seed 29] elapsed_time 01:30:54, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.44±13.17, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 28.98±13.14
2025-12-29 18:18:00,865 | INFO | [trial_009 | seed 29] elapsed_time 01:31:39, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 28.75±12.89, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0019, mean_reward_over_100_episodes_from_eval 29.27±12.86
2025-12-29 18:18:45,951 | INFO | [trial_009 | seed 29] elapsed_time 01:32:24, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 29.09±12.60, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 29.59±12.55
2025-12-29 18:19:30,754 | INFO | [trial_009 | seed 29] elapsed_time 01:33:09, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 29.39±12.29, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0019, mean_reward_over_100_episodes_from_eval 29.93±12.23
2025-12-29 18:20:16,185 | INFO | [trial_009 | seed 29] Requirement met (evaluation metric): solved at episode 109 with mean_100_eval=30.25
2025-12-29 18:20:16,187 | INFO | [trial_009 | seed 29] elapsed_time 01:33:55, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 29.71±11.97, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0020, mean_reward_over_100_episodes_from_eval 30.25±11.89
2025-12-29 18:20:16,187 | INFO | [trial_009 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 18:44:34,876 | INFO | [trial_009 | seed 29] Training complete.
2025-12-29 18:44:34,876 | INFO | [trial_009 | seed 29] Solved (evaluation metric) at episode 109.
2025-12-29 18:44:34,876 | INFO | [trial_009 | seed 29] Final evaluation score 34.60±1.03 in 3848.71s training, 7093.79s wall.
2025-12-29 18:44:34,877 | INFO | [trial_009 | seed 29] Closing UnityVectorEnv (worker_id=9029).
2025-12-29 18:44:34,877 | INFO | [Main] Requesting worker 9029 to close Unity env.
2025-12-29 18:44:36,043 | INFO | [Main] Worker 9029 joined. Unity env fully closed.
2025-12-29 18:44:36,043 | INFO | [trial_009 | seed 29] Final eval score: 34.60
2025-12-29 18:44:36,381 | INFO | [trial_009 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_009_seed_29.png
2025-12-29 18:44:36,383 | INFO | [trial_009 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 18:44:36,562 | INFO | [trial_009] Final scores across seeds: [34.599]
2025-12-29 18:44:36,562 | INFO | [trial_009] Avg=34.599 ± 0.000, Best seed score=34.599
2025-12-29 18:44:36,562 | INFO | [trial_010] Starting trial with hparams: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":2,"tau":0.001}
2025-12-29 18:44:36,568 | INFO | [trial_010 | seed 29] Start training with hparams: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":2,"tau":0.001}
2025-12-29 18:44:36,568 | INFO | [trial_010 | seed 29] === Starting run for seed 29 ===
2025-12-29 18:44:36,568 | INFO | [trial_010 | seed 29] Hyperparameters: {"batch_size":128,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":10,"optimizer":"Adam","target_update_every":2,"tau":0.001}
2025-12-29 18:44:36,570 | INFO | [trial_010 | seed 29] Launching UnityVectorEnv with worker_id=10029, seed=29
2025-12-29 18:44:36,571 | INFO | [Main] Spawning worker 10029 for Unity env (seed=29). Executable: C:\Users\anhtu\pyspark\Reinforcement_Learning_Projects\deep-reinforcement-learning-master\p2_continuous-control\20_Agents_Reacher_Windows_x86_64\Reacher.exe
2025-12-29 18:44:36,589 | INFO | [Main] Worker 10029 started (pid=83828).
2025-12-29 18:44:40,733 | INFO | [trial_010 | seed 29] Environment batched agents (train): 20
2025-12-29 18:45:05,916 | INFO | [trial_010 | seed 29] Environment batched agents (eval): 20
2025-12-29 18:45:19,537 | INFO | [trial_010 | seed 29] elapsed_time 00:00:42, episode 0000, episode_env_steps 1001, episode_sum_max_reward_per_step 11.380000, episode_sum_max_abs_reward_per_step 11.380000, mean_reward_over_100_episodes_from_training 00.69±00.00, mean_exploration_ratio_over_100_episodes_from_training 0.0139±0.0000, mean_reward_over_100_episodes_from_eval 01.01±00.00
2025-12-29 18:46:02,114 | INFO | [trial_010 | seed 29] elapsed_time 00:01:25, episode 0001, episode_env_steps 1001, episode_sum_max_reward_per_step 17.710000, episode_sum_max_abs_reward_per_step 17.710000, mean_reward_over_100_episodes_from_training 00.96±00.27, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0006, mean_reward_over_100_episodes_from_eval 00.87±00.13
2025-12-29 18:46:45,092 | INFO | [trial_010 | seed 29] elapsed_time 00:02:08, episode 0002, episode_env_steps 1001, episode_sum_max_reward_per_step 12.260000, episode_sum_max_abs_reward_per_step 12.260000, mean_reward_over_100_episodes_from_training 00.88±00.25, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0005, mean_reward_over_100_episodes_from_eval 01.01±00.22
2025-12-29 18:47:26,420 | INFO | [trial_010 | seed 29] elapsed_time 00:02:49, episode 0003, episode_env_steps 1001, episode_sum_max_reward_per_step 22.360000, episode_sum_max_abs_reward_per_step 22.360000, mean_reward_over_100_episodes_from_training 01.06±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0005, mean_reward_over_100_episodes_from_eval 01.13±00.29
2025-12-29 18:48:10,492 | INFO | [trial_010 | seed 29] elapsed_time 00:03:33, episode 0004, episode_env_steps 1001, episode_sum_max_reward_per_step 18.900000, episode_sum_max_abs_reward_per_step 18.900000, mean_reward_over_100_episodes_from_training 01.10±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0004, mean_reward_over_100_episodes_from_eval 01.35±00.50
2025-12-29 18:48:54,092 | INFO | [trial_010 | seed 29] elapsed_time 00:04:17, episode 0005, episode_env_steps 1001, episode_sum_max_reward_per_step 12.860000, episode_sum_max_abs_reward_per_step 12.860000, mean_reward_over_100_episodes_from_training 01.03±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0004, mean_reward_over_100_episodes_from_eval 01.33±00.46
2025-12-29 18:49:38,068 | INFO | [trial_010 | seed 29] elapsed_time 00:05:01, episode 0006, episode_env_steps 1001, episode_sum_max_reward_per_step 17.400000, episode_sum_max_abs_reward_per_step 17.400000, mean_reward_over_100_episodes_from_training 01.05±00.33, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0005, mean_reward_over_100_episodes_from_eval 01.28±00.44
2025-12-29 18:50:22,089 | INFO | [trial_010 | seed 29] elapsed_time 00:05:45, episode 0007, episode_env_steps 1001, episode_sum_max_reward_per_step 17.400000, episode_sum_max_abs_reward_per_step 17.400000, mean_reward_over_100_episodes_from_training 01.04±00.30, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0006, mean_reward_over_100_episodes_from_eval 01.25±00.42
2025-12-29 18:51:06,484 | INFO | [trial_010 | seed 29] elapsed_time 00:06:29, episode 0008, episode_env_steps 1001, episode_sum_max_reward_per_step 17.220000, episode_sum_max_abs_reward_per_step 17.220000, mean_reward_over_100_episodes_from_training 01.05±00.29, mean_exploration_ratio_over_100_episodes_from_training 0.0136±0.0006, mean_reward_over_100_episodes_from_eval 01.22±00.40
2025-12-29 18:51:48,971 | INFO | [trial_010 | seed 29] elapsed_time 00:07:12, episode 0009, episode_env_steps 1001, episode_sum_max_reward_per_step 20.030000, episode_sum_max_abs_reward_per_step 20.030000, mean_reward_over_100_episodes_from_training 01.08±00.29, mean_exploration_ratio_over_100_episodes_from_training 0.0135±0.0006, mean_reward_over_100_episodes_from_eval 01.21±00.38
2025-12-29 18:52:33,331 | INFO | [trial_010 | seed 29] elapsed_time 00:07:56, episode 0010, episode_env_steps 1001, episode_sum_max_reward_per_step 14.000000, episode_sum_max_abs_reward_per_step 14.000000, mean_reward_over_100_episodes_from_training 01.06±00.28, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0006, mean_reward_over_100_episodes_from_eval 01.18±00.38
2025-12-29 18:53:19,651 | INFO | [trial_010 | seed 29] elapsed_time 00:08:43, episode 0011, episode_env_steps 1001, episode_sum_max_reward_per_step 15.350000, episode_sum_max_abs_reward_per_step 15.350000, mean_reward_over_100_episodes_from_training 01.06±00.27, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0007, mean_reward_over_100_episodes_from_eval 01.17±00.37
2025-12-29 18:54:03,970 | INFO | [trial_010 | seed 29] elapsed_time 00:09:27, episode 0012, episode_env_steps 1001, episode_sum_max_reward_per_step 16.220000, episode_sum_max_abs_reward_per_step 16.220000, mean_reward_over_100_episodes_from_training 01.05±00.26, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0007, mean_reward_over_100_episodes_from_eval 01.20±00.37
2025-12-29 18:54:47,101 | INFO | [trial_010 | seed 29] elapsed_time 00:10:10, episode 0013, episode_env_steps 1001, episode_sum_max_reward_per_step 23.479999, episode_sum_max_abs_reward_per_step 23.479999, mean_reward_over_100_episodes_from_training 01.10±00.30, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0006, mean_reward_over_100_episodes_from_eval 01.27±00.45
2025-12-29 18:55:30,745 | INFO | [trial_010 | seed 29] elapsed_time 00:10:54, episode 0014, episode_env_steps 1001, episode_sum_max_reward_per_step 24.249999, episode_sum_max_abs_reward_per_step 24.249999, mean_reward_over_100_episodes_from_training 01.14±00.33, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0007, mean_reward_over_100_episodes_from_eval 01.29±00.44
2025-12-29 18:56:13,864 | INFO | [trial_010 | seed 29] elapsed_time 00:11:37, episode 0015, episode_env_steps 1001, episode_sum_max_reward_per_step 22.459999, episode_sum_max_abs_reward_per_step 22.459999, mean_reward_over_100_episodes_from_training 01.18±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0007, mean_reward_over_100_episodes_from_eval 01.26±00.43
2025-12-29 18:56:57,654 | INFO | [trial_010 | seed 29] elapsed_time 00:12:21, episode 0016, episode_env_steps 1001, episode_sum_max_reward_per_step 21.280000, episode_sum_max_abs_reward_per_step 21.280000, mean_reward_over_100_episodes_from_training 01.20±00.35, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0006, mean_reward_over_100_episodes_from_eval 01.35±00.55
2025-12-29 18:57:43,192 | INFO | [trial_010 | seed 29] elapsed_time 00:13:06, episode 0017, episode_env_steps 1001, episode_sum_max_reward_per_step 25.119999, episode_sum_max_abs_reward_per_step 25.119999, mean_reward_over_100_episodes_from_training 01.25±00.39, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0007, mean_reward_over_100_episodes_from_eval 01.37±00.54
2025-12-29 18:58:26,889 | INFO | [trial_010 | seed 29] elapsed_time 00:13:50, episode 0018, episode_env_steps 1001, episode_sum_max_reward_per_step 18.770000, episode_sum_max_abs_reward_per_step 18.770000, mean_reward_over_100_episodes_from_training 01.25±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0007, mean_reward_over_100_episodes_from_eval 01.32±00.56
2025-12-29 18:59:11,736 | INFO | [trial_010 | seed 29] elapsed_time 00:14:35, episode 0019, episode_env_steps 1001, episode_sum_max_reward_per_step 18.130000, episode_sum_max_abs_reward_per_step 18.130000, mean_reward_over_100_episodes_from_training 01.25±00.37, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0007, mean_reward_over_100_episodes_from_eval 01.30±00.55
2025-12-29 18:59:55,053 | INFO | [trial_010 | seed 29] elapsed_time 00:15:18, episode 0020, episode_env_steps 1001, episode_sum_max_reward_per_step 24.479999, episode_sum_max_abs_reward_per_step 24.479999, mean_reward_over_100_episodes_from_training 01.27±00.38, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0007, mean_reward_over_100_episodes_from_eval 01.38±00.64
2025-12-29 19:00:39,520 | INFO | [trial_010 | seed 29] elapsed_time 00:16:02, episode 0021, episode_env_steps 1001, episode_sum_max_reward_per_step 27.879999, episode_sum_max_abs_reward_per_step 27.879999, mean_reward_over_100_episodes_from_training 01.32±00.43, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 01.44±00.68
2025-12-29 19:01:21,843 | INFO | [trial_010 | seed 29] elapsed_time 00:16:45, episode 0022, episode_env_steps 1001, episode_sum_max_reward_per_step 29.309999, episode_sum_max_abs_reward_per_step 29.309999, mean_reward_over_100_episodes_from_training 01.38±00.51, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0007, mean_reward_over_100_episodes_from_eval 01.51±00.74
2025-12-29 19:02:06,117 | INFO | [trial_010 | seed 29] elapsed_time 00:17:29, episode 0023, episode_env_steps 1001, episode_sum_max_reward_per_step 34.659999, episode_sum_max_abs_reward_per_step 34.659999, mean_reward_over_100_episodes_from_training 01.50±00.76, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 01.65±00.98
2025-12-29 19:02:49,959 | INFO | [trial_010 | seed 29] elapsed_time 00:18:13, episode 0024, episode_env_steps 1001, episode_sum_max_reward_per_step 36.219999, episode_sum_max_abs_reward_per_step 36.219999, mean_reward_over_100_episodes_from_training 01.61±00.90, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 01.75±01.09
2025-12-29 19:03:34,432 | INFO | [trial_010 | seed 29] elapsed_time 00:18:57, episode 0025, episode_env_steps 1001, episode_sum_max_reward_per_step 35.539999, episode_sum_max_abs_reward_per_step 35.539999, mean_reward_over_100_episodes_from_training 01.71±01.02, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 01.85±01.18
2025-12-29 19:04:17,199 | INFO | [trial_010 | seed 29] elapsed_time 00:19:40, episode 0026, episode_env_steps 1001, episode_sum_max_reward_per_step 38.069999, episode_sum_max_abs_reward_per_step 38.069999, mean_reward_over_100_episodes_from_training 01.85±01.25, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 01.98±01.35
2025-12-29 19:04:59,593 | INFO | [trial_010 | seed 29] elapsed_time 00:20:23, episode 0027, episode_env_steps 1001, episode_sum_max_reward_per_step 37.799999, episode_sum_max_abs_reward_per_step 37.799999, mean_reward_over_100_episodes_from_training 02.01±01.45, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 02.13±01.52
2025-12-29 19:05:42,877 | INFO | [trial_010 | seed 29] elapsed_time 00:21:06, episode 0028, episode_env_steps 1001, episode_sum_max_reward_per_step 38.679999, episode_sum_max_abs_reward_per_step 38.679999, mean_reward_over_100_episodes_from_training 02.19±01.72, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0006, mean_reward_over_100_episodes_from_eval 02.29±01.72
2025-12-29 19:06:28,303 | INFO | [trial_010 | seed 29] elapsed_time 00:21:51, episode 0029, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 02.41±02.07, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0006, mean_reward_over_100_episodes_from_eval 02.56±02.21
2025-12-29 19:07:12,669 | INFO | [trial_010 | seed 29] elapsed_time 00:22:36, episode 0030, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 02.71±02.61, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0006, mean_reward_over_100_episodes_from_eval 02.81±02.57
2025-12-29 19:07:57,161 | INFO | [trial_010 | seed 29] elapsed_time 00:23:20, episode 0031, episode_env_steps 1001, episode_sum_max_reward_per_step 39.579999, episode_sum_max_abs_reward_per_step 39.579999, mean_reward_over_100_episodes_from_training 02.99±03.01, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0006, mean_reward_over_100_episodes_from_eval 03.17±03.23
2025-12-29 19:08:40,511 | INFO | [trial_010 | seed 29] elapsed_time 00:24:03, episode 0032, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 03.34±03.57, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0006, mean_reward_over_100_episodes_from_eval 03.62±04.10
2025-12-29 19:09:24,636 | INFO | [trial_010 | seed 29] elapsed_time 00:24:48, episode 0033, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 03.89±04.72, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0006, mean_reward_over_100_episodes_from_eval 04.07±04.79
2025-12-29 19:10:10,545 | INFO | [trial_010 | seed 29] elapsed_time 00:25:33, episode 0034, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 04.37±05.44, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0006, mean_reward_over_100_episodes_from_eval 04.63±05.72
2025-12-29 19:10:54,705 | INFO | [trial_010 | seed 29] elapsed_time 00:26:18, episode 0035, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 04.90±06.21, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 05.10±06.31
2025-12-29 19:11:39,014 | INFO | [trial_010 | seed 29] elapsed_time 00:27:02, episode 0036, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 05.44±06.92, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 05.74±07.29
2025-12-29 19:12:21,192 | INFO | [trial_010 | seed 29] elapsed_time 00:27:44, episode 0037, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 06.03±07.72, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 06.31±08.00
2025-12-29 19:13:06,390 | INFO | [trial_010 | seed 29] elapsed_time 00:28:29, episode 0038, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 06.58±08.33, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 06.88±08.65
2025-12-29 19:13:50,508 | INFO | [trial_010 | seed 29] elapsed_time 00:29:13, episode 0039, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 07.13±08.92, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0007, mean_reward_over_100_episodes_from_eval 07.37±09.05
2025-12-29 19:14:35,162 | INFO | [trial_010 | seed 29] elapsed_time 00:29:58, episode 0040, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 07.71±09.54, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0007, mean_reward_over_100_episodes_from_eval 08.03±09.88
2025-12-29 19:15:19,565 | INFO | [trial_010 | seed 29] elapsed_time 00:30:42, episode 0041, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 08.34±10.27, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0007, mean_reward_over_100_episodes_from_eval 08.70±10.65
2025-12-29 19:16:03,525 | INFO | [trial_010 | seed 29] elapsed_time 00:31:26, episode 0042, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 08.95±10.89, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0008, mean_reward_over_100_episodes_from_eval 09.30±11.23
2025-12-29 19:16:47,667 | INFO | [trial_010 | seed 29] elapsed_time 00:32:11, episode 0043, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 09.56±11.48, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0008, mean_reward_over_100_episodes_from_eval 09.88±11.74
2025-12-29 19:17:32,449 | INFO | [trial_010 | seed 29] elapsed_time 00:32:55, episode 0044, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 10.17±12.04, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0009, mean_reward_over_100_episodes_from_eval 10.45±12.21
2025-12-29 19:18:15,759 | INFO | [trial_010 | seed 29] elapsed_time 00:33:39, episode 0045, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 10.78±12.61, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0008, mean_reward_over_100_episodes_from_eval 11.07±12.78
2025-12-29 19:18:59,731 | INFO | [trial_010 | seed 29] elapsed_time 00:34:23, episode 0046, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 11.36±13.07, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0009, mean_reward_over_100_episodes_from_eval 11.67±13.27
2025-12-29 19:19:43,800 | INFO | [trial_010 | seed 29] elapsed_time 00:35:07, episode 0047, episode_env_steps 1001, episode_sum_max_reward_per_step 39.609999, episode_sum_max_abs_reward_per_step 39.609999, mean_reward_over_100_episodes_from_training 11.89±13.44, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0009, mean_reward_over_100_episodes_from_eval 12.21±13.65
2025-12-29 19:20:27,450 | INFO | [trial_010 | seed 29] elapsed_time 00:35:50, episode 0048, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 12.42±13.80, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0009, mean_reward_over_100_episodes_from_eval 12.77±14.05
2025-12-29 19:21:11,749 | INFO | [trial_010 | seed 29] elapsed_time 00:36:35, episode 0049, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 12.94±14.14, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0009, mean_reward_over_100_episodes_from_eval 13.29±14.38
2025-12-29 19:21:54,837 | INFO | [trial_010 | seed 29] elapsed_time 00:37:18, episode 0050, episode_env_steps 1001, episode_sum_max_reward_per_step 39.629999, episode_sum_max_abs_reward_per_step 39.629999, mean_reward_over_100_episodes_from_training 13.43±14.42, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0009, mean_reward_over_100_episodes_from_eval 13.74±14.58
2025-12-29 19:22:38,424 | INFO | [trial_010 | seed 29] elapsed_time 00:38:01, episode 0051, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 13.88±14.63, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 14.22±14.85
2025-12-29 19:23:22,766 | INFO | [trial_010 | seed 29] elapsed_time 00:38:46, episode 0052, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 14.32±14.83, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 14.63±15.00
2025-12-29 19:24:07,760 | INFO | [trial_010 | seed 29] elapsed_time 00:39:31, episode 0053, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 14.76±15.04, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 15.08±15.22
2025-12-29 19:24:52,211 | INFO | [trial_010 | seed 29] elapsed_time 00:40:15, episode 0054, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 15.17±15.22, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 15.47±15.36
2025-12-29 19:25:36,704 | INFO | [trial_010 | seed 29] elapsed_time 00:41:00, episode 0055, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 15.59±15.39, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 15.89±15.53
2025-12-29 19:26:18,408 | INFO | [trial_010 | seed 29] elapsed_time 00:41:41, episode 0056, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 15.97±15.52, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 16.28±15.67
2025-12-29 19:27:03,910 | INFO | [trial_010 | seed 29] elapsed_time 00:42:27, episode 0057, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 16.33±15.63, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 16.63±15.75
2025-12-29 19:27:48,287 | INFO | [trial_010 | seed 29] elapsed_time 00:43:11, episode 0058, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 16.69±15.74, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 16.99±15.85
2025-12-29 19:28:32,644 | INFO | [trial_010 | seed 29] elapsed_time 00:43:56, episode 0059, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 17.04±15.83, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 17.35±15.97
2025-12-29 19:29:16,193 | INFO | [trial_010 | seed 29] elapsed_time 00:44:39, episode 0060, episode_env_steps 1001, episode_sum_max_reward_per_step 39.589999, episode_sum_max_abs_reward_per_step 39.589999, mean_reward_over_100_episodes_from_training 17.36±15.90, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 17.65±16.00
2025-12-29 19:29:58,580 | INFO | [trial_010 | seed 29] elapsed_time 00:45:22, episode 0061, episode_env_steps 1001, episode_sum_max_reward_per_step 39.619999, episode_sum_max_abs_reward_per_step 39.619999, mean_reward_over_100_episodes_from_training 17.70±15.99, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 17.97±16.07
2025-12-29 19:30:42,991 | INFO | [trial_010 | seed 29] elapsed_time 00:46:06, episode 0062, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 18.00±16.04, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 18.29±16.14
2025-12-29 19:31:27,332 | INFO | [trial_010 | seed 29] elapsed_time 00:46:50, episode 0063, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 18.31±16.10, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 18.59±16.19
2025-12-29 19:32:11,218 | INFO | [trial_010 | seed 29] elapsed_time 00:47:34, episode 0064, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 18.61±16.15, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 18.90±16.26
2025-12-29 19:32:54,862 | INFO | [trial_010 | seed 29] elapsed_time 00:48:18, episode 0065, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 18.90±16.20, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 19.21±16.32
2025-12-29 19:33:39,664 | INFO | [trial_010 | seed 29] elapsed_time 00:49:03, episode 0066, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 19.18±16.24, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 19.49±16.36
2025-12-29 19:34:23,184 | INFO | [trial_010 | seed 29] elapsed_time 00:49:46, episode 0067, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 19.46±16.28, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 19.76±16.39
2025-12-29 19:35:07,460 | INFO | [trial_010 | seed 29] elapsed_time 00:50:30, episode 0068, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 19.71±16.29, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 20.02±16.41
2025-12-29 19:35:50,002 | INFO | [trial_010 | seed 29] elapsed_time 00:51:13, episode 0069, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 19.96±16.31, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 20.29±16.45
2025-12-29 19:36:34,954 | INFO | [trial_010 | seed 29] elapsed_time 00:51:58, episode 0070, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 20.22±16.33, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 20.52±16.44
2025-12-29 19:37:19,016 | INFO | [trial_010 | seed 29] elapsed_time 00:52:42, episode 0071, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 20.45±16.34, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 20.78±16.47
2025-12-29 19:38:04,506 | INFO | [trial_010 | seed 29] elapsed_time 00:53:27, episode 0072, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 20.68±16.35, mean_exploration_ratio_over_100_episodes_from_training 0.0134±0.0010, mean_reward_over_100_episodes_from_eval 21.02±16.49
2025-12-29 19:38:48,332 | INFO | [trial_010 | seed 29] elapsed_time 00:54:11, episode 0073, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 20.89±16.33, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 21.24±16.48
2025-12-29 19:39:30,460 | INFO | [trial_010 | seed 29] elapsed_time 00:54:53, episode 0074, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 21.13±16.35, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 21.48±16.50
2025-12-29 19:40:15,411 | INFO | [trial_010 | seed 29] elapsed_time 00:55:38, episode 0075, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.35±16.36, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 21.71±16.51
2025-12-29 19:40:59,868 | INFO | [trial_010 | seed 29] elapsed_time 00:56:23, episode 0076, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 21.57±16.36, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 21.91±16.50
2025-12-29 19:41:44,594 | INFO | [trial_010 | seed 29] elapsed_time 00:57:08, episode 0077, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 21.75±16.34, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 22.05±16.44
2025-12-29 19:42:28,415 | INFO | [trial_010 | seed 29] elapsed_time 00:57:51, episode 0078, episode_env_steps 1001, episode_sum_max_reward_per_step 39.599999, episode_sum_max_abs_reward_per_step 39.599999, mean_reward_over_100_episodes_from_training 21.95±16.32, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 22.23±16.42
2025-12-29 19:43:12,967 | INFO | [trial_010 | seed 29] elapsed_time 00:58:36, episode 0079, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 22.13±16.30, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 22.43±16.40
2025-12-29 19:43:56,994 | INFO | [trial_010 | seed 29] elapsed_time 00:59:20, episode 0080, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 22.31±16.29, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 22.62±16.39
2025-12-29 19:44:41,375 | INFO | [trial_010 | seed 29] elapsed_time 01:00:04, episode 0081, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 22.50±16.28, mean_exploration_ratio_over_100_episodes_from_training 0.0133±0.0010, mean_reward_over_100_episodes_from_eval 22.81±16.38
2025-12-29 19:45:23,445 | INFO | [trial_010 | seed 29] elapsed_time 01:00:46, episode 0082, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 22.68±16.25, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 22.98±16.36
2025-12-29 19:46:08,151 | INFO | [trial_010 | seed 29] elapsed_time 01:01:31, episode 0083, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 22.85±16.23, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 23.17±16.35
2025-12-29 19:46:53,189 | INFO | [trial_010 | seed 29] elapsed_time 01:02:16, episode 0084, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 23.03±16.22, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 23.34±16.33
2025-12-29 19:47:38,775 | INFO | [trial_010 | seed 29] elapsed_time 01:03:02, episode 0085, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 23.20±16.20, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 23.50±16.30
2025-12-29 19:48:22,380 | INFO | [trial_010 | seed 29] elapsed_time 01:03:45, episode 0086, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 23.35±16.17, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 23.66±16.27
2025-12-29 19:49:06,845 | INFO | [trial_010 | seed 29] elapsed_time 01:04:30, episode 0087, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 23.49±16.13, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 23.82±16.25
2025-12-29 19:49:50,896 | INFO | [trial_010 | seed 29] elapsed_time 01:05:14, episode 0088, episode_env_steps 1001, episode_sum_max_reward_per_step 39.519999, episode_sum_max_abs_reward_per_step 39.519999, mean_reward_over_100_episodes_from_training 23.64±16.11, mean_exploration_ratio_over_100_episodes_from_training 0.0132±0.0010, mean_reward_over_100_episodes_from_eval 23.98±16.23
2025-12-29 19:50:35,607 | INFO | [trial_010 | seed 29] elapsed_time 01:05:59, episode 0089, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 23.81±16.09, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0010, mean_reward_over_100_episodes_from_eval 24.13±16.20
2025-12-29 19:51:19,683 | INFO | [trial_010 | seed 29] elapsed_time 01:06:43, episode 0090, episode_env_steps 1001, episode_sum_max_reward_per_step 39.669999, episode_sum_max_abs_reward_per_step 39.669999, mean_reward_over_100_episodes_from_training 23.95±16.05, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0010, mean_reward_over_100_episodes_from_eval 24.27±16.17
2025-12-29 19:52:04,376 | INFO | [trial_010 | seed 29] elapsed_time 01:07:27, episode 0091, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.10±16.03, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0010, mean_reward_over_100_episodes_from_eval 24.43±16.15
2025-12-29 19:52:47,072 | INFO | [trial_010 | seed 29] elapsed_time 01:08:10, episode 0092, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 24.24±16.00, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0010, mean_reward_over_100_episodes_from_eval 24.57±16.12
2025-12-29 19:53:33,616 | INFO | [trial_010 | seed 29] elapsed_time 01:08:57, episode 0093, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 24.39±15.98, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0011, mean_reward_over_100_episodes_from_eval 24.71±16.09
2025-12-29 19:54:17,805 | INFO | [trial_010 | seed 29] elapsed_time 01:09:41, episode 0094, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 24.52±15.95, mean_exploration_ratio_over_100_episodes_from_training 0.0131±0.0011, mean_reward_over_100_episodes_from_eval 24.84±16.05
2025-12-29 19:55:01,914 | INFO | [trial_010 | seed 29] elapsed_time 01:10:25, episode 0095, episode_env_steps 1001, episode_sum_max_reward_per_step 39.729999, episode_sum_max_abs_reward_per_step 39.729999, mean_reward_over_100_episodes_from_training 24.64±15.91, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 24.97±16.02
2025-12-29 19:55:46,040 | INFO | [trial_010 | seed 29] elapsed_time 01:11:09, episode 0096, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 24.75±15.86, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 25.08±15.97
2025-12-29 19:56:29,239 | INFO | [trial_010 | seed 29] elapsed_time 01:11:52, episode 0097, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 24.84±15.81, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 25.13±15.90
2025-12-29 19:57:13,729 | INFO | [trial_010 | seed 29] elapsed_time 01:12:37, episode 0098, episode_env_steps 1001, episode_sum_max_reward_per_step 39.709999, episode_sum_max_abs_reward_per_step 39.709999, mean_reward_over_100_episodes_from_training 24.94±15.76, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 25.25±15.87
2025-12-29 19:57:57,361 | INFO | [trial_010 | seed 29] elapsed_time 01:13:20, episode 0099, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 25.06±15.73, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 25.36±15.82
2025-12-29 19:58:42,165 | INFO | [trial_010 | seed 29] elapsed_time 01:14:05, episode 0100, episode_env_steps 1001, episode_sum_max_reward_per_step 39.739999, episode_sum_max_abs_reward_per_step 39.739999, mean_reward_over_100_episodes_from_training 25.43±15.58, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 25.72±15.67
2025-12-29 19:59:25,424 | INFO | [trial_010 | seed 29] elapsed_time 01:14:48, episode 0101, episode_env_steps 1001, episode_sum_max_reward_per_step 39.639999, episode_sum_max_abs_reward_per_step 39.639999, mean_reward_over_100_episodes_from_training 25.79±15.43, mean_exploration_ratio_over_100_episodes_from_training 0.0130±0.0011, mean_reward_over_100_episodes_from_eval 26.09±15.52
2025-12-29 20:00:10,023 | INFO | [trial_010 | seed 29] elapsed_time 01:15:33, episode 0102, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 26.15±15.26, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0011, mean_reward_over_100_episodes_from_eval 26.44±15.34
2025-12-29 20:00:52,642 | INFO | [trial_010 | seed 29] elapsed_time 01:16:16, episode 0103, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 26.50±15.10, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0011, mean_reward_over_100_episodes_from_eval 26.80±15.18
2025-12-29 20:01:37,624 | INFO | [trial_010 | seed 29] elapsed_time 01:17:01, episode 0104, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 26.85±14.91, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0011, mean_reward_over_100_episodes_from_eval 27.16±15.02
2025-12-29 20:02:21,830 | INFO | [trial_010 | seed 29] elapsed_time 01:17:45, episode 0105, episode_env_steps 1001, episode_sum_max_reward_per_step 39.659999, episode_sum_max_abs_reward_per_step 39.659999, mean_reward_over_100_episodes_from_training 27.19±14.70, mean_exploration_ratio_over_100_episodes_from_training 0.0129±0.0011, mean_reward_over_100_episodes_from_eval 27.52±14.82
2025-12-29 20:03:04,773 | INFO | [trial_010 | seed 29] elapsed_time 01:18:28, episode 0106, episode_env_steps 1001, episode_sum_max_reward_per_step 39.699999, episode_sum_max_abs_reward_per_step 39.699999, mean_reward_over_100_episodes_from_training 27.55±14.49, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0011, mean_reward_over_100_episodes_from_eval 27.85±14.59
2025-12-29 20:03:49,662 | INFO | [trial_010 | seed 29] elapsed_time 01:19:13, episode 0107, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 27.92±14.28, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0012, mean_reward_over_100_episodes_from_eval 28.21±14.37
2025-12-29 20:04:34,387 | INFO | [trial_010 | seed 29] elapsed_time 01:19:57, episode 0108, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.27±14.05, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0012, mean_reward_over_100_episodes_from_eval 28.57±14.13
2025-12-29 20:05:18,313 | INFO | [trial_010 | seed 29] elapsed_time 01:20:41, episode 0109, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 28.63±13.81, mean_exploration_ratio_over_100_episodes_from_training 0.0128±0.0012, mean_reward_over_100_episodes_from_eval 28.93±13.88
2025-12-29 20:06:04,003 | INFO | [trial_010 | seed 29] elapsed_time 01:21:27, episode 0110, episode_env_steps 1001, episode_sum_max_reward_per_step 39.649999, episode_sum_max_abs_reward_per_step 39.649999, mean_reward_over_100_episodes_from_training 28.99±13.55, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0012, mean_reward_over_100_episodes_from_eval 29.29±13.62
2025-12-29 20:06:48,053 | INFO | [trial_010 | seed 29] elapsed_time 01:22:11, episode 0111, episode_env_steps 1001, episode_sum_max_reward_per_step 39.679999, episode_sum_max_abs_reward_per_step 39.679999, mean_reward_over_100_episodes_from_training 29.34±13.28, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0012, mean_reward_over_100_episodes_from_eval 29.65±13.33
2025-12-29 20:07:30,465 | INFO | [trial_010 | seed 29] elapsed_time 01:22:53, episode 0112, episode_env_steps 1001, episode_sum_max_reward_per_step 39.719999, episode_sum_max_abs_reward_per_step 39.719999, mean_reward_over_100_episodes_from_training 29.71±12.99, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0012, mean_reward_over_100_episodes_from_eval 30.00±13.05
2025-12-29 20:08:16,409 | INFO | [trial_010 | seed 29] Requirement met (evaluation metric): solved at episode 114 with mean_100_eval=30.34
2025-12-29 20:08:16,410 | INFO | [trial_010 | seed 29] elapsed_time 01:23:39, episode 0113, episode_env_steps 1001, episode_sum_max_reward_per_step 39.689999, episode_sum_max_abs_reward_per_step 39.689999, mean_reward_over_100_episodes_from_training 30.07±12.70, mean_exploration_ratio_over_100_episodes_from_training 0.0127±0.0012, mean_reward_over_100_episodes_from_eval 30.34±12.76
2025-12-29 20:08:16,410 | INFO | [trial_010 | seed 29] --> reached_goal_mean_reward (eval mean_100) OK
2025-12-29 20:32:32,803 | INFO | [trial_010 | seed 29] Training complete.
2025-12-29 20:32:32,804 | INFO | [trial_010 | seed 29] Solved (evaluation metric) at episode 114.
2025-12-29 20:32:32,804 | INFO | [trial_010 | seed 29] Final evaluation score 37.63±0.76 in 3351.93s training, 6476.23s wall.
2025-12-29 20:32:32,804 | INFO | [trial_010 | seed 29] Closing UnityVectorEnv (worker_id=10029).
2025-12-29 20:32:32,804 | INFO | [Main] Requesting worker 10029 to close Unity env.
2025-12-29 20:32:33,231 | INFO | [Main] Worker 10029 joined. Unity env fully closed.
2025-12-29 20:32:33,231 | INFO | [trial_010 | seed 29] Final eval score: 37.63
2025-12-29 20:32:33,534 | INFO | [trial_010 | seed 29] Per-seed evaluation plot saved to results\continuous_control\run_20251228_184535\plots\evaluation_mean100_trial_010_seed_29.png
2025-12-29 20:32:33,534 | INFO | [trial_010 | seed 29] Summary appended to results\continuous_control\run_20251228_184535\plots_summary.csv
2025-12-29 20:32:33,690 | INFO | [trial_010] Final scores across seeds: [37.629]
2025-12-29 20:32:33,690 | INFO | [trial_010] Avg=37.629 ± 0.000, Best seed score=37.629
2025-12-29 20:32:33,696 | INFO | Best trial: trial_001 with Avg=37.713 ± 0.000
2025-12-29 20:32:33,696 | INFO | Best hyperparameters: {"batch_size":500,"buffer_size":100000,"exploration_noise_ratio":0.05,"hidden_dims":[256,256],"lr":0.0005,"n_warmup_batches":5,"optimizer":"Adam","target_update_every":5,"tau":0.01}
2025-12-29 20:32:33,696 | INFO | Best hyperparameters saved to: results\continuous_control\run_20251228_184535\best_hparams.json
2025-12-29 20:32:33,957 | INFO | Best trial evaluation plot saved to results\continuous_control\run_20251228_184535\plots\trial_001_evaluation_mean100.png
2025-12-29 20:32:34,161 | INFO | [trial_001] Hypothesis tests over 1 seeds:
2025-12-29 20:32:34,161 | INFO | [trial_001] Final scores: [37.713]
2025-12-29 20:32:34,161 | INFO | [trial_001] Mean=37.713, Std=0.000, Goal=30.000
2025-12-29 20:32:34,161 | INFO | [trial_001] Bootstrap 95% CI for mean: [37.713, 37.713]
2025-12-29 20:32:34,161 | INFO | [trial_001] Significant (mean > goal @95%)? Yes
2025-12-29 20:32:34,161 | INFO | Hyperparameter search finished.
